[ { "title": "프로그래머스 인공지능 데브코스 4기 수료 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-%ED%9B%84%EA%B8%B0/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2023-02-17 21:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스 4기의 수료 후기를 적어보려고 합니다. 약 5개월 정도 되는 시간 동안 참여했던 이 프로그램을 돌아보고, 나름대로 간단한 회고를 해보고자 합니다. 부족한 부분들도 많이 있었지만, 많은 분들과 새로운 것들을 배워갈 수 있는 좋은 기회가 되었던 것 같습니다! 프로그래머스에서 주관하는 데브코스 외에도 인공지능과 관련한 부트캠프에 참여하시는 분들께 도움이 되었으면 좋겠습니다.1. 돌아보다프로그램 합격 후에 후기를 담은 글을 블로그에 올렸던 것이 엊그제 같은데, 벌써 5개월이라는 시간이 지났습니다. K-digital training으로 참여했던 이 과정에서는 스크랩핑, 머신러닝 및 딥러닝 (NLP, CV, Rec Sys), SQL, Spark 등 다양한 내용들을 학습할 수 있었습니다. 또한 가장 마지막에는 지금까지 배운 내용으로 최종 프로젝트를 수행하며, 결과물을 만들어보았습니다. 약 1년 정도 다녔던 스타트업을 퇴사하고 이 프로그램에 참여하면서 합격 후기 글을 다음과 같이 적었습니다. 저는 약 1년 정도 다녔던 핀테크 스타트업을 퇴사하고, 이번 프로그램에 참여하는 것으로 결정했습니다. 회사를 다니면서 여러가지 고민이 많이 있었는데, 이러한 고민들을 조금 내려놓고 개인의 시간을 가지면서 제가 하는 분야에 대한 전문성을 기르고 싶다는 생각을 하게 되었습니다. 지금도 여전히 고민은 진행중이고, 향후 진로에 대해서도 취업과 대학원 진학, 창업 등으로 고민을 많이 하고 있지만, 앞서 이야기 했듯 어느 방향으로 가든 제 분야에 대한 전문성과 실력을 기르고 싶다는 마음이 가장 큰 것 같습니다. 이번 프로그램에서는 아래와 같이 계획과 목표를 세우고 참여해보고 싶습니다. 딥러닝의 주요한 모델들에 대한 기본적인 이론 및 응용력 학습하기 데이터 엔지니어링 분야에 대하여 학습해보고, 해당 분야에 대해 조금 더 구체화 시켜보기 팀원들과 함께하는 프로젝트를 통해 유의미한 성과 내보기 (공모전, 논문, 특허 등) 내 진로, 향후 계획 등에 대해서 조금 더 진지하게 고민할 수 있는 시간 갖기 참여하는 약 40명 정도의 교육생 분들과 이야기 나누고, 교제하며 서로 동기부여 받기 프로그램 시작 전, 여러 기대와 꿈을 가지고 고민하며 글을 적었던 것이 기억 납니다. 5개월 이라는 시간이 지난 지금, 과연 이 목표와 계획들은 어떻게 이뤄졌는지 돌아보고 싶습니다. 프로그램에 참여하면서 수업 외적으로 가장 많은 시간을 들여 고민했던 것은 진로와 직무에 대한 부분이었습니다. 이 캠프의 기간에 맞물려, 많은 기업들에서 AI 분야를 비롯하여 개발자 채용의 문이 좁아지고 있다는 소식들을 접하게 되면서 오히려 조금 더 객관적으로 정말로 내가 하고 싶은 것은 무엇인지 계속 고민할 수 있었던 것 같습니다. 개인적으로는, 어떻게 하는지 (Know-how) 보다, 무엇을, 왜 하는지 (Know-why)가 더 중요하다고 생각하기 때문에 데이터 분야 안에서도 이 부분을 꾸준히 고민하려고 했던 것 같습니다. 이러한 생각 때문인지 프로젝트를 하는데 있어서도, 기술적으로 할 수 있는 프로젝트 보다는 사회적으로 필요한 프로젝트를 하고 싶었습니다. 사람들의 삶에서 여전히 존재하는 불편함을 데이터로 해결해보고자 하는 목표 속에, 이를 수행할 수 있는 공모전과 프로젝트를 수행할 수 있었습니다. 사람들의 데이터 이용 과정에서 발생하는 불편함을 해소하기 위하여 ‘데이터 아카이브 서비스’를 개발할 수 있었는데, 자세한 내용은 이 링크를 통해 확인할 수 있습니다. 공공 데이터를 사용해보았던 분들이라면, 어느 정도 공감할 수 있는 문제 정의를 바탕으로 감사하게 2022년도 ETRI OPEN API 공모전에서 우수상을, 데브코스 최종 프로젝트에서 최우수상을 받을 수 있었습니다. 이 외에도 개인적으로 관심 있었던 ‘데이터 엔지니어링’ 분야에 대해서 coursera 강의를 통해 airflow와 kafka를 활용하여 기초적인 데이터 엔지니어링 분야를 학습할 수 있었습니다. 개인적으로 최종 프로젝트에서 이 부분도 고려하여 완성도를 높이고 싶었지만, 시간적인 제약 속에서 아쉽게 적용하지는 못했습니다. 그럼에도 개인적으로 airflow를 통해서 자동화 된 ETL 프로세스를 만들어 볼 계획입니다. 한편, 이번 데브코스의 정식 프로그램의 95% 이상은 온라인으로 진행되었고, 나머지는 팀원들의 재량으로 오프라인으로 모인다면 장소를 지원해주는 형식이었습니다. 저는 프로젝트의 전체적인 관리를 하면서, 팀원 분들과 오프라인으로 프로젝트 할 수 있도록 제안하며 그래도 직접 만났던 분들과는 여전히 좋은 교제를 나누고 있는 것 같습니다. 비록 목표했던 모든 분들과 이야기를 나눠보지는 못했지만, 온라인이라는 제한적인 상황에서 서로의 진로와 꿈, 고민들을 나눌 수 있는 (소수지만) 깊은 관계를 맺을 수 있는 팀원 분들을 알게 되어 정말 감사한 것 같습니다.2. 앞으로 나아가다길다면 길고, 짧다면 짧았던 지난 5개월을 마무리하면서 가장 많이 들었던 생각은 ‘이제는 정말로 무엇을 하고 싶다’는 생각이었습니다. 현재 뚜렷하게 제 신분을 설명할 수 없다는 한계 속에서 이러한 생각이 들었을 수도 있겠지만, 그럼에도 불구하고, 대학원에서 정말로 내가 하고 싶은 연구나, 가고 싶은 회사에서 새로운 부가가치를 만들어내는 일을 하고 싶다는 생각이 정말로 많이 들었던 것 같습니다. 이 고민 속에서 사람과 기술 사이의 관계를 고민하는 HCI (Human Computer Interaction) 이라는 새로운 분야를 알게 되었습니다. 최근 ChatGPT 등과 같이 사람이 생각하는 것보다 더 빠르게 발전하는 여러 기술들 속에, 유용한 기술이라는 것은 사람들에게 더 큰 가치를 제공하는 것임을 깨닫습니다. 즉, 기술 그 자체에 대한 학습 역시 중요하겠지만, 그것을 사용하는 사람에 대해서도 함께 공부할 수 있는 이 분야가 중요할 것이라고 생각합니다. 그래서 아직은 잘 모르지만 이 분야에 대해서 공부하고, 논문을 찾아보며 제가 기여할 수 있는 부분은 어떠한 것인지 고민해보고 있습니다. 이와 더불어, 데이터로 새로운 부가가치를 만들어내는데 기여하는 좋은 문화를 갖는 몇몇 기업들을 찾아보면서 어떤 직무 속에 내가 기여할 수 있을지에 대한 것들을 고민하고 있습니다. 기술로 세상을 더 선하게 변화시키고 싶다는 개인적인 비전을 달성하기 위하여 지금까지 배웠던 것들을 잘 정리하고, 준비하여 새로운 도전을 시작해보겠습니다. 이 글을 읽으시는 모든 분들의 꿈을 진심으로 응원합니다. 감사합니다!" }, { "title": "ETL & Data Pipelines with Shell, Airflow and Kafka 4주차", "url": "/posts/Coursera-Data-Engineering-4%EC%A3%BC%EC%B0%A8/", "categories": "Education, Coursera - Data Engineering", "tags": "AI, Deep learning, Machine learning, Data Engineering, Airflow, Kafka, ETL, ELT", "date": "2023-01-27 00:00:00 +0900", "snippet": "이번 글에서는 Coursera의 ETL and Data Pipelines with Shell, Airflow and Kafka (IBM) 4주차 강의를 정리합니다. 이 강좌는 ETL 및 ELT 데이터 파이프라인에 대해 학습하며, Airflow와 Kafka 등을 이용해 이를 배우게 됩니다. 4주차에는 Kafka를 이용해서 스트리밍 파이프라인을 구축하는 방법에 대해 공부합니다.1. 데이터 학습 목표 Kafka가 이벤트 스트리밍 플랫폼 (ESP)으로 작동하는 방식 학습 Kafka의 핵심 구성 요소 학습 Kafka의 Stremas API가 무엇이고, 장점은 무엇인지 등에 대해 학습 Kafka-python 클라이언트를 통해 Kafka 서버에서 작업 실행시켜보기2. 분산 이벤트 스트리밍 플랫폼 Event 라는 것은 주목할 만한 일이 일어나고 있다는 것을 의미 Event Streaming 맥락에서, Event는 시간이 지남에 따라 엔티티의 관찰 가능한 상태를 설명하는 데이터 유형 자동차의 GPS 좌표, 방의 온도, 환자의 혈압 측정, 애플리케이션에서 RAM 사용량 등 Event는 특별한 데이터의 타입으로 형식이 서로 다른데, 일반적인 3가지는 다음과 같음 Primitive (원시 유형): 일반 텍스트, 숫자, 날짜 등 Key-value Pairs: List, Tuple, JSON, XML, Bytes 등 Key-value with a Timestamp: 이벤트를 타임 스탬프와 연결하여 시간에 민감하게 표현 Event Source와 Event Destination 사이의 연속적 이벤트 전송을 Event Streaming 이라고 함 Event Source에는 Sensors, Devices, Applications 등과 같이 데이터를 만드는 대상 Event Destination는 File Systems, Databases 등과 같이 Event Source가 전송되는 대상 실제로, Event Streaming은 다양하고, 분산된 Event Source와 Destination으로 복잡한 문제 데이터 전송 파이프라인의 프로토콜은 다음과 같은 것들이 있음 FTP: File Transfer Protocol HTTP: Hypertext Transfer Protocol JDBC: Java Database Connectivity SCP: Secure Copy 또한 Event Destination은 동시에 Event Source가 될 수도 있음 다양한 Event Source와 Destination을 처리하기 위해서는, ESP (Event Stream Platform)을 사용해야 함 https://www.geeksforgeeks.org/file-transfer-protocol-ftp-in-application-layer/ ESP (Event Stream Platform) Event Source와 Destination 사이에서 중간 계층 역할을 하면서 이벤트 기반 ETL을 처리하기 위한 인터페이스 따라서 Event Source를 개별 Event Destination으로 전달하지 않고, ESP로 전달 Event Destination은 ESP에 subscribe만 하고, 개별 Event Source로 받지 않고, ESP에서 데이터를 consume 아래 그림에서는 Event Source를 Producer로, Event Destination을 Consumer로 표현 Popular ESP는 Kafka, Kinesis, Flink, Spark, Storm 등이 있음 https://blog.devgenius.io/event-processing-platform-4d950c4ff3e3 Common Components of an ESP Event Broker: ESP에서의 Core Component로, Ingester, Processer, Consumpution을 포함 Ingester: 다양한 Event Sources로부터 Event를 효과적으로 받을 수 있도록 설계 Processer: (De) Serializing, (De) Compressing, Encryption 등 데이터에 대한 작업 수행 Consumpution: 이벤트 저장소에서 이벤트를 검색해 이벤트를 효율적으로 배포 Event Storage Analytics and Query Engine 3. Apache Kafka Kafka는 포괄적인 플랫폼이면서 많은 애플리케이션 시나리오에서 사용 가능 원래 Kafka는 사용자의 키보드를 통한 검색, 마우스 클릭, 검색 등과 같이 사용자의 활동을 추적하기 위한 것 하지만 지금은 하드웨어 및 소프트웨어 모니터링, 센서, GPS 등과 같이 Metric-Streaming에도 적합 Kafka를 이용하여 중앙 저장소에 로그를 수집하고 통합 할 수도 있음 (거래내역을 다루는 은행, 보험 등에서 사용) 즉, Kafka를 통해 많은 양의 데이터를 처리할 수 있고, 신뢰할 수 있는 데이터 전송 서비스를 구축할 수 있음 모든 이벤트들은 Kafka를 통해 수집되고, 저장 및 소비가 가능 데이터 저장, 온오프라인 데이터베이스로의 이동, 백업, 실시간 처리, 분석, 대시보드, AI 등 Email, 텍스트 메시지 등과 같이 Notification을 생성할 수도 있음 수업 자료 Kafka의 주요한 Components Brokers: The dedicated servers to receive, store, process, and distribute events Topics: The containers or databases of events Partitions: Divide topics into different brokers Replications: Duplicate partitions into different brokers Producers: Kafka client applications to publish events into topics Consumers: Kafka client applications are subscribed to topics and read events from them https://techblog.gccompany.co.kr/apache-kafka%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%97%AC-eda-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0-bf263c79efd0 Kafka는 Distributed Client-server Architecture의 형태 Sever 사이드에서는 Broker 라고 불리는 클러스터가 있고, 이벤트를 수신, 저장, 배포하는 역할 수행 이러한 Broker들은 효율적으로 작업되도록 ZooKeeper 라고 불리는 분산 시스템으로부터 관리됨 Kafka는 TCP 기반의 네트워크 통신 프로토콜을 사용해 클라이언트와 서버 사이에서 데이터를 교환 Client 사이드에서는 서버와 통신하기 위해 Kafka CLI나 자바나 파이썬 같은 클라이언트를 제공 수업 자료 Kafka의 주요한 특징 많은 양의 데이터 처리가 가능하고, 동시에 처리할 수 있는 확장성이 뛰어난 Distribution System Kafka 클러스터는 이벤트 스트리밍을 병렬로 처리할 수 있는 Event Brokers가 존재 (빠르고, 확장성 좋음) 이벤트 저장 공간을 여러 개의 파티션으로 나누거나, 복제하여 장애를 방지하고 안정성이 높음 이벤트를 영구적으로 저장할 수 있음 오픈소스이기 때문에 무료로 사용할 수 있고, 커스터마이징이 가능 오픈소스이고, 문서화도 잘 되어 있긴 하지만 Kafka 클러스터를 구축하기 위해서는 인프라 설계가 필요 (어려움) 이를 위해서 Confluent Cloud, IBM Event Streams, Amazon MSK 같은 서비스들도 존재 4. Kafka를 통해 Event Streaming 파이프라인 만들기 Kafka 클러스터는 하나 이상의 Broker를 포함하고 있고, 이를 이벤트 수신, 저장, 처리, 배포 전용 서버로 이해 가능 Broker는 ZooKeeper라는 전용 서버에 의해 동기화 되고, 관리됨 Broker는 Event를 Topic으로 저장 및 관리하고, Consumers에게 배포 Kafka는 다른 분산 시스템과 마찬가지로, 분할 (Partitioning) 및 복제 (Replicating) 개념을 구현 이를 통해 데이터 처리량을 향상시켜서 여러 Broker와 동시에 병렬적으로 작업이 가능 일부 Broker가 다운 되더라도, 여전히 다른 Broker에서 복제하여 작업을 수행할 수 있음 즉, 아래 그림과 같이 log topic과 user topic이 두 파티션으로 구분되고, 복제되어 서로 다른 Broker에 저장 수업 자료 Kafka CLI는 사용자가 이벤트 스트리밍 파이프라인을 구축할 수 있도록 도와줄 수 있음 Kafka-topics 스크립트는 간단하게 Kafka 클러스터의 항목을 관리하는데 자주 사용할 수 있는 스크립트 Create a topic, List topics, Get topics details, Delete a topics 수업 자료 Kafka Producer는 등록된 순서에 따라 Topic 파티션에 이벤트를 등록하는 클라이언트 응용 프로그램 Producer에서 Event를 게시할 때, 선택적으로 Event를 Key와 연결할 수 있음 동일한 Key에 연결된 Event는 동일한 Topic 파티션에 Publish 됨 Key와 연결되지 않은 Event는 로테이션으로 Topic 파티션에 Publish 됨 아래 그림에서 같이 Log를 만드는 Event Source 1과 사용자 활동을 추적하는 Event Source 2가 있다고 가정 Kafka Producer를 통해 log topics과 user topics을 각각의 파티션에 publish 이때, 프로그램의 이름이나 사용자 ID 같은 Key 값으로 이벤트를 연결할 수도 있음 수업 자료 Producer는 Topic에 대하여 Event를 Publish 하거나, Write 하는 것이 가장 중요 아래 그림에서처럼 Key 값을 포함하거나, 포함하지 않고 Producer를 시작시킬 수 있음 Key를 주는 경우에는, 사용자 1에 대한 모든 Event가 동일한 파티션에 저장되어 Consumer가 사용할 것 수업 자료 Event가 Publish 되고, Topic 파티션에 저장되면, Event를 읽을 수 있는 Consumer를 만들 수 있음 Consumer는 저장된 Event를 읽고, Topic을 다룰 수 있는 클라이언트 어플리케이션 Consumer는 Topic 파티션의 데이터를 publish 된 순서에 따라서 읽음 각각의 파티션에 Offset (상대 위치)를 저장하고, 이를 이용하여 Event가 발생할 때, 그것을 읽을 수 있음 Offset을 0으로 재설정할 수 있고, 이를 통해 Consumer는 Topic 파티션의 모든 이벤트를 처음부터 읽을 수 있음 Kafka에서 Producer와 Consumer는 완전히 분리되어 있어서 (Fully Decoupled) Producers는 Consumers와 동기화 시킬 필요가 없고, Event가 Topic에 저장된 후에는 Consumer가 독립적으로 스케줄에 따라 작업 로그와 사용자 행동 이벤트를 Topic 파티션으로부터 publish 하기 위해서는 거기에 맞는 각각의 Consumer가 필요함 그리고 Kafka는 Consumer에게 Event를 push하고, Consumer는 Event Destination으로 보냄 수업 자료 Kafka Consumer Script를 통해 Consumer를 실행시키기 위해서는 다음과 같이 수행 log topic으로부터 Event를 읽은 후, Script를 실행하여 Kafka 클러스터와 Topic을 지정 Consumer는 마지막 파티션 Offset에서부터 시작해서 새로운 이벤트만 읽음 새로운 이벤트를 처리한 후에는 파티션 Offset도 업데이트 되고, Kafka에 반영 가끔씩 사용자가 처음부터 모든 Event를 읽고자 한다면, 옵션을 추가해주면 됨 수업 자료5. Weather Pipeline Example 날씨와 트위터의 Event Stream을 수집하고, 사람들이 트위터에서 극단적 날씨에 대해 말하는 것을 분석하고자 함 이를 위해 JSON 포멧으로 날씨와 트위터 데이터를 실시간으로 받는 IBM Weather API, Twitter API 사용 날씨와 트위터를 JSON 형태로 Kafka에서 받기 위해서는, Kafka 클러스터에서 weather topic과 twitter topic 필요 Weather Producer와 Twitter Producer를 만들고, 데이터는 바이트로 직렬화 되어 Kafka Topic에 저장 2개의 Topic에서 Event를 읽기 위해서 Producer와 마찬가지로, Weather Consumer와 Twitter Consumer 필요 Kafka Topic에 저장된 바이트 (Bytes)는 Event JSON 데이터로 역직렬화 (Deserialized) 데이터들을 관계형 데이터베이스로 전송하기 위해 DB Writer를 사용해서 JSON 파일 분석 및 DB 레코드를 만듦 그 후, SQL 쿼리를 통해서 이 레코드들을 데이터베이스에 작성하고, 저장 마지막으로는 앞서 만든 DB로부터 데이터를 활용해 대시보드를 만들고 시각화 및 분석을 진행할 수 있음 수업 자료6. Kafka Streaming Process Event Streaming에서 데이터 엔지니어는 데이터 전송, 필터링, 집계, 향상 등을 통해 데이터를 처리해야 함 Streams 처리를 위해 개발된 어플리케이션을 Stream Processing Applications이라고 함 Kafka 기반 Stream Processing Applications 구현을 위한 간단한 방법은 한 Topic에서 Event를 읽고, 처리한 후에 다른 Topic을 Publish 하기 위해 Ad hoc 데이터 프로세서를 구현하는 것 Weather API로 JSON 데이터를 받은 후, Weather Producer는 Weather Topic으로 Publish Consumer는 Weather Topic으로부터 데이터를 읽음 Ad hoc 데이터 프로세서를 만들어서 극단적으로 높은 기온과 같이 이상기후 데이터만 필터링하도록 함 프로세서는 간단한 스크립트 파일이거나, Kafka에서 클라이언트와 함께 작동해 데이터를 다루는 프로그램 프로세서는 처리된 데이터를 다른 Produer로 전달하고, Publish 하여 Topic을 만듦 그 Topic은 Consumer로 전달 및 처리되고, 시각화를 위해 대시보드 등에 전달 수업 자료 Ad hoc 프로세서는 처리해야 할 많은 Topic이 있는 경우에 복잡해질 수 있는데, Kafka는 이를 해결할 수 있음 Kafka는 Stream Processing을 위해서 Streams API를 제공 Kafka Streams API는 이벤트 스트리밍 파이프라인에서 데이터 처리를 돕는 간단한 클라이언트 라이브러리 Kafka Topics에 저장된 데이터를 처리하고 분석하기 때문에 Streams API의 입출력이 모두 Kafka Topics Kafka Streams API는 각각의 기록들이 한 번만 처리되도록 보장 Kafka Streams API는 한 번에 하나의 레코드만 처리 수업 자료 Kafka Streams API는 Stream-processing topology 라는 계산 그래프를 기반으로 함 이 Topology에서 각 노드는 Upstream 프로세서에서 Streams을 받고, 맵핑, 필터링, 포메팅 등과 같은 데이터 변환을 수행하며, 다운스트림 프로세서로 출력 Stream을 생성하는 Stream 프로세서 그렇기 때문에 그래프의 가장자리는 Input, Output Streams 프로세서에는 다음과 같은 두 가지 특별한 유형이 있음 Source 프로세서: Consumer처럼 Kafka Topic을 처리하고, 처리된 Streams을 Downstream 프로세서로 전달 Sink 프로세서: Producer처럼 받은 Streams을 Kafka Topic으로 Publish 하는 역할 수업 자료 Kafka Streams API를 통해 날씨 스트림 처리 어플리케이션을 다시 설계한다면 다음과 같음 Ad hoc 프로세서를 개발하는 것 대신, Kafka Streams API를 사용하면 됨 Kafka Streams Topology에는 세 개의 Stream 프로세서가 있음 Source 프로세서: Raw Weather Topic으로부터 Weather Streams을 처리하고, Stream 프로세서로 전달 Stream 프로세서: 이상기후와 같은 조건을 필터링하고, Sink 프로세서로 전달 Sink 프로세서: 처리된 Weather Topic의 결과를 Publish 이러한 방식은 처리해야 할 Topic의 수가 많은 경우에 Ad hoc 데이터 프로세서보다 훨씬 더 쉬운 방법 수업 자료" }, { "title": "ETL & Data Pipelines with Shell, Airflow and Kafka 3주차", "url": "/posts/Coursera-Data-Engineering-3%EC%A3%BC%EC%B0%A8/", "categories": "Education, Coursera - Data Engineering", "tags": "AI, Deep learning, Machine learning, Data Engineering, Airflow, Kafka, ETL, ELT", "date": "2023-01-27 00:00:00 +0900", "snippet": "이번 글에서는 Coursera의 ETL and Data Pipelines with Shell, Airflow and Kafka (IBM) 3주차 강의를 정리합니다. 이 강좌는 ETL 및 ELT 데이터 파이프라인에 대해 학습하며, Airflow와 Kafka 등을 이용해 이를 배우게 됩니다. 3주차에는 Airflow를 이용해 데이터 파이프라인을 구축하는 방법에 대해 공부합니다.1. 데이터 학습 목표 Apache Airflow의 주요 기능 및 원칙 나열 작업 및 종속성의 DAG로 워크플로 설명 워크플로를 코드로 정의할 때의 장점 소개 특정 DAG를 시각화 하는 다양한 방법 요약 DAG 정의 파일의 주요 구성 요소 설명 및 연산자를 인스턴스화 하여 태스크 생성 로깅 기능을 사용해 작업 상태 모니터링 및 DAG 실행 문제 진단2. Apache Airflow Apache Airflow는 훌륭한 오픈소스 워크플로 오케스트레이션 도구 Batch Data Pipeline과 같은 워크플로를 만들고 실행할 수 있는 플랫폼 Airflow에서는 워크플로가 DAG (Directed Acyclic Graph)로 표시 Airflow는 Kafka, Storm, Spark 같은 도구들과는 달리, 데이터 스트리밍 솔루션이 아닌, 워크플로 관리자 기본 구성 요소 Airflow는 예약된 워크플로의 트리거를 처리하는 내장형 Scheduler가 존재 Scheduler는 예약된 각 워크플로에서 개별 작업을 Executor에게 전달 Executor는 이러한 작업을 Worker에 할당하여 실행 및 처리. 그리고 다음 작업 실행 Web Server는 Airflow의 대화식 사용자 인터페이스 제공 (여기에서 DAG를 검사하고, 트리거 및 디버그 가능) DAG Directory는 Scheduler, Executor, Workers에서 액세스 할 수 있는 모든 DAG 파일이 포함 DAG는 태스크 (수행할 작업들)들 사이의 종속성과 실행 순서를 지정 https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/overview.html Airflow의 주요 기능과 장점 표준 Python을 사용하여 워크플로를 만들고, 이를 통해 데이터 파이프라인 구축 시, 유연성을 유지할 수 있음 UI가 유용하여 모니터링, 스케줄링, 워크플로 관리 등을 Web app을 통해 할 수 있음 IBM Cloudant와 같이 다른 많은 Plug-and-play 서비스들과 통합 가능 Python에 대한 지식이 있다면, 누구든지 워크플로를 배포할 수 있음 오픈소스이기 때문에 무엇인가를 공유하고 싶다면, PR을 만들 수 있음 Airflow의 네 가지 주요 원칙 확장성: 모듈식 아키텍쳐를 가지고 있으며, 메시지 큐를 사용하여 임의의 Workers의 수를 관리 동적: Airflow 파이프라인은 Python으로 정의되고, 동적 파이프라인 생성을 허용하여 동시 작업 가능 확장 가능성: 자신의 환경에 맞게 연산자를 쉽게 정의하고, 라이브러리를 확장할 수 있음 린 (Lean): Airflow는 매개변수화가 Jinja 템플릿 엔진으로 내장되어 린하고 명시적 3. DAG (Directed Acyclic Graph) DAG는 방향성 비순환 그래프라고 하는 특별한 종류의 그래프 Graph: Nodes and Edges Directed Graph: Each edge has a direction Acyclic: No loops (cycles) DAG는 Airflow에서 워크플로 또는 파이프라인을 나타내는데 사용 (Python 코드로 정의된 워크플로) 파이프라인에서 수행하는 각 작업은 DAG에서 노드로 표시 Edge는 두 작업이 실행되어야 하는 순서를 정의 따라서 DAG는 Airflow에서 실행해야 하는 작업을 정의하고, 어떤 순서로 실행해야 할지를 위해 사용 이 DAG의 구조는 Python 스크립트로 정의되므로, 작업과 해당 종속성 역시 코드로 정의 (스케줄링도 마찬가지) Task는 Python으로 작성되고, Task는 Operators를 구현 Operators는 DAG의 각 작업이 수행하는 작업을 정의하는데 사용 DAG는 다음의 논리 블록으로 구성된 Python 스크립트 (아래 그림과 같음) 라이브러리 불러오기, DAG Arguments, DAG 정의, 태스크 정의, 태스크 파이프라인 https://analyticsmayhem.com/dbt/schedule-dbt-models-with-apache-airflow/ Apache Airflow Scheduler를 사용해서 작업자 배열에 워크플로를 배포할 수 있음 (DAG에서 정한 기준에 따라 작동) Airflow Scheduler 인스턴스를 시작하면, 코드에서 지정한 ‘Start Date’ 기준으로 실행 그 후에 Scheduler는 후속 DAG를 지정한 일정 간격에 따라서 실행 이와 같이 코드로 워크플로를 정의한다는 것은 유지보수, 버전관리, 협업, 테스트의 측면에서 장점을 갖음 task2 &gt;&gt; task3 코드는 task2가 실행된 후, task3가 실행된다는 의미4. Airflow의 UI Airflow 사용자 인터페이스의 랜딩 페이지는 아래와 같고, 기본값은 DAG에 대한 데이터가 포함된 테이블 형태 각 행에는 다음과 같은 환경의 DAG에 대한 대화형 정보가 표시 (DAG 이름, 스케줄, Owner, 최근 태스크 등) https://airflow.apache.org/docs/apache-airflow/1.10.6/ui.html DAG 이름을 클릭하게 되면, ‘Tree View’ 형태로 결과를 아래와 같이 확인할 수 있음 각 실행에 대한 작업의 상태를 타임라인 형태로 보여주고, 기본 날짜와 실행 횟수를 선택할 수도 있음 https://airflow.apache.org/docs/apache-airflow/1.10.6/ui.html 또한 ‘Graph View’ 형태로 결과를 아레와 같이 확인할 수 있음 DAG의 작업과 종속성을 확인할 수 있고, 각 작업은 연산자 유형에 따라 색으로 구분 https://airflow.apache.org/docs/apache-airflow/1.10.6/ui.html5. Airflow Monitoring and Logging 개발자가 작업 상태를 모니터링 하고, 문제를 진단하며 디버깅하기 위해서는 로깅 기능이 필요 Airflow는 Default로 로컬 파일 시스템에 로그 파일들이 저장되어 빠르게 확인 가능 Airflow의 production deployment인 경우, 원격 접속을 위해 클라우드 상에 로그 파일을 보낼 수 있음 로그 파일을 검색 엔진과 대시보드로 보내서 검색 및 분석할 수 있고, 이때는 Elastic Search나 Splunk를 권장 로그 파일의 Default 위치: logs/dag_id/task_id/execution_date/try_number.log Airflow의 Web Server를 통해 UI 형태로도 로그 결과를 확인할 수 있음 구성 요소의 상태를 확인하고, 모니터링 하기 위한 Metrics Counters: 성공 또는 실패한 작업 수와 같이 항상 증가하는 Metrics Gauges: 현재 실행 중인 태스크의 수와 같이 변동 (Fluctuate)할 수 있는 Metrics Timers: 태스크가 성공 또는 실패까지 걸리는 시간과 같이 Time duration과 연관된 Metrics Production 환경에서 Airflow의 Metrics는 수집되고, 전송되며 분석됨 StatsD는 Airflow에서 데이터를 수집하여, Metrics 모니터링 시스템으로 전송할 수 있는 네트워크 데몬 그리고 Prometheus에 전달되어 Metrics를 모니터링하고 분석되며, 대시보드에서 시각화를 할 수도 있음 " }, { "title": "ETL & Data Pipelines with Shell, Airflow and Kafka 2주차", "url": "/posts/Coursera-Data-Engineering-2%EC%A3%BC%EC%B0%A8/", "categories": "Education, Coursera - Data Engineering", "tags": "AI, Deep learning, Machine learning, Data Engineering, Airflow, Kafka, ETL, ELT", "date": "2023-01-27 00:00:00 +0900", "snippet": "이번 글에서는 Coursera의 ETL and Data Pipelines with Shell, Airflow and Kafka (IBM) 2주차 강의를 정리합니다. 이 강좌는 ETL 및 ELT 데이터 파이프라인에 대해 학습하며, Airflow와 Kafka 등을 이용해 이를 배우게 됩니다. 2주차에는 데이터 파이프라인에 사용되는 도구와 기술에 대해 공부하며, Bash 스크립트와 일괄 및 스트림 처리를 배웁니다.1. 데이터 학습 목표 ETL의 각 단계에서 일어나는 일을 요약 ETL 파이프라인의 중요성과 작동 방식 설명 Shell 스크립트를 통해 ETL 파이프라인 구현 방법 요약 주요한 데이터 파이프라인 프로세스 설명 배치 및 스트리밍 데이터 파이프라인에 대해 학습2. Shell 스크립트 Shell은 유닉스 계열 운영 체제를 위한 강력한 사용자 인터페이스 명령을 해석하고, 다른 프로그램을 실행시킬 수도 있음 파일, 유틸리티 및 응용 프로그램에 대한 액세스를 가능하게 하며, 대화식 스크립팅 언어 Shell을 통해 작업을 자동화할 수도 있음 https://hiseon.me/linux/linux-shell-script-example/3. 데이터 파이프라인 데이터 파이프라인 개념은 광범위 하게 적용되는데, 순차적으로 연결된 일련의 프로세스라고 할 수 있음 한 프로세스의 출력은 다음 프로세스에 대한 입력으로 전달 데이터를 이동하거나 수정하는 파이프라인 (데이터를 추출하여 전달하는 시스템) 데이터 파이프라인의 길이는 데이터 파이프라인에 걸리는 시간을 뜻함. 성능과 관련한 고려사항은 다음과 같음 대기 시간: 단일 작업에 걸리는 총 시간 (대기 시간은 개별 시간의 합으로 각 처리 단계에서 소비) 처리량: 단위 시간 당 파이프라인을 통해 얼마나 많은 데이터를 공급할 수 있는지를 뜻함 데이터 파이프라인 프로세스의 공통 단계 하나 이상의 데이터 소스에서 데이터를 추출 추출된 데이터를 파이프라인으로 수집 파이프라인 내에서 선택적으로 데이터 변환 후 최종 로드 실행할 작업을 예약하거나, 트리거를 걸어주는 매커니즘 전체 워크플로 모니터링 및 원활하게 실행 되도록 필요한 유지 관리, 최적화 작업에 걸리는 시간, 시간에 따라 처리되는 데이터 양, 과부하 등으로 인한 오류 및 장애 등 이벤트 로깅 시스템을 통해 특정 이벤트 (오류)가 발생시 관리자에게 알려주도록 함 Load Balanced Pipelines 한 단계가 데이터 패킷에 대한 프로세스를 완료했을 때, 대기열에 있는 다음 패킷을 사용 파이프라인이 작동하는 동안 스테이지를 유휴 상태로 두지 않음 즉, 모든 단계에서 패킷을 처리하는데 동일한 시간이 소요되어야 한다는 것 (병목 현상이 없음) 하지만 시간 및 비용 등을 고려하면, 파이프라인이 완벽하게 로드 밸런싱 되지는 못함 거의 항상 데이터 흐름에서 병목 현상이 있는 단계가 있다는 것 이 병목 현상이 있는 단계를 병렬화할 수 있다면, 속도를 더 높일 수 있을 것 데이터 파이프라인 도구 및 기술 Python의 Pandas 라이브러리 Excel 또는 CSV 스타일의 테이블 형식 데이터 처리 가능 하지만 빅데이터로 확장하는데는 제한적. 데이터 프레임 조작은 메모리 내에서만 가능하기 때문 유사한 라이브러리로는 Vaex, Dask, Spark 등이 있음 Apache Airflow Python 프로그래밍 언어를 기반으로 하는 오픈 소스 데이터 파이프라인 플랫폼 데이터 파이프라인 워크플로를 프로그래밍 방식으로 작성, 예약, 모니터링 가능 AWS를 포함한 대부분의 클라우드 플랫폼과 통합 Talend 또 다른 오픈소스 데이터 파이프라인 개발 및 배포 플랫폼 빅데이터 마이그레이션, 데이터 웨어하우징, 프로파일링 지원 협업, 모니터링, 스케줄링 기능 포함. 그리고 파이프라인을 생성할 수 있는 GUI 존재 AWS Glue 분석을 위해 데이터를 쉽게 준비하고 로드할 수 있음 데이터 소스를 크롤링하여 데이터 형식을 검색 데이터를 저장할 스키마를 제안하고, AWS 콘솔을 이용해 ETL 작업을 빠르게 생성 및 실행 가능 Panoply ETL 보다는 ELT에 초점을 맞추고, 코드 없이 데이터를 연결 및 통합 할 수 있음 SQL 베이스로 데이터를 볼 수 있고, 데이터 파이프라인을 최적화 하는 대신 분석에 집중하도록 함 Tableau나 Power BI 같은 대시보드 및 BI 도구와 통합 가능 Streaming 데이터 파이프라인 도구로는 Storm, Spark, Kafka 등이 있음 4. Batch &amp; Streaming, Micro-batch &amp; Hybrid Lambda 파이프라인 Batch Data Pipeline 데이터를 하나의 큰 단위로 추출하고 운영할 때 사용 주기적으로 작동 (Hours, Days, Weeks 등) 트리거를 기반으로 시작할 수도 있음 (예를 들면, 소스에 누적되는 데이터가 일정 크기에 도달했다면 실행) 최신 데이터에 의존하지 않는 경우, 정확성이 중요한 경우에 적합 주기적인 데이터 백업, 거래내역 로딩, 고객 주문 및 청구 처리, 중장기 매출 예측, 일기 예보 등 Streaming Data Pipeline 데이터 패킷을 연속적으로 빠르게 수집 (예를 들면, 개별 신용 카드 거래, 소셜 미디어 활동 등) 레코드 또는 이벤트가 발생하는 즉시 처리 (거의 실시간으로 작동) 소셜 미디어 피드 및 감성 분석, 사기 탐지, 사용자 행동 분석, 타겟 광고, 주식 시장 거래, 실시간 추천 등 Micro-batch Data Pipeline 배치 크기를 줄이고, 개별 배치 프로세스의 새로고침 빈도를 높여서 실시간으로 처리할 수 있음 로드 밸런싱에 도움이 되어서 전체 지연 시간을 줄일 수 있음 변환 과정에서 매우 짧은 데이터 기간만 필요한 경우에 유용 Batch와 Streaming 방법에서는 Accuracy와 Latency에 대한 Trade-off가 존재 Lambda Architecture 빅데이터를 처리하도록 설계된 하이브리드 아키텍쳐로 Batch와 Streaming 방법을 결합한 것 히스토리 데이터는 Batch layer로, 실시간 데이터는 Speed layer로, 그 후 두 계층이 Serving layer로 통합 정확성과 속도를 목표로 할 때 이 아키텍쳐를 사용 5. 참고 내용 Batch Processing (일괄 처리) 안정적이고 확장 가능한 데이터 인프라를 구축하는 데 중요한 단계 (일괄 처리 알고리즘 MapReduce) 설정된 시간 간격 동안 저장소에 데이터의 묶음(batch)을 로드하며, 일반적으로 사용량이 적은 업무 시간에 예약 대용량 데이터에 대한 작업으로 전체 시스템에 부담을 줄 수 있는 작업이 다른 워크로드에 미치는 영향을 최소화 Streaming Processing (스트리밍 처리) 데이터를 지속적으로 업데이트 해야 할 때 활용 데이터가 생성되는 즉시 연속 스트림을 처리하는 것 (실시간 분석) https://velog.io/@roo333/%EB%B0%B0%EC%B9%98-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8B%B1-VS-%EC%8A%A4%ED%8A%B8%EB%A6%BC-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8B%B1 Load Balancing (로드 밸런싱): 서버에 가해지는 부하 (로드)를 분산 (밸런싱) 해주는 장치 또는 기술 Round Robin 방식: 서버에 들어온 요청을 순서대로 돌아가며 배정하는 방식 Weighted Round Robin 방식: 각 서버마다 가중치를 매겨서, 가중치가 높은 서버에 요청을 우선적으로 배분 IP Hash 방식: 클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식 Least Connection 방식: 요청이 들어온 시점에 가장 적은 연결 상태를 보이는 서버에 우선적으로 배분 Least Response Time 방식: 서버의 현재 연결 상태와 응답시간을 모두 고려하여 트래픽을 배분 https://icarus8050.tistory.com/101 Lambda Architecture (람다 아키텍쳐) Batch Layer: 데이터 조회 요청에 걸리는 시간을 최소화 하기 위해 배치를 이용해 데이터를 미리 계산 Batch Layer의 저장소에서는 Raw 데이터를 보관 Batch 뷰의 데이터가 부정확 할 때 복구 할 수 있음 이 단계에서는 Apache Hadoop을 사용 Speed Layer: 배치가 도는 간격 사이에서는 데이터 조회가 불가능하므로, 배치 레이어에서 생기는 갭을 채움 이 단계에서는 Apache Storm, SQLstream, Apache Spark를 사용 Serving Layer: 배치 레이어와 스피드 레이어의 출력을 저장 https://ok-data.github.io/2020/06/20/Lambda_Arch/" }, { "title": "ETL & Data Pipelines with Shell, Airflow and Kafka 1주차", "url": "/posts/Coursera-Data-Engineering-1%EC%A3%BC%EC%B0%A8/", "categories": "Education, Coursera - Data Engineering", "tags": "AI, Deep learning, Machine learning, Data Engineering, Airflow, Kafka, ETL, ELT", "date": "2023-01-27 00:00:00 +0900", "snippet": "이번 글에서는 Coursera의 ETL and Data Pipelines with Shell, Airflow and Kafka (IBM) 1주차 강의를 정리합니다. 이 강좌는 ETL 및 ELT 데이터 파이프라인에 대해 학습하며, Airflow와 Kafka 등을 이용해 이를 배우게 됩니다. 1주차에서는 데이터 처리 기술에 대해 공부하며 ETL과 ELT 개념을 학습하고, 둘의 차이는 무엇인지에 대해 알아봅니다. 또한 ETL에서 ELT로 변화하게 되는 이유 등에 대해서도 학습할 수 있습니다.1. 데이터 학습 목표 ETL 프로세스가 어떠한 것인지 학습 ELT 프로세스가 왜 최근 등장하고 있는 트렌드인지 학습 데이터를 Extraction 하고, Loading 하는 방법을 학습 Batch Loading과 Stream Loading에 대해서 학습2. ETL과 ELT ETL (Extraction, Transformation, Loading) ETL은 데이터를 수집하고, 준비하는 자동화 된 데이터 파이프라인 엔지니어링 방법론. 이를 통해 향후 데이터 웨어하우스나, 데이터 마트 같은 분석 환경에서 사용할 수 있도록 도움. 즉, 여러 소스의 데이터를 큐레이팅 해서 통합된 데이터에 맞추는 프로세스 Extration: 하나 이상의 소스에서 데이터를 읽거나 얻는 과정 데이터에 대한 액세스를 구성하고, 애플리케이션으로 읽는 것 (일반적으로 자동화 되어 있음 - 크롤링 등) Transformation: 데이터를 의도된 용도에 맞게 변환하는 과정 (Data Wrangling) Cleaning, Filtering, Joining, Feature Engineering, Formatting and data typing 등 Loading: 변환된 데이터를 가져와 새 환경에 로드하는 과정 (데이터베이스, 데이터 웨어하우스, 데이터 마트) 이 과정의 핵심 목표는 수집된 데이터를 쉽게 사용할 수 있도록 하는 것 (대시보드, 리포트 등에 활용) ELT (Extraction, Loading, Transformation) ELT는 ETL과 유사하지만, 순서가 조금 다른 데이터 파이프라인 엔지니어링 방법론. ELT는 데이터가 수집된 그대로 대상 환경에 직접 로드하고, 데이터 레이크 환경 등에서 사용자가 원하는대로 변환해서 사용하게 됨. Extraction: 데이터를 얻는 과정 Loading: Raw data를 있는 그대로 사용하여 로드하는 과정 Transformations: 사용자의 의도 및 요구대로 데이터를 변환시키는 과정 https://www.integrate.io/ko/blog/etl-vs-elt-5-critical-differences-ko/ ELT 방법이 등장하게 된 이유로는 빅데이터를 다루는 과정에서 빠르게 발전하고 있는 Cloud computing을 통해 ELT 방법론으로 데이터 이동과 처리를 면확히 구분할 수 있음. 또한 Raw 데이터를 적재한 후, 작업하기 때문에 정보 손실이 없다는 점도 장점 중 하나 ETL과 ELT 비교: 최근에는 ETL에서 ELT로 변화되고 있는 추세 ETL에서의 변환은 파이프라인 내에서 발생하는데, ELT에서는 파이프라인과 분리되어 동작. 따라서 ELT 방법에서는 Raw data 자체를 보호하며, 필요에 따라 데이터를 변환시켜 사용할 수 있음 ETL은 고정적인 프로세스이지만, ELT는 유연성을 가지고 있다는 특징이 있음 ETL에서는 전통적으로 구조화 된 관계형 데이터를 처리하기 때문에 확장성 등에서 문제가 발생할 수도 있는데, ELT에서는 모든 종류의 구조화 및 비구조화 데이터를 처리할 수 있음 ETL 파이프라인은 수정하는데 시간과 노력이 필요하지만, ELT에서는 더 민첩하게 대처할 수 있음 3. 데이터 Extraction 기술 OCR: 종이 문서 등에서 텍스트를 스캔 ADC Sampling: 아날로그 오디오 녹음 및 신호를 디지털화 CCD Sampling: 이미지를 캡쳐하고 디지털화 이메일, 휴대폰, 설문 등을 통해 얻은 통계 데이터 및 사용자 로그, 쿠키 웹 크롤링, API, 데이터베이스 쿼리 Edge computing, 의료기기를 통한 데이터 획득4. 데이터 Transformation 기술 응용 프로그램에 맞게 데이터 형식을 지정하는 과정 Data typing, Data structuring (JSON, XML, CSV) Anonymizing, Encrypting (암호화 및 익명화) Cleaning, Normalizing, Filtering, Sorting, Aggregating, Binning, Joining Schema-on-write는 ETL에서 사용되는 일반적 접근으로, 로드하기 전에 정의된 스키마를 준수해야 하는 것. 안전성 있게 데이터를 일관되게 구조화할 수 있지만, 다양성을 제한할 수도 있음 Schema-on-read는 ELT 접근 방식과 관련 있고, 여기서 스키마는 Raw data에 적용. 엄격한 절차가 없기 때문에 잠재적으로 더 많은 데이터에 접근할 수 있음 일반적으로 Raw data는 변환된 데이터보다 훨씬 큰데, ETL에서는 변환 과정에서 일부 데이터를 손실하게 될 수 있음. 하지만 ELT에서는 데이터를 그대로 복사하여 정보를 손실시키지 않음5. 데이터 Loading 기술 Full: 초기 기록 전체를 데이터베이스에 로드. 하나의 큰 배치로 데이터를 로드 Incremental: 새로운 데이터를 삽입하거나, 이미 로드된 데이터를 업데이트 Scheduled: 주기적으로 데이터 로드를 예약 On-demand: 요청 시, 필요에 따라 데이터 로드 Batch and Stream: 데이터를 일괄적으로 로드하거나, 스트리밍 (실시간 처리) Push and Pull: 데이터가 서버로 푸시되거나, 서버에서 클라이언트로 푸시 Parallel and Serial: 병렬 로드, 직렬 로드6. 참고 내용 Data Warehouse (DW): 의사결정에 도움을 주기 위해 분석 가능한 형태로 변환된 데이터가 저장된 중앙 저장소 Data Lake: 사전에 정의된 구조 없이 방대한 양의 원시 데이터가 그대로 저장 (모든 데이터에 대한 중앙 리포지토리) Data Mart: 영업, 재무, 마케팅 등 단일 주제 등에 중점을 둔 단순한 형태의 데이터 웨어하우스 https://www.altexsoft.com/blog/what-is-data-mart/ 데이터 파이프라인을 통해 순차적으로 공급되거나 파이프 되는 데이터의 패킷 이상적으로는 세 번째 패킷이 수집이 될 때까지 세 개의 ETL 프로세스가 모두 서로 다른 패킷에서 동시에 실행 강의 자료 워크플로의 세부 사항을 개별 작업 사이의 종속성으로 분류하게 되면, 복잡성을 제어할 수 있음 Apache Airflow 같은 워크플로 오케스트레이션 도구가 이러한 역할을 수행 Airflow는 DAG (Directed Acyclic Graph)로 워크플로를 나타냄 (그림 참고) Airflow 작업은 연산자라고 하는 미리 정의된 템플릿을 사용하여 표현 이 연산자에는 Bash 실행을 위한 Bash 연산자와 Python 실행을 위한 Python 연산자가 포함 그렇기 때문에 ETL 파이프라인 및 기타 여러 종류의 워크플로를 프로덕션에 배포하는데 유용 아래 그림에서 녹색 상자는 개별 작업을 나타내고, 화살표는 작업 간의 종속성을 나타냄 강의 자료" }, { "title": "LG Aimers 2기 시계열 분석 (고려대학교 강필성 교수님)", "url": "/posts/LG-Aimers-%EC%8B%9C%EA%B3%84%EC%97%B4-%EB%B6%84%EC%84%9D/", "categories": "Education, LG Aimers 2기", "tags": "AI, Deep learning, Machine learning", "date": "2023-01-25 00:00:00 +0900", "snippet": "이번 글에서는 LG Aimers의 AI 전문가 과정에서 시계열 데이터의 순차적 특성을 고려한 모형과 그 학습 원리를 배웁니다. 모형의 어떠한 특성이 시계열 데이터의 특성을 학습에 반영하게 되는지 그리고 어떻게 모델의 성능을 향상시킬 수 있는지를 배울 수 있습니다.1. 순환신경망 기반의 시계열 데이터 회귀Non-Sequential vs Sequential (Time-Series) Data Non-Sequential Data: 시간 정보를 포함하지 않고 생성되는 데이터 순차 데이터가 아닌 경우, 데이터는 N by D 행렬로 표현 (N: 관측치 수, D: 변수 수) (예) 특정 고객의 금융 상품 이용 현황으로 대출 상품 추천 (X: 고객별 금융 상품 이용 현황, Y: 대출사용 유무) 순서가 없는 인공신경망 구조: x -&gt; h -&gt; y Sequential Data: 시간 정보를 포함하여 순차적으로 생성되는 데이터 순차 데이터의 경우, 데이터는 (N) by T by D Tensor 로 표현 (T는 측정 시점 수) (예) 반도체 공정에서 주기적으로 측정되는 여러 센서 값을 이용한 Critical Dimension 예측 순서가 있는 인공신경망 구조: x -&gt; h (과거 정보를 누적시켜서 다시 재학습, Recurrent 형태) -&gt; y RNN Basics: Forward Path 기본 RNN (Vanilla RNN) 구조에서 정보의 흐름 t 시점에서의 은닉 노드의 값은 두 부분에서 영향을 받게 됨 첫번째는, t-1 시점까지 은닉 노드에 저장된 정보 두번째는, t 시점에서 새롭게 제공되는 입력 정보 RNN Basics: Gradient Vanishing, Exploding Problem RNN에서의 Backpropagation에서 활성화 함수는 Tanh로 가정 순전파를 통해서 모델이 얼마나 틀렸는지를 확인한 후, Cost 함수를 사용하여 역전파를 수행 그래서 가장 현재 입력과 출력 간의 쌍들을 잘 맞출 수 있는 가중치 행렬을 구하게 됨 (역전파 목적) 이를 일반화시켜서 표현하면, (1 - tanh^2(z_t)) * x_t 그런데, 1 - tanh^2(x)의 값은 값이 양 또는 음의 값으로 발산할 때, 값이 0으로 수렴 즉, 특정한 값을 벗어나게 되면, Gradient 값이 소실되는 문제가 발생한다는 것 이를 해결하기 위해, LSTM과 GRU 방식이 등장 RNN Hidden Unit: LSTM (Long Short-Term Memory) Gradient exploding, vanishing 문제를 해결하여 Long-term dependency 학습 가능 Vanilla RNN은 Input이 주어지고, 이전 시점에서의 은닉층 (Hidden State)의 정보가 주어지면 이 두 개를 한 번 연산하고, 다음 State로 내보내게 되고 (Concatenate), 이것이 다음 시점의 Output으로 만들어짐 LSTM은 Cell state라고 하여 각 시점마다 Cell state가 존재하고, 모델 상부를 관통하는 선의 모양 Vanilla RNN은 주기억장치 하나만 있는데, LSTM은 주기억장치와 보조기억장치가 함께 있어서 보조기억장치의 역할을 잘 개선시켜서 과거에 멀리 떨어져 있던 정보들을 잘 기억하고, 선택적으로 반영할 수 있게 해주는 것LSTM Process Step 1. 지금까지 Cell state에 저장된 정보 중 얼마만큼 망각 (Forget) 할 것인지 결정 Forget gate: 이전 단계의 Hidden state h_t-1과 현 단계의 입력 x_t로부터 0과 1 사이값 출력 (시그모이드) 1: 지금까지 Cell state에 저장된 모든 정보 보존 0: 지금까지 Cell state에 저장된 모든 정보 무시 이전 단계의 결과와 현 단계의 입력을 Concatenate 하고, 모델의 파라미터 (W_f)를 통해 지금까지 저장된 정보가 얼마나 유용한지 현재 시점에서 유용한지 판단 (1 또는 0으로 결과값을 반환) Step 2. 새로운 정보를 얼마만큼 Cell state에 저장할 것인지를 결정 Input gate: 어떤 값을 업데이트 할 것인지를 결정 고정적으로 결정하는 것이 아닌, 그때 그때 시점 별로 Data에 따라 Adaptive 하게 결정되는 것 Tanh layer를 사용하여 새로운 Cell state의 후보를 생성 후보를 생성하는데 있어서 필요한 데이터는 이전 시점의 Hidden state와 현 시점의 입력 정보 Step 3. 예전 Cell state를 새로운 Cell state로 업데이트 예전 Cell state를 얼마만큼 망각할 것인가를 계산한 Forget gate 결과값과 곱합 새로운 Cell state 후보와 얼마만큼 보존할 것인가를 계산한 Input gate 결과값을 곱합 두 값을 더하여 새로운 Cell state 값으로 결정 즉, 과거부터 지금까지 이만큼의 정보를 저장했고, 현재는 이 정도의 정보를 새로 받았는데, 그 과거 정보를 얼마만큼 보존하고, 현재 정보를 얼마만큼 반영해야 하는지를 데이터를 기반으로 학습으로 결정하는 것 Step 4. 출력 값을 결정 이전 Hidden state 값과 현재의 입력 값을 이용하여 Output gate 값을 산출 Output gate 값과 현재의 Cell state 값을 결합하여 현재의 Hidden state 값을 계산 Vanilla RNN은 W_xh, W_hh, W_hy 라는 세 가지 가중치 행렬을 사용하여 학습 LSTM은 W_f, W_i, W_c, W_o 라는 네 가지 가중치 행렬을 학습시켜야만 작동 또한 LSTM의 입력 값은 이전 Hidden state 값과 현재의 입력 값 (h_t-1, x_t)을 Concatenate 한 것 Vanilla RNN이 먼 시점에서 정보를 기억하지 못해서 보완하게 된 LSTM 방법론RNN Hidden Unit: GRU (Gated Recurrent Unit) LSTM을 단순화 한 구조. 실제 활용에서는 LSTM과 GRU의 성능 차이는 미비함 GRU가 LSTM에 비해 상대적으로 단순하기 때문에 GRU -&gt; LSTM 순서로 적용하는게 일반적 순서 별도의 Cell state가 존재하지는 않음 LSTM의 Forget gate와 Input gate를 하나의 Update gate로 결합 Update gate는 현재 정보를 얼마만큼 많이 반영해 줄것인가를 결정하는 부분 Reset gate를 통해 망각과 새로운 정보 업데이트 정도를 결정 Reset gate는 과거의 정보를 얼마만큼 덜 반영하거나, 더 반영하는지를 연산해주는 부분 RNN Variations: Bidirectional RNN Bidirectional RNN (양방향 순환신경망): 정보의 입력을 시간의 순방향과 역방향 관점에서 함께 처리 (번역기 예시) Deep-Bidirectional RNN: RNN의 Hidden layer가 한 층일 필요가 없이, 더 쌓아보는 접근법 (CNN처럼) 단, CNN과는 다르게, RNN은 층을 여러 개 깊게 쌓는다고 해서 성능의 향상을 보장하지는 않음 경험적으로도 쌓지 않거나, 아니면 최대 두 개에서 네 개 층 정도만 쌓는 것이 Maximum 층이 될 것 RNN: Attention 어느 시점 정보가 RNN의 최종 출력 값에 영향을 미치는지를 알려줄 수 있는 매커니즘 Bahadanau attention (2015): Attention 매커니즘을 구현하기 위해 별도로 다시 모델을 학습함 Luong attention (2015): 별도로 학습하지 않아도, Attention score를 산출할 수 있어서 이 방법론을 더 선호함 일반적인 Vanilla RNN에서는 각 시점 별로 Hidden state의 정보가 전달되고, 가장 마지막 층에서 최종적인 예측값을 도출하는데, Attention 방법에서는 가장 마지막의 Hidden state 정보와 첫번째 Hidden state와의 알파값이라는 유사도 (기여도)를 산출함. 그리고 각 Hidden state 마다 유사도 (기여도) 값을 산출한 후, 과거에 한 번 사용된 Hidden state 값을 버리는 것이 아닌 그 값과 알파값과의 선형 결합을 통해 C라고 하는 Context vector를 만듦. 최종적으로 이 값과 가장 마지막 시점에서의 Hidden state vector를 결합하여 h 틸다라는 새로운 Hidden state vector를 만들고, 이 값을 통해서 최종적인 예측을 수행 이를 통해, Attention 구조를 차용하지 않았을 때에 비해 성능이 훨씬 향상되는 것이 일반적. 또한 알파값이 결국 0부터 1 사이이면서 모든 알파들의 값을 더했을 때는 1이 나오기 때문에, 이 예측 과정에서 몇 번째 시점이 가장 중요한 역할을 수행했는지를 추론할 수 있음 알파_i 값은 i번째 Hidden state vector가 Context vector 생성에 기여하는 비중 두 Hidden state vector 사이의 Score 산출 방식 중 가장 간단한 방식은 두 벡터의 내적을 사용하는 것 알파값이라고 하는 유사도 (기여도)가 산출이 되면, Context vector는 단순히 지금까지 계산을 해왔던 각 시점들의 Hidden state vector와 알파와의 선형 결합 Vanilla RNN, LSTM, GRU 모두는 중간 시점에 해당하는 Hidden state h들의 정보는 버려지고, 마지막만 사용 Attention을 활용하게 되어 중간 시점에 해당하는 Hidden state vector도 다시 한번 의사결정에 활용 이렇게 Context vector를 만든 후, h 틸다라고 하는 새로운 Hidden state vector는 가장 마지막 시점의 Hidden state와 Context vector를 Concatenate 하고, 학습 대상이 되는 가중치를 곱한 후, 비선형 활성화를 통해 만들어지게 되고, 최종 예측을 수행Summary 순환신경망은 순차 데이터를 처리하는데 특화된 인공신경망 구조 현 시점에서 Hidden state (H_t)는 이전 시점의 Hidden state (H_t-1)와 현 시점의 입력 (x_t)를 이용해 계산 Vanilla RNN은 Long-term relationship을 파악하는데 어려움을 겪어서 LSTM, GRU가 등장 LSTM은 Input, Forget, Output gate와 Cell state를 활용하여 정보를 선택적으로 활용 GRU는 Reset, Update gate 만을 사용하여 LSTM 보다 단순화 된 구조 Attention은 시계열 데이터의 어느 시점이 최종 예측에 영향을 미쳤는지 판별할 수 있는 기법. 일반적으로 Attention 구조가 그렇지 않은 구조보다 일반적으로 예측 성능이 우수한 경향이 있음2. 합성곱 기반의 시계열 데이터 회귀 합성곱 즉, CNN 구조는 이미지 데이터를 처리하기 위해 고안된 구조 이 모델을 시계열 데이터에 적용했을 때도 효과적이었음 합성곱 신경망: 합성곱 연산을 통해 이미지로부터 필요한 특질 (Feature)을 스스로 학습할 수 있는 능력을 갖춘 신경망 이미지 인식 종류: Classification, Classification + Localization, Object Detection, Instance Segmentation Classification: 주어진 이미지에서 어떤 객체가 있는지 분류하는 것 Classification + Localization: 어떤 객체가 어디에 있는지 Bounding box로 표현까지 해주는 것 Object Detection: 여러 객체에 대하여 Classification + Localization을 수행 Instance Segmentation: Object Detection을 pixel 단위로 수행하는 것 (Polygon 생성) CNN Basics: Image Representation 이미지를 어떻게 컴퓨터에게 숫자로 인식시킬 것인가? 컬러 이미지는 3차원의 Tensor로 표현됨 (Width * Height * 3 (RGB)) 문제점: 모든 픽셀 하나의 입력 노드로 간주하고, 서로 다른 가중치로 연결하면 Input layer와 First hidden layer에 너무 많은 학습을 시켜야 하는 weights (가중치)가 생김 이 단계에서 필요한 가중치 수: 1685 * 2247 * 3 * 첫번째 Hidden layer의 노드 수 CNN Basics: Convolution Image Convolution (Filter, Kernel): 특정 속성을 탐지하는데 사용하는 Matrix (예를 들면, Edge detection)Convolutional Neural Network (CNN) 합성곱 신경망: 합성곱 연산을 통해 이미지로부터 필요한 특질을 스스로 학습할 수 있는 능력을 갖춘 심층 신경망 이미지 데이터가 갖는 특징: 인접 픽셀 간 높은 상관관계 (Spatially-local correlation), 이미지의 부분적 특성은 고정된 위치에 등장하지 않음 (Feature invariance) Spatially-local correlation을 고려하기 위해 Sparse connection 구성 Sparse connection: 전체 픽셀이 아닌 일부 픽셀만 가중치로 연결하여 연산 수행 인접한 변수만을 이용하여 새로운 Feature 생성 Invariant feature를 추출하기 위해 Shared weight 개념 이용 Shared weight: 동일한 필터는 대상 영역에 상관없이 같은 가중치를 사용하여 연산을 수행 특정 특질을 추출하기 위한 도구로서 같은 대상 크기에는 위치가 다르더라도 동일한 Weight 적용 CNN의 작동 과정 일반적인 CNN은 Convolution 연산, Activation 연산 (대부분 ReLU), Pooling 연산의 반복으로 구성 일정 횟수 이상의 Feature Learning 과정 이후에는, Flatten 과정을 통해 이미지가 1차원 벡터로 변환 이미지는 3차원 Tensor (RGB) 이므로, 필터 역시도 3차원 Filter가 한번에 한 칸씩 이동하면, 시간이 오래 걸리지 않을까? Stride를 통해 한번에 여러 칸 이동하도록 함 가장자리에 있는 픽셀은 중앙의 픽셀보다 합성곱 연산이 적게 수행되지 않을까? Padding을 추가하여 이를 보완 최종적인 Output size는 Stride와 Padding 값에 따라 달라질 수 있음 Output size = ((H + 2P - F / S) + 1) * ((W + 2P - F / S) + 1) CNN Basics: Activation 합성곱을 통해 학습된 값들의 비선형 변환을 수행 (대부분 ReLU를 사용) 선형 변환만 하게 되면, 아무리 복잡한 구조로 조합해도 선형 조합의 결과는 선형 결과가 도출 대부분 Rectified Linear Unit (ReLU)을 사용 0보다 작은 값들은 0으로 변환하고, 0보다 큰 값들은 그 값을 반환 CNN Basics: Pooling 문제점: 고차원의 Tensor를 보다 Compact 하게 축약해야 하지 않을까? Pooling: 일정 영역의 정보를 축약하는 역할 (Max pooling, Average pooling) Strided convolution: Average pooling은 Strided convolution의 특수한 케이스 (모든 weight가 1/n)CNN Basics: Flatten 평탄화 (Flatten): 2차원, 3차원의 Matrix, Tensor 구조를 1차원의 Vector로 변환하는 과정CNN: 하이퍼파라미터 Convolution filter의 크기: 이미지 데이터에는 주로 2-d Convolution을 사용 (가로와 세로의 크기가 같음) Convolution filter의 수: 이 수가 많을수록 동질 영역에서 다양한 형태의 특질을 추출할 수 있음 Stride의 크기: Conv filter가 건너뛰는 픽셀의 수. Stride가 작을수록 촘촘하게 특질을 추출하지만 시간 오래 걸림 Zero Padding 크기: Conv 연산의 편의성을 위해 사용. Conv 연산 전후의 크기를 일치시키기 위한 목적 Filter와 Stride의 크기에 따라서 필요한 Padding의 크기가 결정 CNN Architecture 1: AlexNet 원본 이미지가 너무 크게 되면, 연산량이 부족했기 때문에 이미지를 Resize (224 * 224 차원 * 3 (RGB)) Filter의 크기는 11 * 11 차원, Stride는 4, Filter의 개수는 96개 (Output 사이즈는 55 * 55) 초반에는 넓게 보되 듬성듬성 보고, 후반부에는 좁게 보되 세밀하게 보자 그 다음 Conv 연산에서는 Max pooling 후, Filter의 크기는 5 * 5 차원으로, 개수는 256개로 늘림 그리고 Max pooling 후, 3 * 3 Filter 384개로 적용 촘촘하게 보되, 특질을 찾아낼 수 있도록 Filter의 개수를 증가시킴 총 5번의 Conv 연산 후, 13 * 13 * 256 차원의 Tensor를 Flatten 하여 4096차원의 Dense layer로 변환 최종적으로 정리하면 다음과 같음 224 * 224 크기의 이미지를 Input으로 사용 초기 단계에서는 큰 필터 사이즈와 Stride를 사용 상위 Layer로 갈수록 작은 필터 사이즈와 Stride를 사용 2개의 Fully connected layer 존재 파라미터의 총 개수: 60 Million CNN Architecture 2: VGGNet 원본 이미지는 24 * 24 * 3 차원의 Tensor인데, 64 차원의 Filter로 Conv 연산 두 번 수행 그리고 Max pooling 후, 128 차원의 Filter로 Conv 연산 두 번 수행 그 후, Max pooling 후, 사이즈를 줄여서 256 차원의 Filter로 Conv 연산 세 번 수행 최종적으로 정리하면 다음과 같음 AlexNet에 비해서 단순하지만 깊은 구조 3 by 3 Convolution with stride 1을 기본 연산으로 하며, 중간 중간에 2 by 2 max pooling을 수행 파라미터의 총 개수: 138 Million CNN for Time-Series Data Time-Series Data의 가정은 모든 변수는 동일한 주기 (초, 분, 시간 등)로 수집되고 있음 Task 1 (분류): 특정 기간 (제품 가공 기간) 데이터를 입력으로 하고, 특정 범주를 출력으로 하는 모델 (양/불 판정 등) Task 2 (회귀): 특정 기간 데이터를 입력으로 하고, 특정 수치 (품질 지표)를 출력으로 하는 모델 Task 1, 2는 Input인 X 데이터는 동일하지만, Output인 Y 데이터의 형태가 다름 Task 3 (회귀): 일부 기간 데이터를 입력으로 하고, 이후 기간 데이터를 예측 (태양광 발전량 예측, 전력 소모 예측 등) Task 4 (이상탐지): 일부 기간 데이터를 입력으로 하고, 해당 상황의 정상 및 비정상 여부를 탐지 1-D Convolution vs 2-D Convolution 시계열 데이터는 이미지 데이터와 달리, 변수들 사이에 Spatial Correlation이 존재하지 않음 시간 축으로 움직이는 Convolution은 의미가 있지만, 변수 축으로 움직이는 Convolution은 의미가 없음 2-D Convolution은 시간과 변수 두 축을 모두 Convolution 연산을 통해서 탐색하는 방식 1-D Convolution은 모든 변수를 한번에 고려하여 시간 축에 대해서만 Convolution 연산을 수행 따라서 Filter의 크기가 정사각형이 아닌, 직사각형 형태의 Filter를 사용. 즉, 이것은 모든 변수를 한꺼번에 고려하여, 시점에 대해서만 이동을 시키는 것 Filter의 세로 크기는 변수의 개수만큼 고정이 될 것 (이미지 CNN과의 차이) 1-D Convolution에서 1개의 Filter를 사용하면 1개의 Vector가 결과물로 산출 이와 같은 Conv 연산을 반복하면, 각 Vector 상의 같은 인덱스는 같은 Time-series에 대한 데이터 Dilated Convolution 의문: 보다 긴 길이의 시계열 데이터를 효율적으로 처리할 수는 없을까? Standard Convolution은 항상 인접한 연속된 시점의 데이터에 대한 합성곱 연산을 수행 합성곱 연산을 조금 더 띄엄띄엄 해본다면? Summary 합성곱 연산은 Feature Invariance와 Spatial Correlation을 반영하기 위해 사용되는 연산 이미지를 처리할 때는 정방형의 필터를 사용하여 가로, 세로 두 방향으로 움직이는 2-D 합성곱 연산을 사용 반면, 시계열 데이터에서는 변수 축으로 필터가 이동하는 것은 의미가 없어 필터의 한쪽 크기는 변수의 개수와 같음 그리고 시간 축으로만 움직이는 1-D 합성곱 연산을 수행하도록 함 합성곱 연산은 한 레이어에서만 적용하는 것이 아닌, 반복적으로 쌓아 올려서 사용할 수도 있음 보다 긴 길이의 시계열 데이터를 한번에 처리하기 위해서는, Standard Convolution 보다는 중간 지점을 생략하는 Dilated Convolution을 사용하면 보다 효율적인 정보의 처리가 가능3. 트랜스포머 기반의 시계열 데이터 회귀 앞서 배운 CNN은 원래 이미지 데이터를 처리하기 위해 제안되었으나, 시계열 데이터에 적용한 것 RNN은 원래부터 시계열 데이터나, 순차 데이터를 처리하기 위해 만들어진 방법론 Transformer는 원래 자연어 데이터를 처리하기 위해 만들어진 모델이지만, 이 모델이 이미지와 시계열으로도 확장 Transformer는 언어 모델의 한 종류 언어 모델은 특정 문장 (단어의 나열)이 등장할 확률을 계산해주는 모델 즉, 특정한 언어에서 특정한 문장 즉, 단어의 나열이 얼마나 그럴듯하고 자연스러운지 확률을 계산해주는 모델 Transformer는 Attention의 병렬적 사용을 통해 효율적인 학습이 가능한 구조의 언어 모델 개괄적 구조: 내부에 인코더 파트와 디코더 파트가 존재하며, 이 둘 사이를 이어주는 연결고리가 존재함 Input 데이터를 처리하는 Encoder 모듈과 처리가 완료된 다음 단어를 하나씩 반환해주는 Decoder 모듈이 있음 Encoder는 여섯 개의 블록으로 구성되어 있고, Decoder도 역시 여섯 개의 블록으로 구성됨 입력 데이터가 들어왔을 때, Encoder는 층층이 이전 단계에서 다음 단계로 정보가 전달 Decoding 과정에서는 가장 마지막 단계에서의 Encoder가 모든 단계의 Decoder에 정보를 전달하고, 하위 Decoder의 정보가 상위 Decoder로 정보를 전달해주는 구조 Transformer의 작동 원리 개별 단어에 대한 임베딩 벡터 (Word2Vec, GloVe 등)를 최초 입력으로 사용함 Word2Vec, GloVe 등의 방법론은 실제 단어에서 두 단어가 의미적으로 유사하면, 공간상에서도 유사하도록 학습 이 단어 임베딩은 가장 아래에 위치한 인코더에서만 입력으로 1회 사용 나머지 인코더들을 하위 인코더에서 출력된 결과물을 입력으로 사용 최초 논문에서는 512 차원의 임베딩을 사용 입력으로 사용되는 리스트는 사용자가 지정하는 하이퍼파라미터 - 컴퓨팅 자원이 충분하다면 큰 값 지정 가능 Positional Encoding Transformer는 단어를 순차적이지 않고, 한번에 받아서 입력 시퀀스에서 단어들 간의 위치 관계를 표현해야 함 RNN 구조에서는 단어를 순차적으로 받았던 것과 약간 차이가 있음 따라서 Transformer에서는 입력 시퀀스에서 어떤 단어가 먼저 들어왔고, 나중에 들어왔는지 확인 필요 이 역할을 수행하도록 Positional Encoding을 만들고, 모든 단어 임베딩에 이것을 더해 입력 벡터를 구성함 Multi-Head Attention 어떤 토큰들을 받았을 때, 그 문서 안에서 또는 문장 안에서 단어들이 서로 어떤 연관관계를 가지는지 해석하는 것 Positional Encoding이 더해진 단어 임베딩은 첫 번째 인코더 블록에서 Self-Attention과 FFNN을 거침 특정 위치의 단어는 해당 위치를 유지하면서 연산이 수행 Self-Attention 과정에서는 이 경로간 의존성이 존재 FFNN (Feed Forward Neural Network) 과정에서는 의존성이 존재하지 않아서 병렬화가 가능 Encoding Procedure 인코더는 일련의 벡터들을 입력으로 받음 입력된 벡터들은 Self-Attention과 FFNN을 거쳐서 상위 인코더의 입력으로 투입 즉, Encoder 1의 Output은 Encoder 2의 Input으로도 활용된다는 것 Self-Attention에 대한 이해 The animal did’t cross the street because it was too tired. 이와 같은 문장에서 it이 해당하는 의미를 사람은 알기 쉽지만, 알고리즘은 그렇지 못함 이는 입력 시퀀스의 다른 위치에 있는 단어를 둘러보면서, 특정 위치의 단어를 잘 설명 및 표현 할 수 있게 함 Self-Attention의 절차 Step 1. 입력 벡터에 대해서 세 가지의 벡터를 생성 실제로는 Query, Key, Value에 대응하는 행렬을 곱해서 생성 Query: 다른 단어들을 고려하여 표현하고자 하는 대상이 되는 현재 단어에 대한 임베딩 벡터 어떤 단어가 다른 단어들과 무슨 관계가 있는지를 알고싶은 질의 대상이 되는 단어 Key: Query가 들어왔을 때, 다른 단어들과 매칭을 하기 위해 사용되는 레이블로 사용되는 임베딩 벡터 Value: Key와 연결된 실제 단어를 나타내는 임베딩 벡터 Step 2. 지금 표현하고자 하는 단어 (Q)에 대하여 어떤 단어를 고려해야 하는지 (K)를 알려주는 스코어 산출 Q와 K를 곱한 후, 소프트맥스 함수를 취하여 이 스코어를 계산해줌 Step 3. Step 2에서 계산한 스코어를 차원의 루트 수로 나눠줌 이 과정을 통해 Gradient 전파가 보다 안정적으로 수행됨 Step 4. Step 3의 결과를 이용하여 소프트맥스 함수를 적용해 해당 단어에 대한 집중도를 산출 Step 5. Step 4에서 산출된 확률값과 해당 단언의 Key 값을 곱함 Step 6. Step 5에서 산출된 모든 값들을 더해서 출력으로 반환 Masked Multi-head Attention 디코딩 단계에서 셀프 어텐션은 Query 토큰보다 뒤에 위치한 토큰들에 대한 정보는 가용하지 않다고 가정하고, 해당 부분을 전부 Masking 처리 순차적으로 수행할 필요 없이 한번에 수행 가능 The Final Linear and Softmax Layer Linear layer: 단순 FFNN 형태로서 마지막 디코더의 출력 결과물을 이용해 모든 단어의 출력 확률을 산출하기 위해서 차원을 늘려주는 역할을 수행 Softmax layer: 개별 단어들의 출력 확률값을 반환 Transformer의 시계열 데이터 적용 Transformer를 다변량 시계열 데이터에 최초로 적용한 논문 Transformer의 Encoder 구조만을 사용 Pre-training 과업을 위하여 연속적 길이의 Input masking 사용 Layer Normalization 대신 Batch Normalization 사용 Fine-tuning 단계에서 구조를 어떻게 설계하느냐에 따라 분류, 회귀, 예측 등 다양한 테스크에 적용 가능 Time-Series Transformer (TST) 작동 원리 TST는 크게 Pre-training과 Fine-tuning의 두 부분으로 구분 Pre-training은 데이터를 통해 이 Transformer의 구조를 미리 학습하는 것 Fine-tuning은 원하는 문제를 잘 풀 수 있도록 고도화하는 단계 입력 데이터 변환 원본 입력 데이터 X는 m개의 변수와 w개의 Time window length를 가짐 Pre-training 과정에서는 이 중 일부를 Masking 한 뒤, Transformer의 Input이 되는 d차원으로 변환 Fine-tuning 과정에서는 Masking 없이 d차원으로 변환 입력 데이터 Masking Transformer의 사전 학습 목적은 Masking 된 부분을 정확하게 예측하는 것으로 설계 각 Cell에 대한 Masking 여부를 독립적으로 결정하게 되면, Trivial Solution으로도 문제를 잘 맞춤 Trivial Solution은 Masking 된 Cell 이전 시점 혹은 이후 시점 값을 그대로 사용하거나, 평균값 사용 Masking 길이가 평균만큼이 되는 기하 분포를 따르도록 Markov Chain을 적용하여 Masking 여부 결정 모든 변수에 대해 동일한 시점을 Masking 하는 것보다 변수 별로 독립적으로 Masking segment를 결정하는 것이 실험적으로 더 우수한 성능을 보였음 Positional Encoding NLP의 Transformer처럼 TST에서도 입력 데이터에 이것을 더해 Transformer 인코더의 입력값으로 사용 고정된 Positional Encoding을 사용할 수도 있고, 학습 가능한 Positional Encoding을 사용할 수도 있음 Self-Attention in Transformer Encoder Block 총 3개의 Encoder 블록을 사용 (자연어에서는 6개를 사용했음) NLP에서의 Transformer와 다르게 Layer Normalization 대신 Batch Normalization 사용 시계열 데이터는 NLP Word Embedding에는 없는 이상치가 존재 시계열 데이터는 각 관측치의 길이 변화가 NLP의 문장 길이의 변화보다 작음 이러한 상황 하에서는 실험적으로 Batch Normalization이 우수한 성능을 보이는 것으로 입증 Pre-training 각 관측치 및 Epoch 마다 독립적으로 생성한 Mask를 Input과 Element-wisse Multiplication 하여 Masked Input을 도출 이것을 Input Encoding과 Transformer Encoder에 순차적으로 넣어서 Latent Representation을 도출하고, 이를 Linear Output Layer에 넣어서 모든 값이 채워져 있는 각 시점의 데이터를 예측 Masking 된 부분의 실제값과 예측값의 Mean Squared Error를 기반으로 모델을 학습 Fine-tuning 1단계: Masking을 적용하지 않은 Input time window를 Input encoding과 Transformer Encoder에 순차적으로 넣어서 Representation을 도출 2단계: 도출된 모든 시점의 Representation을 Concatenate 한 것을 Output Linear Layer에 Input으로 넣어서 회귀 또는 분류의 정답을 예측 3단계: Task의 실제 정답과 TST가 예측한 값의 차이를 통해 Output Linear Layer를 Fine-tuning TST의 성능 Supervised Learning에 사용되는 Label의 비율 증가에 따른 TST (Pretrained)와 TST (Sup only)의 성능 변화로 다음 결과 도출 두 모델 모두 사용 가능한 Label의 비율이 증가할수록 성능이 향상 Pretrained TST가 Sup only TST 보다 모든 비율에서 높은 성능을 도출한 것을 통해 동일한 Training set을 중복 사용하여 모델을 학습한 것이 효과가 있다는 것을 알 수 있음 Fine-tuning 데이터의 개수가 고정되었을 때, Pre-training에 사용되는 데이터의 비율 증가에 따른 Pretrained TST의 성능 변화를 통해 다음 결과 도출 Pre-training에서 많은 데이터를 학습할수록 Pretrained TST의 성능이 향상 Pretrained TST의 Fine-tuning 데이터의 개수가 적을수록 Pre-training에 사용되는 데이터의 비율 증가에 따른 성능 향상 폭이 큼 Summary TST는 Transformer의 Encoder 구조만을 사용 Pre-training 과업을 위하여 연속적 길이의 Input masking을 사용 Layer Normalization 대신 Batch Normalization 사용 Fine-tuning 단계에서 구조를 어떻게 설계하느냐에 따라 회귀, 분류, 예측 등 다양한 테스크로 적용 가능 Pre-training을 통해 기존의 Supervised Learning만 수행했을 경우보다, 우수한 예측 성능을 보임" }, { "title": "LG Aimers 2기 인과추론 (서울대학교 이상학 교수님)", "url": "/posts/LG-Aimers-%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/", "categories": "Education, LG Aimers 2기", "tags": "AI, Deep learning, Machine learning", "date": "2023-01-24 00:00:00 +0900", "snippet": "이번 글에서는 LG Aimers의 AI 전문가 과정에서 인과성에 대해 추론하고, 경험적 데이터를 사용해 인과 관계를 결정하는 방법을 익히게 됩니다. 이를 통해 데이터를 생성한 프로세스에 대해 만들어야 하는 필수 가정과 이러한 가정이 합리적인지 평가하는 방법, 마지막으로 추정되는 양을 해석하는 방법을 학습합니다.1. Causality 인과성에 대한 소개와 인과적 추론을 하기 위한 기본 개념 인과성 (Causality)은 하나의 어떤 무엇인가가 다른 무엇을 생성함에 있어서 영향을 미치는 것 원인과 결과 사이의 관계는 필요조건이나 충분조건일 필요는 없음 과학은 일반적 사실이나 법칙을 포함하는 지식 체계 법칙은 현상의 본질적 구조를 명확하게 한 것 즉, 원인과 결과의 매커니즘을 기술한 것 (Cause and Effect) AI는 어떤 에이전트가 목표를 성취하기 위해서 합리적인 액션을 취하는 것 강화학습에서는 주어진 상황에서 어떤 행동을 취할지를 학습함 환경에 변화를 주어 원하는 상태로 변화시키는 인과관계로 해석이 가능함 데이터 사이언스는 데이터를 수집, 처리, 분석하여 결과를 대중들과 상호작용할 것인가 하는 많은 부분에서 상관성과 인과성 모두 고려해야 함 (기계학습은 데이터의 상관성을 학습하는 것) 인과추론은 알 수 없는 실험 결과를 관측 데이터와 연결하는 것 (모델에 대한 형식적, 수학적 이해가 필요함) Structural Causal Model (SCM)Pearl’s Causal Hierarchy Associateional or Observational (기본적인 관측 계층) Interventional or Experimental (실험 계층) Counterfactual (관측과 실험에 의한 값을 동시에 고려하는 반사실적 계층) Correlation (level 1) vs Causation (level 2) 초콜릿의 소비량과 노벨상 수상의 상관관계 Simpson’s Paradox 신장 결석 환자가 병원에 왔음. 그리고 환자를 진찰 및 처방하고, 결과가 리포트 되고, 헬스케어 데이터가 생성 데이터를 확인해보니, 신장 결석 사이즈가 작을 때는 처방 A의 효과가 더 좋았음 신장 결석 사이즈가 클 때도 처방 A의 효과가 더 좋았음 그러나 모든 데이터를 합쳐서 보면, 처방 B의 효과가 더 좋았던 것을 볼 수 있음 즉, 이 프로세스는 결석의 상태와 처방에 따라 환자의 나중 건강 상태가 결정되고 있음 인과적 분석을 하기 위해서는 주어진 데이터 뿐 아니라, 각 변수들이 가지는 인과적 관계를 이해하는 것이 필요함데이터 분석 시, 고려할 것 주어진 데이터가 상관성을 지니고 있는지, 인과성을 지니고 있는지 확인 알고자 하는 질문이 조건부 확률 같은 상관성에 대한 것인지, 인과성에 관한 것인지를 알아야 함2. Causal Effect Identification 인과추론을 수행하기 위한 기본적인 방법론 제시 Query, Causal Diagram, Data -&gt; Causal Inference Engine -&gt; Solution3. Modern Identification 인과추론의 다양한 연구 방향 제시 General Identification: 여러 데이터가 한 도메인에 주어졌을 때, 그것을 활용하여 원하는 인과 효과를 계산하는 것" }, { "title": "LG Aimers 2기 Explainable AI (서울대학교 문태섭 교수님)", "url": "/posts/LG-Aimers-%EC%84%A4%EB%AA%85%EA%B0%80%EB%8A%A5%ED%95%9C-AI/", "categories": "Education, LG Aimers 2기", "tags": "AI, Deep learning, Machine learning", "date": "2023-01-19 00:00:00 +0900", "snippet": "이번 글에서는 LG Aimers의 AI 전문가 과정에서 설명가능한 AI에 대하여 학습합니다. 머신러닝은 크고 복잡한 데이터를 이해하고, 이들 간의 관계성을 살펴보는 기술이지만 본질적으로 해석 가능성을 제한하는 블랙박스인 경우가 많습니다. 현실에서 이것을 사용할 때는 그에 따른 해석이 요구되는데, 따라서 그 한계를 보완하기 위해 Explainable AI 즉, 설명가능한 AI 기술에 대해 학습하여 머신러닝 모델과 그 의미에 대하여 학습할 것입니다.1. Explainable AI 1 최근 딥러닝은 그 성능이 매우 빠르게 발전하고 있음 하지만 대용량 학습 데이터로부터 학습하는 모델 구조는 점점 더 복잡해지고, 이해하기 어려워진다는 한계점이 있음 즉, 입력을 주게 되면, 그에 따른 결과가 나오는 하나의 블랙박스 형태의 결과가 보여진다는 것 이러한 예측 결과가 사람에게 직접 영향을 미치게 되는 경우에는 이 한계점은 매우 심각하게 될 것 자율주행, 의학적 진단, 대출 승인 등을 비롯한 AI 편향성 문제 Reliability &amp; Robustness (Pascal VOC 2007 Classification) 말 이미지가 주어졌을 때, 말의 어느 부분을 보고 해당 사진이 말이라는 것을 알게 됐는지 특정 부분을 하이라이트 XAI 기법은 이미지에서 말에 해당하는 부분이 아닌, 아랫쪽에 주로 하이라이트가 되어 있었음 데이터를 확인해보니, 말 사진에는 텍스트 워터마크가 있었고, 이것으로 말이라고 예측하고 있었다는 것 이처럼 XAI 기법을 통해서 모델이나 데이터셋의 오류를 색출하고, 편향성을 확인 할 수 있을 것 결국, 왜 알고리즘이 그런 예측 결과를 냈는지 설명하여 신뢰 여부를 결정할 수 있어야 함 XAI에서 설명가능하다는 것은 모델을 사용할 때, 그 동작을 이해하고 신뢰할 수 있게 해주는 기계학습 기술으로 정의XAI의 대비되는 종류 Local vs Global Local: Describes an individual prediction (개별적인 예측 결과를 설명) Global: Describes entire model behavior (전반적인 행동을 설명) White-box vs Black-box White-box: Explainer can access the inside of model (모델 내부 구조를 알고 설명) Black-box: Explainer can access only the output (모델 구조를 모르고, 출력만으로 설명) Intrinsic vs Post-hoc Intrinsic: Restricts the model complexity before training Post-hoc: Applies after the ML model is trained Model-specific vs Model-agnostic Model-specific: Some methods restricted to specific model classes Model-agnostic: Some methods can be used for any model -&gt; Linear model, Simple Decision Tree: Global, White-box, Intrinsic, Model-specific -&gt; Grad-CAM: Local, White-box, Post-hoc, Model-agnosticSimple Gradient method Simply use the gradient as the explanation (딥러닝의 Back-propagation) Strength: Easy to compute (via Back-propagation) Weakness: Becomes noisy (due to shattering gradient problem) 즉, 똑같은 예측 결과를 갖는 조금씩 변하는 이미지들에 대해 각 이미지에 대한 설명이 많이 다를 수도 있음 SmoothGrad Simple method to address the noisy gradients 이미지가 주어졌을 때, 작은 노이즈인 엡실론을 섞어준 뒤, 노이즈가 섞인 입력 이미지에 Gradient를 구하는 과정을 여러 번 수행하여 그 Gradient의 평균으로 설명하는 것 (대략 50번 정도) Strength: Clearer interpretation via simple averaging, Applicable to most sensitive maps Weakness: Computationally expensive2. Explainable AI 2Class Activaiton Map (CAM) 어떤 이미지가 CNN 모델의 입력으로 주어졌을 때, 이미지에 해당하는 Activation들이 최종 이미지에 최종 Activation으로 나타나게 됨. 이러한 각 Activation map은 Global Average Pooling 별로 학습된 w_1부터 w_n을 활용하여 Activation map을 결합하게 됨. 최종 결합된 이미지는 하이라이트 되어 표현됨 어떤 Activation map에 Activation이 크게 된다는 것은 그 Map이 주어진 입력과 관련이 많다는 뜻이고, 그것을 결합하는 w가 크다는 것도 최종 분류에 큰 영향을 주는 Activation이라는 것 CAM은 Object detection 이나, Semantic segmentation 등 더 복잡한 응용 분야에도 적용 가능 Strength: It clearly shows what objects the model is looking at Weakness Model-specific: It can be applied only to models with limited architecture It can only be obtained at the last convolutional layer and this makes the interpretation resolution coarse (마지막 Convolutional layer의 Activation에서 얻을 수 있으므로 해상도가 좋지 않음) Grad-CAM CAM 방식을 보완한 방식으로, Global Average Pooling layer가 없는 모델도 적용할 수 있음 특정 모델 구조를 가지고 학습된 w를 사용하는 것이 아닌, Activation map의 Gradient를 구한 다음에 그것의 Global Average Pooling 값으로 w를 적용한다는 것 Strength: Model-agnostic 하여 It can be applied to various output models Weakness: Average gradient sometimes is not accuratePerturbation-based 입력 데이터를 조금씩 바꾸면서 그에 대한 출력을 보고, 그 변화에 기반하여 설명하는 접근법 Local Interpretable Model-agnostic Explanations (LIME) 어떤 분류기가 딥러닝 모델처럼 복잡한 비선형적 특징을 가지더라도, 주어진 데이터 포인트들에 대해서는 아주 Local 하게는 다 선형적인 모델로 근사화가 가능하다는 관찰에서 출발 그래서 주어진 데이터를 조금씩 교란해 가면서, 교란된 입력 데이터를 모델에 여러 번 통과시켜 나오는 출력을 보고, 나오는 입출력 Pair들을 간단한 선형 모델로 근사하여 설명을 얻어내는 방식 Strength: Black-box interpretation (딥러닝 모델 뿐 아니라, 입력과 출력을 얻을 수 있다면 모두 적용 가능) Weakness: Computationally expensive, Hard to apply to certain kind of models, When the underlying model is still locally non-linear Randomized Input Sampling for Explanation (RISE) LIME 방식과 비슷하게, 여러 번 입력을 Perturb 해서 설명을 구하는 방식 랜덤한 Mask를 만들어서 그 Mask를 씌운 입력이 모델을 통과 했을 때, 해당 클래스에 대한 예측 확률이 얼마나 떨어지는 확인하여 설명력을 예측하게 됨. 즉, 여러 개의 랜덤 마스킹이 되어 있는 입력에 대해 출력 스코어를 구하고, 그 확률을 통해 이 마스크들을 가중치를 두어 평균을 냈을 때 나오는 것이 설명 Map Strength: Much clear saliency-map Weakness: High computational complexity, Noisy due to sampling Different approach for XAI Identify most influential training data point for the given prediction Influence function Measure the effect of removing a training sample on the test loss value 특정 Training 이미지 없이 모델을 훈련시켰을 때, 해당 모델의 성능이 얼마만큼 변할지 근사화 하는 함수 이 함수를 가지고, 각 Training 이미지마다 영향력을 계산하고, 그 값이 가장 큰 이미지를 설명으로 제공 3. Explainable AI 3XAI 방법을 비교 평가하는 방법 사람들이 직접 XAI 방법들이 만들어낸 설명을 보고 비교 및 평가하는 것 AMT (Amazon Mechanical Turk) Test Guided Backprop, Guided Grad-CAM 등 확인 가능 Weakness: Obtaining human assessment is very expensive Human annotation을 활용하는 것 Some metrics employ human annotations (localization and semantic segmentation) as a ground truth, and compare them with interpretation Pointing game: Bounding box를 활용하여 평가하는 방법 Weakly supervised semantic segmentation: 어떤 이미지에 대해 Label만 주어졌을 때, 그것을 활용하여 픽셀 별로 객체의 Label을 예측하는 방법 (Weakly supervised인 이유는, 픽셀 별로 정답 Label이 없기 떄문) IoU (Intersection over Union): 정답 Map과 이렇게 만들어낸 Segmentation map이 얼마나 겹치는지 평가 Weakness: Hard to make the human annotations, Such localization and segmentation labels are not a ground truth of interpretation Pixel Perturbation 즉, 픽셀을 교란하여 모델의 출력값의 변화를 테스트 성이 있는지 분류하는 모델이 있을 때, 성 부분을 가려서 모델을 통과시키면 그 값이 크게 떨어질 것임. 만약 성이 아닌 다른 부분을 가리게 된다면, 분류 스코어 값은 크게 변동이 없을 것임 AOPC (Area Over the MoRF Perturbation Curve): 주어진 이미지에 대해 각 XAI 기법이 설명을 제공하면, 그 설명의 중요도 순서대로 각 픽셀을 정렬할 수 있고, 그 순서대로 픽셀을 교란했을 때, 원래 예측한 분류 스코어 값이 얼마나 빨리 바뀌는지를 측정하는 것 Insertion: 중요한 순서대로, 백지 상태의 이미지에서 중요한 픽셀의 순서대로 하나씩 추가해가면서 분류기의 출력 스코어가 어떻게 변화하는지 확인하는 것. 따라서 이 값이 클수록 좋은 결과 Deletion: AOPC 방법과 같이 XAI 기법이 제공한 중요도 순서대로 픽셀을 하나씩 지워가며, 분류 확률 값이 떨어지는 확인하는 것으로, AOPC와는 반대로 커브의 아래 쪽의 면적을 구함. 따라서 이 값이 낮을수록 좋은 결과 Weakness: 데이터를 지우거나, 추가하는 과정이 머신러닝의 주요한 가정에 위반하는 경우가 있음. 즉, 어떤 픽셀을 지우고, 모델의 입력으로 넣었을 때, 해당 이미지는 모델을 학습시킨 Training 이미지들의 분포와 다르기 때문에 정확하지 않다는 것 ROAR (RemOve And Retrain) XAI 기법이 발견한 중요한 픽셀을 지우고 나서, 지운 데이터를 통해 모델을 재학습하고, 정확도가 얼마나 떨어지는지 평가하는 방법 (재학습한 후에 나오는 모델의 성능이 떨어지는 경우에는 좋은 설명 방법이라는 것) 앞선 방법들에 비해 조금 더 객관적이고, 정확한 평가를 할 수 있지만, 계산 복잡도가 크다는 단점이 있음 XAI 방법의 신뢰성에 관한 연구 Sanity Checks Model Randomization Model Randomization Test 분류 모델에 위쪽 Layer부터 모델의 계수들을 순차적으로 Randomized 한 후에 얻어지는 설명들을 구함 계속 Randomized 되었으므로, 시간이 지날수록 성능이 떨어지지 않은 모델들은 학습이 잘못됨을 추론 Adversarial Attack 어떤 입력 이미지에 대한 픽셀을 아주 약간 바꿨을 떄, 분류기의 예측 결과를 완전히 다르게 만든다는 것 많은 설명 방법들이 Gradient와 연관되는 값을 사용하는데, Decision boundary가 불연속적으로 나오게 된다면, Gradient의 방향이 급격하게 변할 수 있기 때문에 조금만 입력이 바뀌어도 Gradient가 아주 많이 바뀔 수가 있다는 것 이에 조금 더 강건하게 반응하기 위해 ReLU 대신, Softplus를 사용하라 Adversarial Model Manipulation 모델이 편향되었다는 것을 알았을 때, 해당 모델을 다시 고쳐서 재학습 시키는 것이 아니라, 모델 계수를 조금씩 조작하여 모델의 정확도는 차이가 없지만 XAI의 결과가 공정한 것처럼 보일 수도 있다는 것 " }, { "title": "LG Aimers 2기 지도학습 - 딥러닝 (KAIST 주재걸 교수님)", "url": "/posts/LG-Aimers-%EB%94%A5%EB%9F%AC%EB%8B%9D/", "categories": "Education, LG Aimers 2기", "tags": "AI, Deep learning, Machine learning", "date": "2023-01-18 00:00:00 +0900", "snippet": "이번 글에서는 LG Aimers의 AI 전문가 과정에서 딥러닝에 대한 기본 개념과 대표적인 모형의 학습 원리를 학습합니다. 특히, 이미지와 언어 모델 학습을 위한 딥러닝 모델과 학습 원리를 배우게 될 것입니다.1. Introduction to DNN Artificial Intelligence &gt; Machine Learning &gt; Deep learning 하나하나의 뉴런들이 모여서, 하나의 신경망을 구성 (여러 Layers를 가지고 있음) = DNN DNN 적용을 위해서는 빅데이터, 컴퓨팅 성능, 진보된 알고리즘 모델이 필요함 영상 인식, 이미지 합성, 기계 번역, 챗봇, 자연어 처리, 주식 가격 예측 등에 적용 퍼셉트론 (Perceptron): y = f(w0 + w1x1 + w2x2) AND, OR, XOR Gate XOR Gate는 Single layer 퍼셉트론으로는 결과값을 낼 수 없음 Input layer - Hidden layer - Output layer (2-layer neural network) Input layer - Hidden layer1 - Hidden layer2 - Output layer (3-layer neural network) Forward Propagation, Activation Function (Sigmoid, Softmax), Loss Function (MSE, Cross entropy loss)2. Training NN Gradient Descent: Loss Function을 최소화 시킬 수 있는 최적의 파라미터 값을 업데이트 하는 과정 Loss function이 복잡한 경우에는, 수렴 속도가 늦어지는 경우도 존재 따라서 Original Gradient Descent 알고리즘을 다양한 형태로 변화시킴 (Momentum, Adagrad, Adam 등) NN의 학습 과정 가장 처음으로는, 학습 데이터에 대해 Random Initialize 된 값으로 Forward Propagation을 수행 그 상태에서 Loss Function의 값을 최소화 시킬 수 있는 파라미터를 찾아나감 (Backward Propagation) Gradient Vanishing을 해결하기 위해 Tanh, ReLU 활성화 함수 등을 사용하게 됨 Batch Normalization (배치 정규화) 각 배치 단위 별로 데이터가 다양한 분포를 가지더라도, 배치 별로 평균과 분산을 이용해 정규화 해주는 것 활성화 함수의 출력값을 정규화 하여 그 분포를 고르게 해주는 효과 3. CNN and 이미지 분류 Fully Connected NN, Convolution NN (CNN - 이미지 처리에 사용), Recurrent NN (RNN - 시계열 데이터에 사용) CNN은 특정 클래스에 존재할 수 있는 작은 특정 패턴들을 정의하고, 패턴들이 주어진 이미지에 있는지를 판단 매칭의 정도를 나타내는 결과값을 활성화 지도 (Activation map)이라고 하고, 이는 특정 Convolution Filter를 주어진 입력 이미지에 가능한 모든 위치에 오버랩을 시켜서 매칭되는 정도를 나타낸 것 Channel, Filter, Pooling Layer (Max, Average) 일반적인 구조: Conv - ReLU - Conv - ReLU - Pooling - Conv - ReLU - Pooling - FC Hyperparameters Convolution: Number of filters, Size of filters Pooling: Window size, Window stride Fully Connected: Number of layers, Number of neurons CNN 모델은 어느 종류의 layer를 어느 위치에, 어느 순서로 배치하는가가 중요한 문제. 이에 대하여 많은 연구자들이 CNN 모델에 대한 architecture를 사전에 정의한 것들이 있음 = AlexNet, VGGNet, GoogleNet, ResNet VGGNet: 각각의 Conv layer에서 사용하는 필터의 가로, 세로 size를 3 by 3으로 고정하고, layer를 깊게 쌓아서 문제를 해결한 알고리즘 ResNet (Residual Network): Conv layer를 통해 나온 output에 layer를 또 추가하는 것. layer를 추가적으로 쌓아서 생기는 비효율성에 대하여 일부 layer는 skip 할 수 있도록 하는 skip connection을 추가한 알고리즘 CNN 알고리즘의 꾸준한 성능 개선과 함께, 모델의 layer 개수도 꾸준히 증가 됨 (AlexNet은 8개, ResNet은 152개 층)4. Seq2Seq with Attention Recurrent Neural Network (RNN) one to one, one to many, many to one, many to many RNN 모델의 기울기 소실 및 폭발의 문제를 해결하기 위한 LSTM, GRU 모델 등장 Seq2Seq, Encoder &amp; Decoder Original Seq2Seq 모델은 매 time step 마다 생성되는 RNN의 각 time step의 Hidden state vector는 같은 dimension으로 이뤄져야 한다는 제약 조건이 있음. Output vector가 다시 Input vector로 사용되기 위해. 이러한 경우에 축적해야 되는 정보가 시간이 길어짐에 따라서 점점 많아지지만, 정보는 항상 똑같은 개수의 dimension에 저장하게 되어 정보를 유실하게 된다는 한계점이 있음 이러한 Bottleneck 문제를 해결하고자 attention 이라는 추가적인 모델이 Seq2Seq에 도입 입력 sequence에 주어지는 데이터를 encoder에서 인코딩 한 후, decoder에서는 encoder의 마지막 time step의 Hidden state vector 만을 입력으로 받지 않고, 그 입력과 더불어 decoder의 각 time step에서 encoder에서 나온 여러 인코딩 데이터 중 필요로 하는 것을 가지고 가서 예측에 사용 기본적 구조는 encoder와 decoder가 존재하고, encoder의 마지막 time step의 Hidden state vector가 decoder의 가장 최초의 Hidden state vector인 h0로 사용됨. 그런데 여기서 어떤 decoder의 각 time step에서 추가적으로 encoder에 있는 여러 Hidden state vector로부터 필요한 정보를 취사선택해서 가장 유관하다고 생각하는 정보를 추가적인 입력으로 사용함 5. Transformer Transformer 모델은 Seq2Seq with attention 모델의 개선된 버전 Solving long-term dependency problem Seq2Seq with attention 모델에서 Encoder와 Decoder가 RNN 기반의 모델로 구성됨 Transformer 모델은 Encoder와 Decoder에서도 attention 기반으로 동작하는 모델 RNN 기반의 모델들은 Long-term Dependency 문제가 있음 (오랜 시계열을 거쳐 정보가 소실 될 수 있음) Transformer에서는 가까이 있거나 멀리 있는 정보를 접근해서 필요한 정보를 사용할 수 있게 됨 Self-attention, Multi-head Attention Layer Normalization은 각 단어에서 발견된 특정한 dimension으로 이루어진 벡터의 각 원소에 평균과 분산을 계산 그리고 각 단어 내에서 발생된 벡터 각각의 원소 값의 평균과 분산이 0과 1이 되도록 정규화 dimension 혹은 layer 내의 각 노드 별로 학습된 trainable parameters로 affine transformation 수행 이는 Batch Normalization과 비슷하게 학습을 조금 더 안정화시키고, 성능을 개선시킬 수 있음 Positional Encoding은 각 단어의 입력 벡터에 몇 번째 순서에서 나타났다는 알려 줄 수 있는 정보 즉, 각 단어의 순서나 위치를 구분할 수 있게 되는 것 Transformer 모델은 기존에 RNN 및 Convolution 기반의 Sequence를 인코딩하는 모델보다 좋은 성능을 보임 이렇게 가능하게 된 이유는 Long term dependency를 근본적으로 해결했기 때문 자연어처리 외에도 다양한 도메인에 적용되고 있음 또한 Transformer에서 제한된 Layer 수를 더 많이 늘리되, Block 자체의 설계나 디자인은 그대로 계승하고, Model의 사이즈를 점차 늘리면서 Self-supervised 방법론을 추가로 사용하여 대규모 데이터를 학습한 사전 학습 모델을 활용할 수 있음 6. Self-supervised Learning Self-supervised Learning (자가지도학습)은 데이터의 Labeling 과정 없이도 Raw data 만으로 모델을 학습 즉, Raw 데이터나, 별도의 추가적인 Label 없이 입력 데이터만으로 입력 데이터 중에 일부를 가려놓고, 가려진 입력 데이터를 주었을 때 가려진 부분을 잘 복원 혹은 예측하도록 하여, 주어진 입력 데이터의 일부를 예측하도록 모델을 학습 (Computer Vision 분야의 Inpainting Task, Zigsaw Puzzle Task 등) Transfer Learning의 기본 아이디어는 자가지도학습을 통해 만들어진 (Inpainting) 모델의 앞쪽 Layer는 물체를 잘 인식하기 위해 필요로 하는 유의미한 패턴을 추출할 수 있도록 학습됨. 그리고 뒤쪽의 Layer는 실제 풀고자 하는 문제를 해결할 수 있도록 특화되어 학습이 될 것. 따라서 대규모 데이터로 학습된 모델에 풀고자 하는 문제를 해결할 수 있는 Layer를 뒤에 덧붙여서 모델을 재학습 BERT (Pre-training of Deep Bidirectional Transformers for Language Understanding) BERT 모델은 Transformer의 Encoder 역할을 수행 입력 문장을 BERT 모델의 입력 Sequence로 제공하되, 입력 데이터의 일부를 가리고 그것을 예측하도록 함 두 개의 문장을 주고, 연속되게 등장하여 두 문장 사이에 어떤 의미 관계가 있는지 판단 (Next Sentence 예측) CLS, MASK, SEP 토큰 추가 Masked Language Model (MLM) 주어진 입력 문장에 대해, 특정 확률에 따라 각 단어를 Masked token으로 대체할지 전처리 수행 약 15% 비율의 단어를 Mask 단어로 대체하되, 거기서 80%는 Mask 단어, 10% 랜덤한 단어, 10%는 그대로 유지 Too little masking: Too expensive to train Too much masking: Not enough to capture the given context Next Sentence Prediction (NSP) 두 개의 문장을 SEP token으로 구분하여 제공하고, CLS token으로부터 인코딩 된 Hidden state vector의 Binary classification 결과를 예측 Further Details of BERT Model Architecture BERT BASE: L = 12, H = 768, A = 12 BERT LARGE: L = 24, H = 1024, A = 16 Input Representation WordPiece Embedding (30,000 WordPiece) Learned positional embedding CLS (Classification embedding) Packed sentence embedding (SEP) Segment Embedding Pre-training Tasks Masked LM Next sentence prediction GPT (Generative Pre-Trained Transformer) GPT 모델은 Transformer의 Decoder 역할을 수행 주어진 텍스트 데이터들에 대해 문장을 가져와서 특정 문장의 일부만 주어졌을 때, 다음에 나타날 단어를 예측. 그리고 그 다음 단어가 주어졌을 때, 그 다음 단어를 예측하는 Word level의 Language modeling task를 학습 Zero-shot Summarization으로도 활용 가능 일반적으로 Summarization을 수행하기 위해서는 사전 학습된 모델을 가져와서 target task인 Summarization을 목적으로 입력 지문과 정답 요약 문장인 Labeled 학습 데이터를 가지고 주어진 모델을 Fine-tuning 하는데, GPT는 그런 과정 없이 Summarization을 수행할 수 있어서 Zero-shot이라고 함 GPT3는 BERT와 GPT2와 다르게, 훨씬 더 많은 Layer 수를 가지고, 학습에 필요로 하는 1,750억 개의 파라미터 Zero-shot, One-shot, Few-shot Learning " }, { "title": "프로그래머스 인공지능 데브코스 16주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-16%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2023-01-16 00:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스의 16주차 강의에 대한 정리입니다. 이 강의에서는 추천 시스템에 대하여 다루게 됩니다.1. Recommendation System 이란?추천 엔진의 정의 사용자: 서비스를 사용하는 사람 아이템: 서비스에서 판매하는 물품 (다른 사용자가 물품이 될 수도 있음 - 링크드인 등) 일반적으로 서비스가 성장하면, 사용자나 아이템의 수도 같이 성장하게 됨 특히, 사용자의 성장도가 훨씬 커짐 하지만 아이템의 수가 커지면서 아이템의 선택에 대한 이슈가 생김 모든 사용자가 능동적으로 검색하지 않고, 사람들이 추천에 대한 니즈가 생김 Twitter의 알파 제인의 정의: 사용자가 관심 있어 할 만한 아이템을 제공해주는 자동화 된 시스템 (관심, 자동화) Yahoo의 디팍 아그라왈의 정의: 비즈니스 장기적 목표를 개선하기 위해 사용자에게 알맞은 아이템을 자동으로 보여주는 시스템 (장기적 목표, 매출액, 자동화)추천 엔진이 필요한 이유 조금의 노력으로 사용자가 관심 있어 할 만한 아이템을 찾아주는 방법 아이템의 수가 굉장히 큰 경우 더 의미가 있음 사람의 노다가로 해결할 수 없어 자동화가 필요함 개인화 (Personalization)로 연결 될 수 있음 또한 가끔씩 전혀 관심 없을 듯한 아이템도 추천 가능 (Serendipity) 회사 관점에서는 추천 엔진을 기반으로 다양한 기능을 추가할 수 있음 마케팅 시, 추천 엔진 사용 (이메일 마케팅) 관련 상품 추천으로 쉽게 확장 할 수 있음 아이템의 수가 많아서 원하는 것을 찾기 어려운 경우 (검색의 수고를 덜어줌) 추천을 통해 신상품 등의 마케팅이 가능해짐 (추천을 통해 신상품 노출이 가능) 인기 아이템 뿐 아니라, 롱 테일의 다양한 아이템을 노출 할 수 있음 (개인화가 알고리즘화 될 수 있음)추천은 결국 매칭 문제 사용자에게는 맞는 아이템을 매칭해주기 (아이템은 서비스에 따라 달라지고, 다른 사용자가 될 수도 있음) 어떤 아이템을 추천할 것인가? 지금 뜨는 아이템 추천 (개인화 되어 있지 않은 추천) 사용자가 마지막에 클릭했던 아이템 추천 사용자가 구매했던 아이템을 구매한 다른 사용자가 구매한 아이템 추천 (협업 필터링) 추천 UI도 굉장히 중요 (보통 추천 유닛이 존재하고, 이를 어떤 순서로 노출시킬지?) Cold Start 문제: 사용자의 데이터가 없는 상태에서 새로운 추천을 어떻게 해야 할까? 따라서 사용자와 아이템 등에 대한 부가 정보들이 필요해짐 아이템 부가 정보: 먼저 분류 체계를 만들어야 함, 태그 형태로 부가 정보를 유지하는 것도 좋음 계층 구조의 분류 체계 (대분류, 소분류, 태그 및 키워드 등) 사용자 프로파일 정보: 개인정보 (성별, 연령), 아이템 정보 (관심 및 서브 카테고리, 태그, 클릭, 구매 아이템) 무엇을 기준으로 추천 할 것인가? 클릭? 매출? 소비? 평점?추천 엔진 예제 아마존 관련 상품 (Related Product) 추천 - 사용자: 멤버, 아이템: 상품 과거 구매 이력, 인기 있는 상품들, 주기적으로 구매 할 수 있는 상품들 등이 추천되고 있음 넷플릭스 영화 및 드라마 추천 - 사용자: 멤버, 아이템: 영화, 드라마 격자 형태의 추천 유닛 (최근 뜨고 있는 것 기반, 과거 시청 이력 기반, 인기 Top 10 기반 추천) 구글 자동 검색어 완성 - 사용자: 검색자, 아이템: 검색어 타이핑을 전체 완성하지 않아도 됨, 알지 못했던 새로운 키워드로 접근 가능하다는 등의 효과 링크드인 혹은 페이스북 친구 추천 - 사용자: 멤버, 아이템: 멤버 Industry, 지역, 학교 등과 관련 있는 사람들 추천 스포티파이 혹은 판도라 노래, 플레이리스트 추천 - 사용자: 멤버, 아이템: 노래, 플레이리스트 헬스케어 도메인의 위험 점수 계산 - 사용자: 의사, 간호사, 아이템: 환자 어느 환자가 더 위험한지 예측하여 치료시 우선순위를 주기 위함 환자 별로 발병 확률과 발병시 임팩트를 계산하여 곱하는 형태 (발병 확률을 모델링) 유데미 강좌 추천 - 사용자: 멤버, 아이템: 강좌앞서 살펴본 추천 엔진들의 공통점 격자 형태의 UI 사용 (넷플릭스가 선구자) 다양한 종류의 추천 유닛들이 존재함 일부 유닛은 개인화 (사람에 따라 다른 아이템을 추천해줌) 일부 유닛은 인기도 등의 비개인화 정보 기반 (모든 사람에게 동일한 아이템 추천) 추천 유닛의 랭킹이 중요해짐 이 부분도 모델링 하여 개인화 하는 추세 클릭을 최적화 하고, 이 데이터 수집을 위한 실험을 수행 (데이터 수집을 위한 온라인 테스트) 추천 엔진의 종류 컨텐츠 기반 (아이템 기반) 개인화 된 추천은 아니고, 비슷한 아이템을 기반으로 추천이 이뤄짐 책이라면, 타이틀, 저자, 책 요약, 장르 등의 정보를 사용 많은 경우, NLP 테크닉을 사용하여 텍스트 정보를 벡터 정보로 변환 (단어 카운트, TF-IDF, 임베딩) 구현이 상대적으로 간단 (보통 아이템의 수가 사용자의 수 보다 작음) 협업 필터링 (Collaborative Filtering): 평점 기준 기본적으로 다른 사용자들의 정보를 이용하여 내 취향을 예측하는 방식 사용자 기반, 아이템 기반 두 종류가 존재 결국은 행렬 계산으로 이뤄짐 (Sparse 행렬 형태) 유사도 계산 (코사인 유사도 등) 사용자 기반 (User): 나와 비슷한 평점 패턴을 보이는 사람을 찾아서 그 사람들의 평이 좋았던 것을 추천 나와 비슷한 사용자를 어떻게 찾을지가 중요 (사용자 프로파일 정보 구축, 프로파일간 유사도 계산 - KNN) 아이템 기반 (Item): 평점의 패턴이 비슷한 아이템들을 찾아서 그것을 추천하는 방식 2001년에 아마존에서 논문으로 발표. 아이템들 간 유사도를 비교하는 것으로 시작 사용자 기반 협업 필터링과 비교하여 더 안정적이며, 좋은 성능을 보임 아이템의 수가 보통 작기 때문에 사용자에 비해 평점의 수가 평균적으로 많고, 계산량이 적음 즉, 사용자 기반 추천에 비해, 데이터에 대한 고객들의 평점 등에 대한 데이터가 많아서 성능이 좋음 사용자 행동 기반 아이템 클릭, 구매, 소비 등의 정보를 기반으로 하는 추천 사용자와 아이템에 대한 부가 정보가 반드시 필요함 여기에 속하는 추천은 구현이 간단하긴 하지만, 아주 유용함 모델링을 통해 사용자와 아이템 페어에 대한 클릭 확률 등의 점수 계산이 가능 의사 결정 트리나 딥러닝 등이 사용 가능 (유데미에서 채택한 방법) Batch 기반 추천, 실시간 추천인지 방식 등도 결정해야 함 위 알고리즘들을 하이브리드 형태로 사용유사도 측정 방법 두 개의 비교 대상을 N차원 좌표로 표현. 사용자와 사용자 혹은 아이템과 아이템 보통 코사인 유사도나 피어슨 상관계수 유사도를 사용하게 됨 두 벡터의 방향성이 비슷할수록 1에 가까운 값이 계산되는 코사인 유사도 (동일할 경우 1이 됨) 두 벡터가 반대 방향을 향하는 경우에는 -1이 계산 피어슨 유사도는 코사인 유사도의 개선 버전으로 각 벡터를 중앙 (중심)으로 재조정 협업 필터링에 대한 문제 Cold start 문제 사용자: 아직 평점을 준 아이템이 없는 경우 아이템: 아직 평점을 준 사용자가 없는 경우 보통 컨텐츠 기반 혹은 사용자 행동 기반 추천과 병행하여 이 문제를 해결해나감 리뷰 정보의 부족 (Sparsity) - 리뷰를 했다는 자체도 사실은 관심으로 볼 수 있음 업데이트 시점 - 사용자나 아이템이 추가 될때마다 다시 계산해야 함 확장성 이슈 - 사용자와 아이템의 수가 늘어나면서 행렬 계산에 시간이 오래 걸림 (Spark 같은 것이 필요해지는 이유) 협업 필터링의 많은 문제들이 추천의 일반적인 문제이기도 함협업 필터링 구현 방법 메모리 기반 앞서 설명한 방식 (사용자 기반, 아이템 기반) 사용자간 혹은 아이템간 유사도를 미리 계산 추천 요청이 오면, 유사한 사용자 혹은 아이템을 K개 뽑아서 이를 바탕으로 아이템 추천 구현과 이해가 상대적으로 쉽지만, 스케일하지 않음 (평점 데이터의 부족) 모델 기반 넷플릭스 프라이즈 컨테스트 때 고안된 추천 방식 (아이템 행렬에서 비어 있는 평점을 SGD를 사용해서 채움) 이는 보통 SVD (Singular Vector Decompostion)을 사용해서 구현 (딥러닝의 오토인코더를 사용하기도 함) 평점을 포함한 다른 사용자 행동을 예측하는 방식으로 진화하고 있음 주로 암시적 정보 (클릭, 구매, 소비)를 기반으로 행동을 예측하게 됨 아이템 노출 - 아이템 클릭 - 아이템 구매 - 아이템 소비 (인프라 단에서 해당 데이터들 수집이 필요함) 사용자 행동 기반 간단한 추천 유닛 구성 사용자가 관심을 보인 특정 카테고리의 새로운 아이템, 인기 아이템 등 사용자 행동을 예측하는 추천 (클릭 혹은 구매) 지도 학습 문제로 접근 가능. 무엇을 학습하고, 예측하는 모델인지 먼저 생각해야 함 어떤 기준으로 추천을 할까? = 머신러닝의 레이블 정보 명시적 힌트: 리뷰 점수 (Rating), 좋아요 (Like) 암시적 힌트: 클릭, 구매, 소비 등 2. Recommendation System 구현 1넷플릭스 프라이즈 개요 2006년부터 3년간 운영된 넷플릭스의 기념비적인 추천 엔진 경진대회 넷플릭스 추천 시스템 품질을 10% 개선하는 팀에서 $1M 수여 약속 (RMSE가 평가 기준으로 사용) 프라이버시 이슈도 제기 되었긴 했지만, 넷플릭스 브랜드 인지도도 올라감 이를 기폭제로 캐글과 같은 머신러닝 경진대회 플랫폼이 등장 이 대회를 통해서 협업 필터링이 한 단계 발전하게 되었음 SVD를 활용한 SVD++는 이후 굉장히 많은 분야에서 활용됨 앙상블 방식의 모델들이 가장 좋은 성능을 보이게 됨 (하지만 실행시간이 너무 길어서, 실제로는 사용 불가) 앙상블과 랜덤포레스트: 다수의 분류기를 사용해서 예측하는 방식 성능이 좋긴 하지만, 훈련과 예측 시간이 오래 걸린다는 단점이 있음 다양한 알고리즘들이 논문으로 학회에서 발표됨 (SVD++ 포함) 추천 엔진의 발전 역사 2001년 아마존이 아이템 기반 협업 필터링 논문 발표 2006년 ~ 2009년 넷플릭스 프라이즈 SVD를 이용한 사용자의 아이템 평점 예측 알고리즘 탄생 앙상블 알고리즘의 보편화 딥러닝의 일종이라고 할 수 있는 RBM (Restricted Boltzman Machine)이 단일 모델로 최고 성능을 보임 딥러닝이 추천의 분야에서 사용 가능성을 보이게 됨 2010년 딥러닝이 컨텐츠 기반 음악 추천에 사용되기 시작 2016년 딥러닝을 기반으로 한 추천이 활기를 띠기 시작 오토인코더 기반으로 복잡한 행렬 계산을 단순화 하는 방식이 하나 아이템 관련 사용자 정보를 시간 순으로 인코드 하는 RNN을 사용하는 방식이 다른 방식 아마존에서 DSSNTE 라는 알고리즘을 오픈소스화 했다가 나중에 SageMaker 라는 제품으로 통합 유데미 추천 살펴보기 문제 정의: 학생들에게 관심 있을만한 강의를 먼저 보여주는 것 추천 UI - 격자 기반 UI, 다양한 추천 유닛들이 존재 (유닛 선택과 랭킹이 필요함) 온라인 강의 메타 데이터 - 분류 체계, 태그, 클릭 키워드 분석 등 다양한 행동 기반 추천 - 클릭, 구매, 소비 등인기도 기반 추천 유닛 개발 인기도 기반 추천은 Cold start 이슈가 존재하지 않음 그렇다면, 인기도의 기준은? 평점? 매출? 최대 판매? 사용자 정보에 따라 확장 가능 (서울 지역 인기 아이템 추천 등) 단, 개인화는 되어 있지 않음 (어느 정도는 가능함) 아이템의 분류 체계 정보 존재 여부에 따라 쉽게 확장 가능 (특정 카테고리에서의 인기 아이템 추천) 인기도를 다른 기준으로 바꿔서 다양한 추천 유닛 생성 가능 (Top course, Newest course 등) Cold start 이슈가 없는 추천 유닛 (현재 사용자들이 구매한 아이템, 사용자들이 보고 있는 아이템 등)유사도 측정 (코사인 및 피어슨 유사도) 벡터들 사이에 유사도를 판단 코사인 유사도: N차원 공간에 있는 두 개의 벡터 간의 각도 (원점에서)를 보고서 유사도를 판단하는 기준 평점처럼 방향 뿐 아니라, 벡터 크기의 정규화도 중요하면, 피어슨 유사도를 사용하게 됨 (코사인 유사도의 개선판) 먼저 벡터 A와 B의 값들을 보정 각 벡터 내 셀들의 평균값들을 구한 뒤, 평균값을 각 셀에서 빼줌 예를 들면, A = {3, 4, 5} 라면, 평균값은 4이고, 보정 후에는 {-1, 0, 1}이 됨 그 이후 계산은 코사인 유사도와 동일함. 이를 중앙 코사인 유사도 혹은 보정된 코사인 유사도라고 부름 이를 통해 모든 벡터가 원점을 중심으로 이동하고, 벡터 간 비교가 더 쉬워짐 (정규화 효과) TF-IDF 소개와 실습 텍스트를 행렬 (벡터)로 표현하는 방법 텍스트 문서를 행렬로 표현하는 방법은 여러 가지가 존재함 기본적으로 일단 단어를 행렬의 차원으로 표현해야 함 Bag of Words 방식은 문서들에 나타나는 단어 수가 N개이면, N차원으로 문서를 표현 딥러닝의 워드임베딩 사용시, 차원 수도 축소되고, 공간 상에서 비슷한 단어끼리 가깝게 위치 One Hot Encoding + Bag of Words (카운트) - 단어의 수를 카운트해서 표현함 가장 먼저는 Stopwords를 제거함 (the, is, in, we, can, see 등) 그 뒤 단어의 수를 계산함 (sky, blue, sun, bright, shining 5개) 단어 별로 차원을 배정 (sky = 1, blue = 2, sun = 3, bright = 4, shining = 5) One Hot Encoding + Bag of Words (TF-IDF) - 단어의 값을 TF-IDF 알고리즘으로 계산된 값으로 표현 CountVectorizer 소개 앞서 Bag of Words 카운팅 방식을 구현한 모듈 벡터로 표현이 되면, 문서들 간의 유사도 측정이 가능함 TF-IDF 소개 앞서 카운트 방식은 자주 나오는 단어가 높은 가중치를 가지게 됨 하지만 TF-IDF는 한 문서에서 중요한 단어를 카운트가 아닌 문서군 전체를 보고 판단함 어떤 단어가 한 문서에서 자주 나오면 중요하지만, 이 단어가 다른 문서들에서 자주 나오지 않으면 더 중요할 것 TF-IDF = TF(t, d) * IDF(t) TF(t, d): 단어 t가 문서 d에서 몇 번 나왔는가? DF(t): 단어 t가 전체 문서군에서 몇 번 나왔는가? IDF(t): 앞서 DF(t)의 역비율 단어 t가 전체 문서들 중에서 몇 개의 문서에서 나왔는지? 이 비율을 역으로 계산한 것이 IDF In(N/DF): N은 총 문서 수를 나타내고, DF는 단어가 나온 문서를 뜻함 ### CountVectorizer 코드화from sklearn.feature_extraction.text import CountVectorizertext = [ 'The sky is blue', # sky, blue 'The sun is bright', # sun, bright 'The sun in the sky is bright', # sun, sky, bright 'We can see the shining run, the bright sun' # shining, sun, bright]countvectorizer = CountVectorizer(analyzer='word', stop_words='english')count_wm = countvectorizer.fit_transform(text)   sky blue sun bright shining doc1 1 1 0 0 0 doc2 0 0 1 1 0 doc3 1 0 1 1 0 doc4 0 0 2 1 1 ### TFidfVectorizer 코드화from sklearn.feature_extraction.text import TfidfVectorizertext = [ 'The sky is blue', 'The sun is bright', 'The sun in the sky is bright', 'We can see the shining run, the bright sun' ]tfidfvectorizer = TfidfVectorizer(analyzer='word', stop_words='english', norm='l2')tfidf_wm = tfidfvectorizer.fit_transform(text)### Cosine 유사도 계산from sklearn.metrics.pairwise import cosine_similaritycosine_similarities = cosine_similarity(tfidf_wm)   sky blue sun bright shining doc1 1, 1*log(4/2) = 0.6191 1, 1*log(4/1) = 0.7852 0 0 0 doc2 0 0 1, 1*log(4/3) = 0.7071 1, 1*log(4/3) = 0.7071 0 doc3 1, 1*log(4/2) = 0.6578 0 1, 1*log(4/3) = 0.5325 1, 1*log(4/3) = 0.5325 0 doc4 0 0 2, 2*log(4/3) = 0.7325 1, 1*log(4/3) = 0.3662 1, 1*log(4/1) = 0.5738 TF-IDF 문제점 정확히 동일한 단어가 나와야 유사도 계산이 이뤄짐 (동의어 처리가 안됨) 단어의 수가 늘어나고, 아이템의 수가 늘어나면 계산이 오래 걸림 결국 워드 임베딩을 사용하는 것이 더 좋음 (아니면, LSA 같은 차원 축소 방식을 사용해야 함)3. Recommendation System 구현 24. 딥러닝 기반 Recommendation System 구현 15. 딥러닝 기반 Recommendation System 구현 2" }, { "title": "LG Aimers 2기 지도학습 - 분류, 회귀 (이화여대 강제원 교수님)", "url": "/posts/LG-Aimers-%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5/", "categories": "Education, LG Aimers 2기", "tags": "AI, Deep learning, Machine learning", "date": "2023-01-13 00:00:00 +0900", "snippet": "이번 글에서는 LG Aimers의 AI 전문가 과정에서 머신러닝의 한 부류인 지도학습에 대한 기본 개념과 분류 및 회귀의 목적과 차이점에 대해서 학습합니다. 또한 다양한 모델과 방법론을 통해서 언제 어떤 모델을 사용해야 하는지, 왜 사용 해야 하는지, 모델 성능을 향상 시키는 방법 등에 대해 학습합니다.1. SL FoundationMachine Learning Problems 지도학습 (Labeled data): Regression, Classification 데이터 X를 이용하여 정답인 Y로 가는 함수 h를 학습하는 것 새로운 데이터가 들어올 때도 동작 할 수 있도록 하는 함수를 찾아내는 것 지도학습은 모델의 Output과 실제 값의 Error를 줄여가면서 학습이 진행 (Training) 학습 단계에서 보지 못했던 새로운 데이터를 통해서 모델의 성능을 확인 (Testing) 비지도학습 (Unlabeled data): Clustering, Dimensional ReductionLearning Model Goal: Target function (f: x -&gt; y) Training data Learning model (Feature selection, Model selection, Optimization) Hypothesis, EvaluationModel Generalization 학습 과정에서 데이터가 제한 됨에 따라, 성능 역시 제한 될 수 밖에 없음 따라서 모델의 궁극적 목적은 어느 데이터가 들어와도 동작할 수 있는 일반화가 필요함 Generalization Error (Training Error, Validation Error, Test Error) Overall Error (Loss Function, Cost Function) Test Error를 Training Error로 가까이 가도록 한다면? 실패하는 경우에는 Overfitting (High Variance) -&gt; 정규화 등을 사용 Training Error가 0에 가까이 가도록 한다면? 실패하는 경우에는 Underfitting (High Bias) -&gt; 조금 더 복잡한 모델 사용 Variance와 Bias의 Trade-off (Overfitting vs Underfitting)Avoid Overfitting Data Augmentation, Ensemble Regularization to penalize complex models (Lasso 등) Cross-validation (CV, K-fold) - Train, Valid, Test Dataset2. Linear RegressionLinear Models Hypothesis set H 많은 장점이 있음 (단순함, 해석 가능성, 일반화) 주어진 입력에 대해 출력과 선형적 관계를 추론 (단변량, 다변량 문제) 선형 모델은 파라미터 (x절편 및 y절편 등)가 달라짐에 따라 데이터 fitting 과정에서 오차가 발생 손실 함수가 가장 작게 되도록 하는 모델 파라미터를 찾는 것이 목표 (파라미터 최적화)Gradient Descent 데이터의 양이 증가할수록 벡터의 차원의 수가 증가함에 따라 복잡도가 늘어나게 됨 Needs Iterative Algorithm (경사하강법) Iterative 하게 최적의 파라미터를 찾아가는 과정 Gradient는 함수를 미분하여 얻는 값으로 해당 함수의 변화하는 정도를 확인할 수 있음 경사하강법에서는 Gradient가 최솟값이 되도록 반복적으로 파라미터를 변화 시킴 적절한 Learning Rate가 필요함 (하이퍼파라미터: 직접 사람이 지정해야 하는 값) Global Optima, Local Optima - 최적화 된 포인트 찾아가기 3. Gradient DescentLearning Rate Learning Rate에 따른 수렴 속도의 변화 Batch Gradient Descent 알고리즘은 전체 샘플 m개를 모두 고려해야 하는 단점이 존재 데이터가 증가하면 증가할수록 복잡도가 커짐 Stochastic Gradient Descent 알고리즘은 Batch 경사하강법의 문제점을 해결한 방법 샘플의 개수를 1개로 줄여서 파라미터를 지속적으로 개선시키는 알고리즘 Batch 경사하강법에 비해 빠르게 Iteration을 돌 수 있다는 장점 하지만 각 샘플 하나씩 계산하기 때문에 노이즈의 영향이 크다는 단점 Local Minimum을 피할 수 있는 방법 Momentum: 과거 Gradient가 업데이트 되었던 방향 및 속도를 반영하여 현재 포인트에서 Gradient가 0이 되더라도 계속해서 학습을 진행할 수 있는 동력을 제공하게 되는 것 Nesterov Momentum: Look ahead gradient step AdaGrad: Adapts an individual learning rate of each direction RMSProp: AdaGrad의 단점 (Learning rate가 작아지는 부분에서 학습 X)을 보완한 알고리즘 Adam (Adaptive Moment Estimation): RMSProp + Momentum 방식 모델의 과적합 문제 모델이 너무 복잡한 경우, 학습 데이터에서만 좋은 결과를 보이는 Overfitting 된 모델이 나오게 됨 Overfitting을 피할 수 있는 방법: Features의 개수를 줄이기, Regularization (정규화)4. Linear Classification Binary Classification: decision-boundary에 따라 class를 구분하기 (Logistic 모델) Zero-One Loss function Hinge Loss function Cross-entropy Loss function Multiclass Classification: One-VS-All Linear 모델의 장점: 간단함, 해석 가능성이 높음5. Advanced ClassificationSVM (Support Vector Machine) 모델 모델의 boundary 사이에서 존재하는 가장 가까운 margin을 갖는 Support Vector를 설정 Support Vector는 실제 테스트 시, 성능을 결정할 수 있는 중요한 (민감한) 데이터 따라서 Support Vector의 margin을 최대화 할 수 있는 모델을 구축하는 것이 목표 그렇기 때문에 Outliers에 대해서도 robust 하게 동작이 가능 Optimization 방법: Hard margin SVM, Soft margin SVM, Nonlinear transformANN (Artificial Neural Network) 모델 Non-linear classification model Activation functions: Sigmoid, ReLU, Leaky ReLU 등 ANN 모델의 Layer를 더 많이 쌓게 되면, Deep Neural Network (DNN)이 됨 DNN을 통해서 더 비선형적인 모델의 결과를 도출 할 수 있게 됨 Gradient Vanishing, Backpropagation, CNN6. Ensemble 앙상블 방식: 머신러닝에서 알고리즘의 종류에 상관 없이 서로 다르거나, 같은 매커니즘으로 동작하는 다양한 머신러닝 모델을 묶어서 함께 사용하는 방식 (예측 모델의 집합을 합쳐서 새로운 모델 만들기) 앙상블 모델의 장점 예측 성능을 안정적으로 향상 시킬 수 있다는 것 비교적 간단하게 사용 할 수 있다는 것 모델의 파라미터 튜닝이 많이 필요하지 않다는 것 Bagging (Bootstrapping + Aggregating): 학습 과정에서 Training samples을 랜덤하게 나눠서 선택하여 학습 Bootstrapping: 다수의 Sample data set을 생성하여 학습하는 방식 Aggregating: Committee prediction Boosting: Sequential 하게 동작하는 앙상블 모델 (Weak classifier의 Cascading) Weak classifier: Bias가 높은 Classifier (비교적 성능이 낮은 모델) Random Forest, Adaboost, GBM (Gradient Boosting Machine) Performance Evaluation: Accuracy, Confusion Matrix (TN, FN, FP, TP), Precision, Recall, ROC Curve" }, { "title": "LG Aimers 2기 품질성과 신뢰성 (한양대학교 배석주 교수님)", "url": "/posts/LG-Aimers-%ED%92%88%EC%A7%88%EC%84%B1%EA%B3%BC-%EC%8B%A0%EB%A2%B0%EC%84%B1/", "categories": "Education, LG Aimers 2기", "tags": "AI, Deep learning, Machine learning", "date": "2023-01-10 00:00:00 +0900", "snippet": "이번 글에서는 LG Aimers의 AI 전문가 과정에서 품질과 신뢰성에 대한 강의를 기록합니다. 한양대학교 배석주 교수님께서 강의해주시고, 이 강의를 통해 데이터 이해를 위한 기본적 소양을 기를 수 있습니다. 또한 품질의 의의와 각종 통계적 방법과 품질경영정보시스템의 방법론을 이해하며, 최적화를 위한 수학적 모델 및 분석 방법을 학습 할 수 있습니다.1. 품질 및 품질 비용품질 (Quality)이란? 전통적 품질 관리에서의 품질: 규격에 부합하는 것 품질을 보는 5개 관점 선험적 관점: 품질을 정의 할 수는 없더라도, 무엇인지 고객이 인지 제품 관점: 바람직한 성분이나 속성의 함량 차이가 곧 품질의 차이 사용자 관점: 용도 적합성 제조 관점: 요구사항에 부합되는 정도 가치 관점: 품질은 실제 용도와 판매가격의 최적 상태 품질의 구성 요소 제품특징: 시장 점유율의 확대나 보다 높은 가격을 통해 주로 판매 수익의 증대에 기여하는 요소 무결함: 재작업, 폐기 처분, 고객 불만 등의 감소를 통한 원가 절감에 기여하는 요소 품질의 유형 요구 품질 (Requirement of Quality): 제품 또는 서비스를 사용하는 사람의 입장에서 요구하는 품질 설계 품질 (Quality of Design): 기업의 제조 역량을 고려해 추상적 요구 품질을 명문화 (구체화)한 품질 제조 품질, 적합 품질 (Quality of Manufacturing or Confomance): 원자재 품질, 설비 능력, 공정 능력 등 제조 시스템의 다양한 원천에서 발생하는 변동성과 불확실성에 의해 제조 품질이 결정 사용 품질, 시장 품질 (Quality of Use of Market): 고객이 제품 또는 서비스를 실제 사용한 후, 그 제품으로부터 기본적 욕구의 충족, 애프터 서비스, 보전, 신뢰성 등에 대한 만족감 또는 불만을 인식함으로써 결정 품질의 8가지 차원: 성능, 특징, 신뢰성, 적합성, 내구성, 서비스성, 심미성, 인지품질 종합적 품질 (Total Quality): 제품과 서비스가 아무리 훌륭해도, 고객에게 수용되지 않으면 의미 없음. 즉, 고객 지향적인 품질의 정의가 필요하고 중요함. 이를 위해 제조 시스템의 가치 사슬을 고려해 볼 필요가 있음 저품질 비용 (COPQ, Cost of Poor Quality): 기업 내에서 불필요하게 발생하는 이익손실비용을 측정하는 재무적 지표 저품질로 인해 드러난 실패 비용은 빙산의 일각 회계상 파악 가능한 손실 - 매출의 4~6% (전통적 실패 비용은 정의가 쉬움) 회계상 파악 불가능한 손실 - 매출의 25~30% (숨어 있는 실패 비용은 측정이 어렵고 정의가 곤란) 2. 통계적 공정 관리 (SPC)SPC 필요성과 개념 Feed-Back 공정관리 시스템 (ERP, MEC) SPC는 공정에서 요구되는 품질, 생산성 목표를 달성하도록 통계적 방법으로 공정을 효율적으로 운영하는 관리 방법 Statistical: 통계적 자료와 분석 기법을 이용하여 Process: 공정의 품질 변동을 주는 원인과 공정의 능력 상태를 파악하여 Control: 주어진 품질 목표가 달성되도록 끊임 없이 품질 개선이 이뤄지도록 관리하는 활동 SPC의 장점과 단점 장점: 결함 방지에 효과적, 불필요한 공정 조정 방지, 계량치 및 계수치 데이터 모두에 사용 가능 단점: 데이터의 정확한 수집 및 관리가 필요, 관리도에 대한 올바른 분석과 패턴에 대한 조치 필요 SPC의 적: 품질 변동 우연 원인 (Chance Cause): 엄격히 관리된 상태 하에서도 어느 정보 품질 변동을 발생시키는 원인 이상 원인 (Assignable Cause): 산발적으로 발생하여 품질 변동을 발생시키는 원인 SPC에서 사용되는 통계적 기법: 평균, 분산 및 확률분포, 관리도 및 공정능력 지수, QC 7가지 기본 도구 QC 7가지 도구란, 적은 데이터로부터 가능한 한 신뢰성이 높은 객관적 정보를 얻는데 가장 유효한 수단 특성 요인도, 파레트도, 체크 시트, 산점도, 히스토그램, 층별, 관리도 (그래프) 3. 스마트 품질 경영품질 4.0과 스마트 품질 경영 전사적 품질 관리 (Total Quality Management) 품질 4.0은 기존 품질 관리 기법과 IoT, 빅데이터 등이 결합된 신개념 품질관리 및 경영 개념 품질 경영 시스템의 Digital Transformation 설명적 애널리틱스: 데이터로 과거에 무엇이 발생했는지를 분석하기 위한 기법 (상관관계 모니터링) 진단적 애널리틱스: 과거에 축적된 데이터로 인과관계를 찾아내어 특정 품질 관련 이벤트가 발생했는지 분석 예측적 애널리틱스: 통계학적 모델을 통해 미래에 어떤 사건이 발생할 확률로 예측하는 기법 처방적, 규범적 애널리틱스: 예측되는 이벤트를 위해 무엇을 하면 좋을지 처방하는 의사결정 관련 기법 스마트 공장은 환경을 고려하고, 안전성을 확보하며 역동적 시장 변화에 대응하는 지능형 디지털 시스템 품질 관리 문화는 기업 내 여러 부서 간의 협업과 대화를 통해 합의를 이뤄내는 것이 중요함 빅데이터를 활용한 스마트 품질 경영 실시간 커뮤니티 피드백을 제공하는 방안 원격 진단 및 유지 보수 고도화 된 공급망 품질 관리 예시 공정 모니터링 시스템의 품질 예측 및 불량 요인 분석 알고리즘 개발 공정 변수와 품질 계측치의 상관관계를 파악할 수 있는 지표 도출 (군집분석) 공정 변수를 통해 품질 계측치를 예측할 수 있는 가상 계측 시스템 구축 (회귀분석) 4. 신뢰성 개념과 중요성신뢰성의 중요성 제품 라이프 사이클 관점의 Total Cost 관리가 필요 (품질비용은 잠재적 Risk) 개발 단계에서 시장 품질은 예측 가능하고, Control 될 수 있어야 함 신뢰성: 주어진 작동 환경에서 주어진 시간동안 시스템이 고유의 기능을 수행할 확률 품질: 정적 (현시점에서 제품의 특성), 전사적 추진 및 주로 생산 단계, 불량률 신뢰성: 동적 (미래의 성능과 고장), 전문분야 기술자로 구성된 팀에서 추진 및 설계 및 개발 단계, 고장률 신뢰성 분석의 필요성 (취약한 설계, 과부하, 강도와 부하의 산포, 마모, 시간 매커니즘, 잠재된 오작동, 오류) 신뢰성 척도 신뢰도: 부품, 제품, 시스템 등이 주어진 사용 조건에서 일정 기간 요구되는 기능을 고장 없이 수행할 확률 순간 고장률: 어떤 시점까지 동작하고 있는 시스템이 계속되는 단위 시간 동안 고장을 일으킬 비율 평균 고장률: 총 동작 시간 동안의 고장 개수 평균 고장 시간: 수리불가시스템에서 고장이 발생하기까지의 평균 시간 평균 고장 간격: 수리가능시스템에서 고장 간격 간의 평균 동작 시간 보전도: 고장난 시스템이 주어진 조건 하에서 규정된 시간 내에 수리 (보전)을 완료할 확률 가용도: 수리 가능한 시스템이 어떤 특정 시점에 기능을 유지하고 있을 확률 고장률, 욕조곡선, 평균고장시간, 평균고장간격시간, 평균잔여수명, 백분위 수명 신뢰성 데이터 수명 데이터: 의도된 기능을 제대로 수행하고 있거나, 고장인지의 여부로 판정 (Binary Data) 선능 데이터: 시간 경과에 따른 제품의 성능을 측정 (Continous Data) 5. 신뢰성 분포와 신뢰성 척도연속형 수명 분포와 신뢰성 척도 지수분포: 확률밀도함수 및 누적분포함수, 고장률 함수, 평균 수명, 메디안 수명 지수분포 무기억성: 이산형에서 기하분포가 무기억성을 갖는 것처럼 연속형 분포에서는 지수분포가 무기억성을 가짐 지수분포의 일반화 형태는 감마분포 감마분포: 포아송 프로세스를 따르는 사건이 k건 발생하는데 걸린 시간의 확률 분포 포아송분포: 시간 Lambda 동안 포아송 프로세스를 따르는 사건의 개수에 대한 확률 분포 정규분포, 표준정규분포, 대수정규분포 베르누이와 이항분포, 포아송분포 신뢰성 데이터 표현 (수명분포), 고장 개수 표현 (이항분포, 포아송분포)6. ICT 기반 예지 보전시스템 열화 시스템은 사용시간, 빈도의 증가에 따라 열화 특정 운용 조건에서 요구된 기능을 수행하지 못하는 경우, 시스템 고장 발생 일반적으로 고장 후 교체 비용이 예방 보전 비용보다 훨씬 높음보전 보전의 목적: 안전하고 경제적으로 운전 될 수 있는 조건으로 장비 유지 비용 검토와 관련된 문제 인식 Safety Risk 휴지기간비용 및 수리비용 고려 보전도 (Maintainablilty): 예방보전 (상태기반, 시간기준), 사후보전 (보전연기, 즉시보전) 사후보전: 점검 및 정기 교환을 전혀 하지 않고, 장비 고장 후 수리 장점: 장비 수명이 다할 때까지 사용하므로, 2차 고장이 없다면 보전비 및 수리비가 모두 저렴 단점: 고장이 늘어나고, 생산공정에 미치는 영향이 크면 수율 및 생산 능력이 저하 시간기준보전: 장비의 열화에 가장 비례하는 파라미터로서 수리 주기를 정하고, 주기까지 사용시 무조건 수리 장점: 점검 등의 보전 공수가 적고, 고장도 적음 단점: Over Maintenance가 되어 수리비가 많이 들 수 있음 상태기반보전: 장비 열화 상태를 온오프라인으로 파악하며, 열화를 나타내는 값이 미리 정한 기준에 달하면 수리 장점: TBM의 단점인 과잉 유지 관리를 방지 단점: 감시 체계 설치에 대한 비융이 들며, TBM에 비해 보전 인력이 더 필요할 수도 있음 주요 보전 활동 개념 비교: BM - CM - PM - PdM " }, { "title": "LG Aimers 2기 AI 윤리 (KAIST 차미영 교수님)", "url": "/posts/LG-Aimers-AI-%EC%9C%A4%EB%A6%AC/", "categories": "Education, LG Aimers 2기", "tags": "AI, Deep learning, Machine learning", "date": "2023-01-04 00:00:00 +0900", "snippet": "이번 글에서는 LG Aimers의 AI 전문가 과정에서 AI 윤리에 대한 강의를 기록합니다. KAIST 차미영 교수님께서 강의해주시고, 데이터 과학자로서 기본 소양과 어떤 자세를 가져야 하는지를 고민할 수 있습니다. 더불어 인공지능 기술로 어떻게 문제를 해결할 수 있을지에 대해 학습합니다.1. 데이터 분석과 AI 학습에서 유의할 점데이터 처리 및 수집에서 윤리 이슈 데이터를 잘 해석하고 있는가? 초콜렛을 많이 먹으면 노벨상을 탄다? -&gt; 논문 링크 상관관계와 인과관계는 다름 상관관계 (Correlation): 일정한 수치로 계산되어 두 대상이 서로 관련성이 있다고 추측되는 관계 인과관계 (Causality): 일반적으로 어떤 사실과 다른 사실 사이의 원인과 결과 관계 키와 체중 사이에는 일정한 정도의 상관관계가 존재. 키가 큰 사람이 어느 정도 체중이 많이 나가는 경향이 있기 때문. 하지만 키가 크다고 반드시 체중이 많이 나가거나, 체중이 많다고 꼭 키가 크지 않기 때문에 둘 사이에 인과관계가 있다고 이야기 하기는 어려움 데이터 전처리와 분석 방법은 적절한가? Error bar 추가하기 (데이터의 편차를 표시해주기) 적합한 통계 테스트 찾기 아웃라이어 제거하기 데이터 표준화하기 EDA (Exploratory Data Analysis) 충분한 시간 할애하기 학습에 쓰는 데이터가 충분한가? Under-fitting, Over-fitting 피하기 Appropirate-fitting으로 데이터 학습 결과가 적절한지 이해할 수 있어야 함 학습 데이터는 테스트 데이터와 달라야 함 블랙박스 알고리즘 (Black Box Algorithms) 설명력이 중요한 AI 예시 (탈세범 검출 - 위장 반입, 원산지 조작 등 세관에서 벌어지는 불법 행위 적발 AI) 실제 사례에서는 성능 뿐 아니라, 설명력 역시도 매우 중요한 부분 AI 모델의 결정에 설명력 더하기 High risk 결정에서는 설명력도 정확도 만큼이나 중요 Saliency map, SHAP와 같이 post-hoc explainability (사후 설명력)를 제공하는 기술 알고리즘의 내면을 가시화해서 보여주는 기술들의 등장 학습 결과가 바뀔 수 있는 위험성 One pixel attack의 예시에서는 픽셀 하나만 바뀔 경우에 알고리즘 학습 결과가 달라지는 문제점 AI 모델들이 노이즈에 굉장히 민감하게 반응하고 있음을 이해할 수 있는 예시 Handling the Web Data 수집하는 SNS, 인터넷, 블로그 등의 글이 대중들의 의견을 대표할 수 있는 대표성이 있는가? 의견의 대표성 (Spiral of silence) -&gt; 편향 현상 인터넷 상의 의견이 대표성 있는 의견이 아닐 수도 있음을 인지 소셜 링크를 통한 빠른 정보 전파, 봇의 참여, 극단화 현상 주의 오정보의 빠른 확산으로 인한 인포데믹 현상 인포데믹 (Infodemic): 사실 정보와 더불어 오정보의 양이 늘어 구분이 어려워지는 정보 과부화 현상 데이터 사용과 서비스 개발에 사용자 어려움을 반영해야 함 원치 않은 광고 원치 않은 메일 수신 회원가입 시 너무 많은 개인정보 요구 유해 콘텐츠 노출 사이트마다 유사한 내용의 콘텐츠 제공 The right to be forgotten (잊혀질 권리) 윤리에 대한 법적 제도 (GDPR, General Data Protection Regulation) AI and Ethical Decisions (인공지능 알고리즘으로 인한 부작용 존재 - 챗봇, 채용 등)결론 데이터의 확보, 전처리, 분석, 해석의 모든 과정이 중요: 고품질의 데이터가 입력되었을 때 학습 결과도 유의미하며, 데이터가 갖는 오차 범위와 특이점, 대표성에 대한 충분한 이해를 가지고 접근 알고리즘의 설명력, 편향, 신뢰의 문제에 주의: 블랙박스 알고리즘이 실제 적용되기 위해 설명력 보강이 필요하고, 노이즈와 데이터 가변성에도 대처 가능한 알고리즘을 개발하도록 노력해야 함. 더불어 AI가 다양한 서비스에서 인간 결정을 돕거나, 대체함에 따라 윤리적 의사결정이 확보되도록 점검2. AI Ethics인공지능 알고리즘과 윤리 이슈 AI and Creativity GAN 알고리즘을 이용한 미술, 음악 등 예술에서의 적용 자연언어처리 (NLP) 기술의 혁신 - BERT, GPT 등 AI Art in Action 인공지능이 만들어낸 작품의 가격은 $432,500 AI 예술 작품은 학습 데이터 기반인데, 창작성 (Originality)이 있을까? 학습 데이터, 프로그래머, 기획자 사이에 저작권 이슈가 존재 NFT (Non-Fungible Token)의 시대에서도 영향을 미치고 있음 Copyright Issues 학습에 사용된 데이터를 제공한 사람에게도 혜택이 돌아가기 어려움 창작자인 AI는 법적 권리를 제공할 수 있는 법적 제도가 없음 현존하는 예술가의 스타일을 따라한 예술 작품을 만들 경우 상업적 피해 가능성 창작된 작품이 인간의 윤리적 규범을 따르지 않을 가능성 AI Contributed Harm 아시모프의 로봇 3원칙 로봇은 인간을 다치게 해서는 안되며, 인간이 해를 입은 것을 방관해서는 안됨 첫 번째 법칙에 위배되지 않는 한, 로봇은 인간의 명령에 복종 첫 번째, 두 번째 법칙에 위배되지 않는 한, 로봇은 스스로 보호해야 함 자율 주행 차량 사고가 났을 때, 누가 책임 져야 할까? -&gt; 소유자, 회사, 개발자, 운전자, 자율주행차, 보행자? 로봇의 인격화: 로봇이 고통을 느끼지 못하더라도, 로봇 학대는 인류에 나쁠 것 결론 인간의 창조적 활동 영역으로 들어온 인공지능: AI가 기술 혁신과 창작 도구로 활용이 확대되어, 인간의 개입 없이 독자적 창작과 혁신 활동이 가능한 수준으로 발전하리라 전망 AI 시대 지적 재산, 법 인격, 처벌, 그리고 윤리 문제 부각: AI에 의한 발명과 저작 등에 대한 법제 정비, 오동작시 처벌과 윤리 규정 마련 등의 논의가 다양한 시민의 수요와 요구를 반영하도록 유의 AI에 대한 경계와 규제의 선택은 인류에 대한 재정의3. 세계적인 데이터 과학자가 되는 방법데이터 과학자 인사이트 Becoming a World-class Data Scientist 데이터에 대한 관심과 호기심 이종 데이터의 결합은 혁신을 가져올 수 있음 통신사 데이터를 대중교통 노선을 만드는데 활용 소셜 네트워크 데이터를 통해 정치 성향, 좋아하는 브랜드 등 유추가 가능 가짜 뉴스 탐지 새로운 기회 이종 (Heterogeneous) 빅데이터의 결합과 새로운 인공지능 기반 계산과학 방법의 적용 데이터 사이언스 기반 난제 해결 정책 결정 및 신규 산업 창출의 도약 대두 세계적 데이터 과학자는 어떻게 일할까? 데일리 루틴으로 데이터에 관심을 가지고, 조금씩 결과를 내는 것 변화가 곧 생존 계획한 것을 바로 실행 What gets scheduled, gets done 목표가 낮아서 너무 빨리 성취하는 오류 50%의 성공 확률을 가지는 설레는 목표 계속해서 재조정하기 실패를 두려워 하지 말라 레이 달리오, 성공의 원칙 목표가 무엇인지 안다. 문제를 찾아낸다. 근본적 원인을 발견한다. 극복하기 위한 계획을 세운다. 실행한다. " }, { "title": "프로그래머스 인공지능 데브코스 10주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-10%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-11-28 00:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스의 10주차 강의에 대한 정리입니다. 딥러닝의 심화 내용과 함께 CNN과 RNN에 대하여 학습합니다.1. 딥러닝 기초 영상 분류: 과거에는 매우 어렵고, 도전적 문제 ImageNet: 2만 2천여 부류에 대해 수백~수만장의 사진을 인터넷에서 수집하여 1500만여 장의 사진을 구축 및 공개 ILSVRC (ImageNet Large Scale Visual Recognition Competition) 대회 - CVPR 학술대회에서 개최 1000가지 부류에 대해 분류, 검출, 위치 지정 문제 120만 장의 훈련 집합, 5만 장의 검증 집합, 15만 장의 테스트 집합 우승: AlexNet (2012) -&gt; GoogleNet &amp; VGGNet (2014) -&gt; ResNet (2015) 우승한 모델은 코드와 학습된 가중치를 공개하여 널리 사용되는 표준 신경망이 됨AlexNet 컨볼루션층 5개와 완전 연결 (Fully Connected, FC) 층 3개 8개 층에 290300-186624-64896-43264-4096-4096-1000개의 노드 배치 컨볼루션층은 200만개, FC층은 6500만개 가량의 매개 변수 FC층에 30배 많은 매개변수 (향후 CNN은 FC층의 매개변수를 줄이는 방향으로 발전함) 구조 당시 GPU의 메모리 크기 제한으로 인해 GPU 1, 2로 분할하여 학습 수행 3번째 컨볼루션층은 두 개의 결과를 함께 사용 (Inter-GPU Connections) 컨볼루션층 큰 보폭으로 다운 샘플링 학습에 성공한 요인 외적요인: ImageNet 이라는 대규모 사진 데이터, GPU를 사용한 병럴 처리 내적요인: 활성 함수로 ReLU 사용, 지역 반응 정규화 기법 적용, 과잉적합 방지하는 규제 기법 적용 인간 신경망 측면 억제 모방, ReLU 활성화 규제 데이터 확대 (잘라내기 - Cropping, 반전 - Mirroring으로 2048배로 확대) 드롭아웃 (완전연결층에서 사용함) 테스트 단계에서 앙상블 적용: 입력된 영상을 잘라내기와 반전을 통해 증가시켜서 2~3% 만큼 오류율 감소 효과 VGGNet 3*3의 작은 커널을 사용함 GoogleNet의 인셉션 모듈처럼 이후 깊은 신경망 구조에 영향 큰 크기의 커널은 여러 개의 작은 크기 커널로 분해 될 수 있음 매개변수의 수는 줄이면서 신경망은 깊어지는 효과 5 by 5 커널을 2층의 3 by 3 커널로 분해하여 구현 5 by 5 커널의 매개변수는 5 * 5 = 25 3 by 3 커널의 매개변수는 9 + 9 = 18 3 by 3 커널을 1 by 3 커널과 3 by 1 커널로 분해하여 구현 3 by 3 커널의 매개변수는 3 * 3 = 9 1 by 3 커널의 매개변수는 1 * 3 = 3 3 by 1 커널의 매개변수는 3 * 1 = 3 따라서 기존 9개보다 6개로 줄어드는 효과를 볼 수 있음 결국, 최종적으로 n이 클수록 매개변수의 수는 줄어드는 효과가 있음 신경망을 더욱 깊게 만듦 (신경망의 깊이가 어떤 영향을 주는지 확인) 컨볼루션층 8~16개를 두어 AlextNet의 5개에 비해서 2~3배 깊어짐 1 by 1 커널: VGGNet은 적용 실험만 하고, 최종 선택은 안함 (GoogleNet에서는 사용됨) 차원 통합, 차원 축소 효과GoogleNet 핵심은 인셉션 모듈 (Inception) - 총 9개의 인셉션 모듈을 포함 Conv 레이어를 sparse 하게 연결하고, 행렬 연산은 dense 하게 처리함 수용장의 다양한 특징을 추출하기 위해 NIN의 구조를 확장하여 복수의 병렬적인 컨볼루션 층을 가짐 NIN 구조는 기존 컨볼루션 연산을 MLPConv 연산으로 대체하는 것 커널 대신 비선형 함수를 활성 함수로 포함하는 MLP를 사용하여 특징 추출에 유리 신경망의 미소 신경망 (Micro NN)이 주어진 수용장의 특징을 추상화 시도 전역 평균 풀링 (Global Average Pooling) 사용 FC층 대신 Global Average Pooling을 사용 전 층에서 나온 특징 맵들을 각각 평균 낸 것을 이어서 1차원 벡터 생성 FC층을 사용했을 때에 비해, 가중치의 개수를 상당히 줄일 수 있었음 GoogleNet은 NIN 개념을 확장한 신경망 인셉션 모듈: 마이크로 네트워크로 MLPConv 대신 네 종류의 컨볼루션 연산 사용 (다양한 특징 추출) 1 by 1 컨볼루션을 사용하여 차원 축소: 매개변수의 수 (특징 맵의 수)를 줄임, 깊은 신경망 3 by 3, 5 by 5 같은 다양한 크기의 컨볼루션을 통해 다양한 특징을 추출 매개변수가 있는 층 22개, 없는 층 (풀링) 5개로 총 27개 층 완전 연결층은 1개에 불과 함 (1백만 개의 매개변수를 가지고, VGGNet의 완전 연결층에 비하면 1% 수준) 두 개의 보조 분류기 추가 네트워크가 깊어지면서 발생하는 기울기 소실 문제를 줄이기 위해 추가 원 분류기의 오류 역전파 결과와 보조 분류기의 오류 역전파 결과를 결합하여 경사 소멸 문제 완화 학습할 때 도우미 역할을 하고, 추론할 때 제거됨 ResNet 잔류 (잔차) 학습이라는 개념을 이용하여 성능 저하를 피하면서 층 수를 대폭 늘림 지름길 연결을 두는 이유? 깊은 신경망도 최적화가 가능해짐 단순한 학습의 관점 변화를 통한 신경망 구조 변화 단순 구조의 변경으로 매개변수 수에는 영향이 없음 덧셈 연산만 증가하므로, 전체 연산량 증가도 거의 미비 깊어진 신경망으로 인해 정확도 개선 가능 경사 소멸 문제 해결 VGGNet과 같은 점: 3*3 커널 사용 VGGNet과 다른 점: 잔류 학습 사용, 전역 평균 풀링 사용 (FC층 제거), 배치 정규화 적용 (Dropout 필요 없음)2. CNN Models목적함수: 교차 엔트로피와 로그 우도 그리고 소프트맥스 활성화 함수3. 딥러닝 최적화4. RNN 출처: 프로그래머스 인공지능 데브코스 4기 10주차 강의 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "프로그래머스 인공지능 데브코스 9주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-9%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-11-21 00:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스의 9주차 강의에 대한 정리입니다. 1. 다층 퍼셉트론1인공신경망과 생물신경망 사람의 뉴런: 두뇌의 가장 작은 정보 처리 단위 컴퓨터가 사람 뇌의 정보 처리를 모방하여 지능적 행위를 할 수 있는 인공지능 도전 뉴런의 동작 이해를 모방한 초기 인공 신경망 (ANN) 연구 시작 퍼셉트론이 고안됨 신경망의 종류 전방 (Forward) 신경망, 순환 (Recurrent) 신경망 얕은 (Shallow) 신경망, 깊은 (Deep) 신경망 결정론 (Deterministic) 신경망: 모델의 매개변수와 조건에 의해 출력이 완전히 결정되는 신경망 확률론 (Stochastic) 신경망: 고유의 임의성을 가지고 매개변수와 조건이 같더라도 다른 출력을 갖는 신경망 퍼셉트론: 절 (Node), 가중치 (Weight), 층 (Layer)과 같은 새로운 개념의 구조 도입 제시된 퍼셉트론 구조의 학습 알고리즘을 제안 깊은 인공신경망 (Deep Learning)을 포함한 현대 인공신경망의 토대 입력 (편향 노드 포함) -&gt; 입력과 출력 사이의 연산 -&gt; 출력 일반적인 분류기의 학습 과정 과업 정의와 분류 과정의 수학적 정의 (가설 설정) 해당 분류기의 목적함수 정의 목적함수를 최소화 하는 값을 찾기 위한 최적화 수행 경사하강법을 통해 기울기를 미분하여 반복 탐색해 극값을 찾음 2. 다층 퍼셉트론2다층 퍼셉트론 퍼셉트론: 선형 분류기 (Linear Classifier)의 한계 OR, AND 분류기는 가능하지만, XOR 문제는 해결하지 못함 다층 퍼셉트론의 핵심 아이디어 은닉층을 두어, 특징 공간을 분류하는데 유리한 새로운 특징 공간으로 변환 연성에서는 출력이 연속값이므로 시그모이드 함수를 활성화 함수로 도입 오류 역전파 알고리즘을 사용하여 한 층씩 그레디언트를 계산하고, 가중치를 갱신 특징 공간 변환 퍼셉트론 2개를 병렬 결합하면, 원래 공간을 새로운 특징 공간으로 변환 가능 추가 퍼셉트론 1개를 순차 결합하면, 다층 퍼셉트론이 됨활성화 함수 딱딱한 공간 분할과 부드러운 공간 분할 계단 함수는 딱딱한 의사결정: 영역을 점으로 변환 그 외에 활성화 함수는 부드러운 의사결정: 영역을 영역으로 변환 로지스틱 시그모이드 하이퍼볼릭 탄젠트 시그모이드 Softplus와 Rectifier (ReLU) 활성화 함수에 따른 다층 퍼셉트론의 공간 분할 능력 변화 (경성 부분 변화) 일반적으로 은닉층에서 로지스틱 시그모이드를 활성화 함수로 많이 사용 S자 모양의 넓은 포화 곡선은 경사도 기반한 학습 (오류 역전파)을 어렵게 함 기울기 소실 (Gradient Vanishing) 문제 발생 따라서 깊은 신경망에서는 ReLU를 활용 계단 활성화 함수의 범위는 -1과 1 로지스틱 활성화 함수의 범위는 0부터 1 하이퍼볼릭 탄젠트 활성화 함수의 범위는 -1부터 1 소프트플러스, 렉티파이어 (ReLU) 활성화 함수의 범위는 0부터 무한대 구조 기존에는 입력층 -&gt; 은닉층 -&gt; 출력층의 2층 구조 입력층 -&gt; 은닉층 -&gt; 은닉층 -&gt; 출력층의 3층 구조 p개의 은닉 노드: p는 하이퍼 매개변수 p가 너무 크면 과잉적합, 너무 작으면 과소적합 하이퍼 매개변수 (Hyper-paramenters) 최적화 필요 동작 특징 벡터 x를 출력 벡터 o로 사상 (Mapping) 하는 함수로 간주할 수 있음 2층 퍼셉트론: o = f2(f1(x)) 3층 퍼셉트론: o = f3(f2(f1(x))) 은닉층은 특징 추출기 은닉층은 특징 벡터를 분류에 더 유리한 새로운 특징 공간으로 변환 현대 기계학습에서는 특징학습 (Feature Learning, Data-driven Learning) 이라 부름 심층학습은 더 많은 층을 거쳐 계층화 된 특징학습을 함 범용적 근사 이론 (Univeral Approximation Theorem) 하나의 은닉층은 함수의 근사를 표현 다층 퍼셉트론도 공간을 변환하는 근사 함수 얕은 은닉층의 구조: 일반적으로 깊은 은닉층의 구조가 좋은 성능을 가짐 입력층 -&gt; 은닉층 (순방향 전파) -&gt; 오차 계산 -&gt; 은닉층 (역방향 전파) -&gt; 오차 계산 학습 알고리즘은 오류 역전파를 반복하여 수행성능 향상을 위한 경험의 중요성 순수한 최적화 알고리즘으로는 높은 성능이 불가능 데이터 희소성, 잡음, 미숙한 신경망 구조 등 때문 성능 향상을 위한 다양한 경험 (Heuristics)을 개발하고 공유함 아키텍쳐, 초깃값, 학습률, 활성화 함수 3. 다층 퍼셉트론3목적 함수의 정의 훈련집합 특징 벡터 집합 (X)과 부류 벡터 집합 (Y) - 지도학습 부류 벡터는 단발성 (One-hot) 코드로 표현 기계학습의 목표: 모든 샘플을 옳게 분류하는 함수 f를 찾는 것 목적 함수: 평균 제곱 오차 (Mean Squared Error, MSE) 전방 전파와 오류 역전파오류 역전파 알고리즘의 설계 연쇄 법칙의 구현: 반복되는 부분식들 (Subexpressions)을 저장하거나 재연산을 최소화 목적 함수의 최저점을 찾아주는 경사 하강법 출력의 오류를 역방향 (왼쪽)으로 전파하여 경사도를 계산하는 알고리즘 (오류 역전파 알고리즘)미니배치 확률론적 경사 하강법 미니배치 방식 한번에 t개의 샘플을 처리 (t는 미니배치 크기) 미니배치 방식은 보통 수십 ~ 수백 경사도의 잡음을 줄여주는 효과 때문에 수렴이 빨라짐 GPU를 사용한 병렬처리에도 유리함 현대 기계학습은 미니배치 기반의 확률론적 경사 하강법을 표준처럼 널리 사용 4. 심층 학습 기초 1심층 학습 (Deep Learning) 다층 퍼셉트론에 은닉츠을 여러 개 추가하면, 깊은 신경망이 됨 (심층 학습은 깊은 신경망의 학습) 심층 학습은 새로운 응용을 창출하고, 인공지능 제품의 성능을 획기적으로 향상 (현대 기계학습 주도) 1980년대 이미 깊은 신경망 아이디어는 등장했으나, 당시에는 실현 불가능 경사 소멸 (Gradient Vanishing) -&gt; 활성화 함수 변화를 통해 해결 작은 훈련 집합, 과다한 연산과 시간 소요 (낮은 연산의 범용 컴퓨터, 값 비싼 슈퍼 컴퓨터) 일부 연구자들은 실망스러운 상황에서도 지속적인 연구 학습률에 따른 성능 변화 양상 모멘텀과 같은 최적 탐색 방법 모색 은닉 노드 수에 따른 성능 변화 데이터 전처리의 영향, 활성함수의 영향, 규제 기법의 영향 심층 학습의 성공 배경 혁신적 알고리즘 등장 (합성곱 신경망, CNN 구조) 경사 소멸 문제 해결을 위한 ReLU 활성 함수 과잉 적합을 방지하는데 효과적인 다양한 규제 기법 층별 예비 학습 (Pretraining) 기법 개발 값싼 GPGPU 등장, 학습 데이터 양과 질의 향상 표현 학습의 부각 전통적인 다층 퍼셉트론 (은닉층은 특징 추출기) 얕은 구조이므로 가공하지 않은 획득한 원래 패턴을 그대로 입력하면 낮은 성능 따라서 사람이 수작업 특징을 선택하거나, 추출하여 신경망에 입력 현대 기계학습 (심층학습) 학습에 의해 자동적으로 데이터로붵 특징 추출 (표현 학습 = Representation Learning) 특징 벡터를 신경망의 입력 (종단간 학습 = End-to-End Learning) 깊은 신경망을 통한 계층적 표현 학습 깊은 신경망의 표현 학습 (특징 학습) 낮은 단계 은닉층은 선이나 모서리 같은 간단한 저급 특징 추출 높은 단계 은닉층은 추상적 형태의 복잡한 고급 특징 추출 표현 학습이 강력해져서 기존 응용에서 획기적인 성능 향상 영상 인식, 음성 인식, 언어 번역 등 새로운 응용 창출 (화소 수준의 영상 분할, CNN과 LSTM의 혼합 학습 모델 등) 깊은 다층 퍼셉트론 (깊은 신경망) 깊은 다층 퍼셉트론의 구조와 동작 입력 (d+1 차원의 특징 벡터)과 출력 (c개 분류) L-1개의 은닉층 (입력층은 0번째 은닉층, 출력층은 L번째 은닉층으로 간주) DMLP (Deep Multi-Layers Perceptron)의 가중치 행렬 DMLP의 동작: MLP의 동작을 나타내는 식을 보다 많은 단계로 확장한 것 DMLP 학습은 기존 MLP 학습과 유사 (경사도 계산, 가중치 갱신을 더 많은 층에서 수행) 깊은 다층 퍼셉트론의 학습 주요 알고리즘의 개선 및 합성곱 신경망 (CNN)의 부상 구조: 퍼셉트론 -&gt; 다층 퍼셉트론 -&gt; 깊은 다층 퍼셉트론 활성함수: 계단 함수 -&gt; 시그모이드 함수 -&gt; ReLU와 변형 목적함수: 평균 제곱 오차 -&gt; 평균 제곱 오차 -&gt; 교차 엔트로피 또는 로그우도 심층 학습은 왜 강력한가? 종단간 최적화 된 학습 가능 고전적 방법에서는 사람의 직관에 따르기 때문에 성능에 한계 인식 대상이 달라지게 되면, 새로 처음부터 설계해야 했음 하지만 심층 학습은 전체 깊은 신경망을 동시에 최적화 (종단간 학습, End-to-End) 깊이 (Depth)의 중요성 (더 깊어질수록, 더 정교한 분할) 계층적 특징 (Hierarchical Features) 깊은 신경망에서는 층의 역할이 잘 구분됨 반면 얕은 신경망은 하나 또는 두 개의 은닉층이 여러 형태의 특징을 모두 답당 5. Convolutional Neural Network (CNN)컨볼루션 신경망 DMLP: 완전 연결 구조로 높은 복잡도, 학습이 느리고 과잉 적합이 발생할 수도 있음 컨볼루션 신경망 (CNN) -&gt; 부분 연결 구조 격자 구조를 갖는 데이터에 적합 컨볼루션 연산을 수행하여 특징 추출 영상 분류나 문자 인식 등 인식 문제에 높은 성능 컨볼루션 (Convolution): 해당하는 요소끼리 곱해서 결과를 모두 더하는 선형 연산 보폭 (Stride): 커널을 다음 컨볼루션 연산을 위해 이동시키는 칸 수 패딩 (Padding): 컨볼루션 결과의 크리를 조정하기 위해 입력 배열의 둘레를 확장하고, 0으로 채우는 연산 풀링: 일정 크기의 블록을 통합하여 하나의 대푯값으로 대체하는 연산 최댓값 풀링 (Max Pooling): 지정된 블록 내의 원소들 중에서 최댓값을 대푯값으로 선택 평균값 풀링 (Average Pooling): 블록 내의 원소들의 평균값을 대푯값으로 사용 컨볼루션 신경망 특징 추출 컨볼루션 연산을 하는 Conv 층 ReLU 연산을 하는 ReLU 풀링 연산을 하는 Pool 추출된 특징을 통해 분류나 회귀를 수행하는 다층 퍼셉트론 전체 연결된 (Fully connected) FC 층 반복 분류의 경우 마지막 층에 소프트맥스 연산 수행 6. 심층 학습 기초 2컨볼루션 (합성곱) 신경망 - CNN 영상 인식의 예: 픽셀 단위의 정보로부터 특정 사물 등을 인식하는 것 컴퓨터 비전의 어려운 점 동일한 객체라도 영상을 찍는 카메라 이동에 따라 모든 픽셀 값이 변화 됨 경계색 (보호색)으로 배경과 구분이 어려운 경우 조명에 따른 변화로 구분이 힘듦 기형적 형태의 영상 존재, 일부가 가려진 영상 존재 같은 종류 간의 변화가 큼 (같은 고양이라도 고양이의 크기가 다름) 컨볼루션층 (CONV): 선형 함수인 컨볼루션과 비선형 함수인 활성 함수의 조합 풀링층 (POOL): 컨볼루션의 얻어진 특징을 통계적으로 압축 덧대기 (Padding): 가장 자리에서 영상의 크기가 줄어드는 효과 방지 (각 층의 입출력 특징 형상 유지) 가중치 공유 (묶은 가중치): 모든 노드가 동일한 커널을 사용하므로 매개변수는 3개에 불과 (모델 복잡도가 낮아짐) 다중 특징 맵 추출: 커널 값에 따라 커널이 추출하는 특징이 달라짐 (한 개의 커널만 사용하면 너무 빈약한 특징만 추출) 전체 구조: CONV - (ReLU) - POOL - … - FC 영상 분야에서 다양하게 활용 (분류, 검색, 검출, 분할 등)DMLP와 CNN의 비교 DMLP: 완전 연결 구조로 높은 복잡도, 학습이 느리고 과잉 적합 우려 CNN: 컨볼루션 연산을 이용한 부분 연결 (희소 연결) 구조로 복잡도 낮춤, 좋은 특징을 추출해서 학습 격자 구조 (영상, 음성 등)를 갖는 데이터에 적합 수용장은 인간의 시각과 유사 가변 크기의 입력 처리 가능 CNN의 완전 연결 신경망과 차별 학습에 의해 결정된 복수의 커널 (혹은 필터)에 대응되는 특징을 추출하는 CONV 층 각 층의 입출력의 특징 형상을 유지시킴 (특징 맵) 영상의 공간 정보를 유지하면서 공간적으로 인접한 정보의 특징을 효과적으로 인식 각 커널 (필터)은 파라미터를 공유하여 완전 연결 신경망 대비 학습 파라미터가 적음 추출된 영상의 특징을 요약하고 강화하는 POOL 층 가변 크기의 데이터 다루기 완전 연결 신경망은 특징 벡터의 크기가 달라지면, 연산 불가능 CNN은 가변 크기를 다룰 수 있음 (컨볼루션 층, 풀링 층에서 커널 및 보폭 수정을 통한 특징 맵 크기 조절) 컨볼루션 (합성곱) 연산 컨볼루션은 해당하는 요소끼리 곱하고 결과를 모두 더하는 선형 연상 영상에서 특징을 추출하기 위한 용도로 사용 (공간 필터)컨볼루션층 특징 학습 커널을 사람이 설계 하지 않고, 학습으로 찾음 2차원 영상이 7*7 커널을 64개 사용한다면, 학습은 (7*7+1) * 64 = 3200개의 매개변수를 찾아내야 함 DMLP와 마찬가지로 오류 역전파로 커널을 학습 컨볼루션 연산에 따른 CNN 특성 이동에 동변 (신호가 이동하면, 이동 정보가 그대로 특징 맵에 반영) 병렬 분산 구조 각 노드는 독립적으로 계산하므로 병렬 구조 노드는 깊은 층을 거치면서 전체에 영향을 미치므로 분산 구조 큰 보폭에 의한 다운 샘플링: 일반적으로 보폭이 k이면, k개 마다 하나씩 샘플링하여 커널을 적용 텐서 적용: 3차원 이상의 구조에도 적용 가능 n차원 구조의 데이터 적용풀링층 풀링 (Pooling) 연산 최대 풀링, 평균 풀링, 가중치 평균 풀링 등 보폭을 크게 하면, 다운 샘플링 효과 풀링 연산의 특성 풀링은 상세 내용에서 요약 혹은 평균 등의 통계적 대표성을 추출함 매개 변수가 없음 특징 맵의 수를 그대로 유지함 (크기 X) 연산 효율화 (연산 횟수, 연결 가중치 개수를 줄임) 작은 변화에 둔감 (물체 인식이나 영상 검색 등에 효과적) 전체 구조 빌딩 블록 CNN은 빌딩 블록을 이어 붙여서 깊은 구조로 확장 전형적 빌딩 블록의 예시: 컨볼루션층 -&gt; 활성함수 (주로 ReLU) -&gt; 풀링층 다중 커널을 사용하여 다중 특징 맵을 추출 컨볼루션 층의 출력 크기와 매개변수 수 입력: W1 * H1 * D1 K개 F*F 커널, 보폭 S, 덧대기 P 출력의 크기: W2 * H2 * D2 W2 = (W1 - F + 2P) / S + 1 H2 = (H1 - F + 2P) / S + 1 D2 = K 매개변수의 수 커널마다 (F*F*D1)개의 가중치와 1개의 바이어스를 가짐. 전체 매개변수 수는 (F*F*D1) * K + K 일반적으로 F = 2, S = 2 혹은 F = 3, S = 1을 사용함 초창기 CNN 사례는 LeNet-5 특징 추출 CONV - POOL - CONV - POOL - CONV의 다섯 층을 통해 28*28 명암 영상을 120차원의 특징 벡터로 변환 평균 풀링 사용 분류: 은닉층이 하나인 MLP CNN 첫 성공 사례; 필기 숫자 인식기를 만들어서 수표 인식 자동화 시스템 구현 출처: 프로그래머스 인공지능 데브코스 4기 9주차 강의 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "프로그래머스 인공지능 데브코스 7주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-7%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-10-31 00:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스의 7주차 강의에 대한 정리입니다. 1. ML Basics (Probability)Machine Learning 기초 소개 Machine Learning (기계학습) 경험을 통해 자동으로 개선하는 컴퓨터 알고리즘의 연구 머신러닝 알고리즘의 결과는 목표값을 예측하는 함수 y(x) 핵심 개념 학습 단계: 함수 y(x)를 학습 데이터에 기반해 결정하는 단계 시험셋(Test set): 모델을 평가하기 위해 사용하는 새로운 데이터 일반화 (Generalization): 새로운 데이터에 대해 올바른 예측을 수행하는 역량 지도학습: Target이 주어진 경우 (분류, 회귀) 비지도학습: Target이 없는 경우 (군집) 다항식 곡선 근사 (Polynomial Curve Fitting) 새로운 입력 벡터가 주어졌을 때, 목표값을 예측하는 것 확률이론: 예측값의 불확실성을 정량화 하여 표현할 수 있는 수학적 프레임워크 제공 결정이론: 확률적 표현을 바탕으로 최적의 예측을 수행할 수 있는 방법론 제공 오차함수, 과소적합, 과대적합, 규제화확률변수 (Random Variable) 확률변수 X는 표본의 집합 S의 원소 e를 실수값 X(e) = x에 대응시키는 함수 대문자 X, Y…: 확률변수 소문자 x, y…: 확률변수가 가질 수 있는 값 연속확률변수 (Continuous Random Variable) 누적분포함수 (Cumulative Distribution Function, CDF) 누적분포함수와 확률밀도함수 사이의 관계 확률변수의 성질 덧셈법칙 곱셈법칙 베이즈 확률: 사후확률, 가능도 (우도), 사전확률 확률변수의 함수 확률변수 X의 함수 Y = f(X)도 확률변수 (함수의 함수) 2. ML Basics (Decision Theory, Linear Regression)3. ML Basics (Probability Distributions)4. ML Basics (Probability Distributions)5. 7주차 돌아보기 기간: 2022. 10. 31 ~ 2022. 11. 04 출처: 프로그래머스 인공지능 데브코스 4기 6주차 강의 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "프로그래머스 인공지능 데브코스 6주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-6%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-10-24 00:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스의 6주차 강의에 대한 정리입니다. 1. 인공지능과 기계학습 소개 일상 속 인공지능 음성인식 (Siri), 추천 시스템 (Netfilx), 자율주행 실시간 객체 인식 (Face ID), 로봇, 번역 (papago) 데이터 기반의 접근 기술에 집중하기 보다는, 인간 중심의 소통이 중요 인공지능 == 도구 도구를 만드는 방법을 배우는 것도 중요하지만, 도구를 사용하는 방법도 배워야 함 출처: https://itwiki.kr/w/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5 기계도 학습이 가능한가? 경험을 통해 점진적으로 성능이 향상되는 기계를 만들 수 있다! 인공지능: 인간의 학습, 추론, 지각, 자연언어 이해 등의 지능적 능력을 기기로 실현한 기술 학습: 경험의 결과로 나타나는, 비교적 지속적인 행동의 변화나 그 잠재력의 변화 또는 지식을 습득하는 과정 경험 E를 통해, 주어진 작업 T에 대한, 성능 P의 향상 (E * T = P) 인공지능의 주도권 전환 지식 기반 -&gt; 기계 학습 -&gt; 심층 학습 (표현 학습, Deep learning, Representation learning) 데이터 중심 접근 방식으로 전환 예측은 회귀 (Regression) 문제와 분류 (Classification) 문제로 나뉨 회귀는 목표치가 실수, 분류는 종류의 값 기계 학습 개념 훈련집합 (Training set) 가설: 눈대중으로 데이터 양상이 직선 형태를 보임 -&gt; 모델을 직선으로 선택 가정 기계 학습의 훈련 (Train) 주어진 문제인 예측을 정확하게 할 수 있는 최적의 매개변수를 찾는 과정 처음에는 임의의 매개변수로 시작하지만, 개선하여 정량적인 최적 성능 (Performance)에 도달 훈련을 마치면, 추론 (Inference)을 수행 새로운 특징에 대응되는 목표치의 예측에 사용 기계 학습의 궁극적인 목표 훈련집합에 없는 새로운 데이터에 대한 오류를 최소화 (새로운 데이터 = 테스트 집합) 테스트 집합에 대한 높은 성능을 일반화 (Generalization) 능력이라 부름 기계 학습의 필수 요소 학습할 수 있는 데이터가 있어야 함 데이터 규칙이 존재해야 함 수학적으로 설명이 불가능 차원의 저주 (Curse of Dimensionality): 차원이 높아짐에 따라 발생하는 현실적인 문제들 기술 추세 기계 학습 알고리즘과 응용의 다양화 표현 학습이 중요해짐 심층 학습이 기계 학습의 주류 심층 학습은 현대 인공지능 실현에 핵심 기술 인공지능의 단계: 초인공지능, 강인공지능, 약인공지능데이터에 대한 이해 데이터 수집 -&gt; 모델 정립 (가설) -&gt; 예측 기계 학습: 데이터를 설명할 수 있는 학습 모델을 찾아내는 과정 주어진 과업에 적합한 다양한 데이터를 충분한 양만큼 수집 =&gt; 과업 성능 향상간단한 기계 학습의 예 목적 함수 (비용 함수, Objective function, Cost function) 과업을 달성하기 위해 모델의 성능이 개선되는지 객관적으로 확인할 수 있는 지표 비용 함수의 예 중 하나는 평균제곱오차 (Mean Squared Error, MSE) 비용 함수를 최소화 시킬 수 있는 파라미터를 찾는 것이 목표 조금 더 현실적인 상황: 실제 세계는 선형 데이터가 아니고 잡음이 섞임 (비선형 모델이 필요)모델 선택 과소적합 (Underfitting): 모델의 용량 (자유도)이 작아서 오차가 클 수 밖에 없는 현상 과소적합을 극복하기 위해서는 더 많은 데이터를 사용하거나, 비선형 모델을 사용하라 과잉적합 (Overfitting): 고차원으로 근사한다면, 훈련 집합에 대해 거의 완벽하게 추정 가능 하지만 새로운 데이터를 예측하는 경우에는 문제가 발생할 수 있음 모델의 용량이 크기 때문에 학습 과정에서 잡음까지도 학습해버림 따라서 적절한 용량의 모델을 선택하는 모델 선택 작업이 필요함 편향 (Bias)과 분산 (변동, Variance) =&gt; trade-off 관계 훈련집합을 여러 번 수집하여 1~12차에 반복해서 적용하는 실험 저차원에서는 오차가 크고, 편향도 큼. 하지만 비슷한 모델을 얻음 (낮은 변동) 고차원에서는 오차가 작고, 편향도 작음. 하지만 크게 다른 모델을 얻음 (높은 변동) 용량이 작은 모델 (과소적합)은 편향이 크고, 분산이 작음 용량이 복잡한 모델 (과대적합)은 편향이 작고, 분산이 큼 기계 학습의 궁극적인 목표 낮은 편향과 낮은 분산을 가진 예측 모델을 만드는 것이 목표 하지만 모델의 편향과 분산은 상충 관계 따라서 편향을 최소로 유지하며, 분산도를 최대로 낮추는 전략이 필요함 모델의 용량이 증가한다는 것은 편향이 감소하고, 분산이 증가하는 경향이 있음 검증집합을 이용한 모델 선택 훈련집합과 테스트집합과 다른 별도의 검증집합 (Validation set)을 가진 상황 부트스트랩 (Bootstrap) 임의의 복원 추출 샘플링 (Sampling with replacement) 반복 데이터 분포가 불균형 일 때 사용 현대 기계 학습의 전략 용량이 충분히 큰 모델을 선택한 후에, 선택한 모델이 정상을 벗어나지 않도록 여러 규제 (Regularization) 기법을 적용 데이터 확대: 데이터를 많이 수집할수록 일반화 능력이 향상됨 가중치 감쇠: 개선된 목적함수를 이용하여 가중치를 작게 조절하는 규제 기법 지도 방식에 따른 유형 지도 학습 (Supervised Learning) 특징 벡터와 목표치 (정답)가 모두 주어진 상황 회귀와 분류 문제로 구분 비지도 학습 (Unsupervised Learning) 특징 벡터는 주어지는데, 목표치가 주어지지 않는 상황 (정답이 없음) 군집화 (Clustering), 밀도 추정 (Density estimation), 특징 공간 변환 (PCA) 과업 강화 학습 (Reinforcement Learning) 상대적인 목표치가 주어지는데, 지도 학습과 다른 형태 (보상) 준지도 학습 (Semi-supervised Learning) 일부는 특징 벡터와 목표치를 모두 가지지만, 나머지는 특징 벡터만 가지는 상황 최근, 대부분의 데이터가 특징 벡터 수집은 쉽지만, 목표치는 수작업이 필요하여 최근 중요성 부각 다양한 기준에 따른 유형 오프라인 학습과 온라인 학습 (Offline, Online Learning) 보통은 오프라인 학습을 다룸 온라인 학습은 IoT 등에서 추가로 발생하는 데이터 샘플을 가지고 점증적 학습 수행 결정론적 학습과 확률적 학습 (Deterministic, Stochastic Learning) 결정론적에서는 같은 데이터를 가지고 다시 학습하면 같은 예측 모델이 만들어짐 확률적 학습은 학습 과정에서 확률 분포를 사용하므로, 같은 데이터로 학습하면 다른 예측 모델이 나옴 분별 모델과 생성 모델 (Discriminative, Generative Models) 분별 모델은 부류 예측에만 관심. 즉, P(y|x)의 추정에 관심 생성 모델은 P(x) 또는 P(x|y)를 추정하여 새로운 샘플을 생성하여 사용할 수 있음 2. 기계학습과 수학 리뷰기계학습에서 수학의 역할 수학은 목적함수를 정의하고, 목적함수의 최저점을 찾아주는 최적화 이론 제공 최적화 이론에 학습률, 멈춤 조건과 같은 제어를 추가하여 알고리즘 구축벡터와 행렬 백터 (Vector): 샘플을 특징 벡터 (Feature vector)로 표현 행렬 (Matrix): 여러 개의 벡터를 담음, 훈련 집합을 담은 행렬을 설계 행렬 (Design matrix)이라고 부름 전치 행렬 (Transpose matrix): 행 요소와 열 요소를 뒤바꾼 것 행렬을 이용하면, 방정식을 간결하게 표현 가능 특수 행렬들 정사각행렬 (정방행렬, Square matrix) 대각행렬 (Diagonal matrix) 단위행렬 (Identity matrix) 대칭행렬 (Symmetrix matrix) 행렬 연산: 행렬 곱셈, 벡터의 내적 (Inner product) 텐서 (Tensor): 3차원 이상의 구조를 가진 숫자 배열 (array) 0차: 수 (Scalar), 1차: 벡터 (Vector), 2차: 행렬 (Matrix) 유사도 (Similarity)와 거리 (Distance): 벡터를 기하학적으로 해석 (코사인 유사도) 벡터와 행렬의 거리 (크기)를 놈 (Norm)으로 측정 행렬의 프로베니우스 놈 (Frobenius norm)으로 행렬의 크기 측정 가능 1차 놈 (Manhattan distance) 2차 놈 (Euclidean distance) 퍼셉트론의 해석 퍼셉트론 (Perceptron): 1958년에 고안한 분류기 (Classifier) 모델, 활성 함수는 계단 함수 사용 다중 퍼셉트론 (Multi-layer perceptron) 추론 (Inferring)은 학습을 마친 알고리즘을 현장의 새로운 데이터에 적용하는 작업 훈련 (Training)은 훈련 집합의 샘플에 대하여 가장 잘 설명할 수 있는 가중치를 찾아내는 작업 현대 기계학습에서 심층학습은 퍼셉트론을 여러 층으로 확장하여 만듦 선형결합과 벡터공간 벡터: 공간 상의 한 점으로 화살표 끝이 벡터의 좌표에 해당 선형결합이 만드는 벡터공간: 기저 벡터 a와 b의 선형 결합 (Linear combination) 선형결합으로 만들어지는 공간을 벡터공간 (Vector space)이라고 부름역행렬 다음의 성질은 서로 필요충분조건 A는 역행렬을 갖음. 즉, 특이행렬이 아님 A는 최대계수를 갖음 A의 모든 행과 열이 선형독립임 A의 행렬식은 0이 아님 A의 고윳값은 모두 0이 아님 행렬 분해 분해 (Decomposition): 정수 3717은 특성이 보이지 않지만, 3*3*7*59로 소인수 분해하면 특성이 보임 고윳값 (Eigenvalue), 고유 벡터 (Eigenvector) 고유 분해 (Eigen-decomposition)는 고윳값과 고유 벡터가 존재하는 정사각행렬에만 적용 가능 하지만 기계학습에서는 정사각행렬이 아닌 경우의 분해도 필요하기 때문에 고유 분해는 한계가 있음 특잇값 분해 (Singular Value Decomposition, SVD) 등장 - 정사각행렬이 아닌 행렬의 역행렬 계산에 사용 확률과 통계 기계학습이 처리할 데이터는 불확실한 세상에서 발생하므로, 불확실성 (Uncertainty)을 다루는 확률 및 통계가 필수 확률 변수 (Random variable) 확률 분포 (Probability distribution): 확률질량함수 &amp; 이산확률변수, 확률밀도함수 &amp; 연속확률변수 확률 벡터 (Random vector): 확률변수를 요소로 갖음 확률 기초: 곱 규칙 (Product rule), 합 규칙 (Sum rule) 조건부 확률, 연쇄법칙 (Chain rule), 독립 (Independence), 조건부 독립, 기댓값 베이즈 정리와 기계학습 베이즈 정리 (Bayes’ rule) 사후 (Posteriori) 확률 = 우도 (Likelihood) 확률 * 사전 (Prior) 확률 사후 확률을 직접 추정하는 일은 아주 단순한 경우를 빼고 거의 불가능 따라서 베이즈 정리를 이용하여 추정최대 우도 매개변수 (모수, Parameter)를 모르는 상황에서 매개변수를 추정하는 문제 어떤 확률변수의 관찰된 값들을 토대로 그 확률변수의 매개변수를 구하는 방법 (최대 우도, Maximum Likelihood)평균과 분산 데이터의 요약 정보로서 평균 (Mean)과 분산 (Variance) 평균 벡터 (치우침 정도)와 공분산 행렬 (Covariance matrix) - 확률변수의 상관정도유용한 확률분포 가우시안 분포 (Gaussian distribution): 평균과 분산으로 정의 다차원 가우시안 분포: 평균 벡터와 공분산행렬로 정의 베르누이 분포 (Bernoulli distribution): 성공 확률 p이고, 실패 확률이 1-p인 분포 이항 분포 (Binomial distribution): 성공 확률이 p인 베르누이 실험을 m번 수행할 때, 성공할 횟수의 확률분포 로지스틱 시그모이드 함수 (Logistic Sigmoid function): 일반적으로 베르누이 분포의 매개변수를 조정을 통해 얻음 소프트플러스 함수 (Softplus function): 정규 분포의 매개변수의 조정을 통해 얻음 지수 분포 (Exponential distribution) 라플라스 분포 (Laplace distribution) 디랙 분포 (Dirac distribution) 혼합 분포들 (Mixture distribution): 3개의 요소를 가진 가우시안 혼합 분포 변수 변환 (Change of variables): 기존 확률변수를 새로운 확률변수로 바꾸는 것정보이론 정보이론: 사건 (Event)이 지닌 정보를 정량화 할 수 있을까? 정보이론의 기본 원리: 확률이 작을수록 많은 정보 자주 발생하는 사건보다, 잘 일어나지 않는 사건 (Unlikely event)의 정보량 (Informative)이 많음 정보이론과 확률통계는 많은 교차점을 가짐, 확률통계는 기계학습의 기초적인 근간 제공 정보이론 관점에서도 기계학습을 접근 가능: 엔트로피, 교차 엔트로피, KL 발산, 상대 엔트로피 자기 정보 (Self information): 사건 (메시지)의 정보량 엔트로피 (Entropy): 확률변수 x의 불확실성을 나타내는 엔트로피, 모든 사건 정보량의 기댓값으로 표현 모든 사건이 동일한 확률을 가지 때 즉, 불확실성이 가장 높은 경우에 엔트로피가 최고임 교차 엔트로피 (Cross entropy): 두 확률분포 P와 Q 사이의 교차 엔트로피 심층학습의 손실함수로 많이 사용 교차 엔트로피를 손실함수로 사용하는 경우, KL 발산의 최소화 함과 동일 KL 다이버전스: 두 확률분포 사이의 거리를 계산할 때 주로 사용 가지고 있는 데이터 분포 P(X)와 추정한 데이터 분포 Q(X) 간의 차이를 최소화하는데 교차 엔트로피 사용 최적화 기계학습의 최적화는 단지 훈련집합이 주어지고, 훈련집합에 따라 정해지는 목적함수의 최저점으로 만드는 모델의 매개변수를 찾아야 함 주로 확률적 경사 하강법 (Stochastic gradient descent, SGD) 사용매개변수 공간의 탐색 특징 공간의 높은 차원에 비해 훈련 집합의 크기가 작아서 참인 확률분포를 구하는 일은 불가능 따라서 기계학습은 적절한 모델 (가설)을 선택하고, 목적함수를 정의하여 모델의 매개변수 공간을 탐색 그리고 목적함수가 최저가 되는 최적점을 찾는 전략 사용 특징 공간에서 해야 하는 일을 모델의 매개변수 공간에서 하는 일로 대치 최적화 문제 해결: 낱낱 탐색 (Exhaustive search) 알고리즘, 무작위 탐색 (Random search) 알고리즘 경사 하강법 (미분 활용) 미분 미분에 의한 최적화: 1차 도함수는 함수의 기울기 (경사), 즉 값이 커지는 방향을 지시 편미분 (Partial derivative): 변수가 복수인 함수의 미분, 미분 값이 이루는 벡터를 경사도라고 부름 기계학습에서 편미분: 매개변수 집합은 복수 매개변수이므로, 편미분을 사용 최적화는 예측 단계가 아닌, 학습 단계에서 필요함경사 하강 알고리즘 경사 하강법 (Gradient descent)는 낮은 곳을 찾아가는 원리 함수의 기울기 (경사)를 구하여 기울기가 낮은 쪽으로 반복적으로 이동하여 최솟값에 도달 집단 (무리, Batch) 경사 하강 알고리즘 샘플의 경사도를 구하고 평균한 후에 한꺼번에 갱신 훈련 집합 전체를 다 봐야 갱신을 일어나기 때문에 학습 과정이 오래 걸린다는 단점 존재 정확한 방향으로 수렴하긴 하지만, 속도가 느리다는 단점 확률론적 경사 하강 (SGD, Stochastic Gradient Descent) 알고리즘 한 샘플 혹은 작은 집단 (무리, Mini-batch)의 경사도를 계산한 후 즉시 갱신 수렴이 다소 해맬 수도 있긴 하지만, 속도가 빠르다는 장점 3. ML Basics - E2EEnd to End 머신러닝 프로젝트 큰 그림 보기 문제 정의: 지도학습 &amp; 비지도학습, 분류문제 &amp; 회귀문제, 배치학습 &amp; 온라인학습 성능측정지표: RMSE 등 데이터를 구하기 데이터 가져오기 데이터 구조 훑어보기 train, test 데이터셋 나누기 (데이터 변경이 생겨도 일관성 있는 기준을 유지하도록 하라) 데이터로부터 통찰을 얻기 위해 탐색하고, 시각화 해보기 상관관계 확인 머신러닝 알고리즘을 위해 데이터를 준비하기 데이터 수동 변환 보다는, 함수를 만들어서 자동 변환하는 것이 더 좋음 새로운 데이터에 대한 변환을 손쉽게 재생산 할 수 있음 향후 재사용할 수 있는 라이브러리 구축 가능 - 데이터 정제 (Data Cleansing) 누락된 특성 다루는 방법: 행 제거, 열 제거, 특정 값으로 채우기 (0, 평균, 중간값 등) SimpleImputer 함수 활용하기 One hot 인코딩 (OrdinalEncoder, OneHotEncoder 함수 활용하기) - 특성 스케일링 (Feature Scaling): Min max scaling, Standardization - 변환 파이프라인 (Transformation Pipeline): 순차적 변환 시, 사용 (Pipeline class) 모델을 선택하고 훈련시키기 모델을 상세하게 조정하기 솔루션을 제시하기 시스템을 론칭하고, 모니터링 및 유지보수 하기4. ML Basics - Linear Algebra 행렬의 곱셈 중요한 연산과 성질들 (정방행렬, 삼각행렬, 대각행렬, 단위행렬) Norms 선형독립과 Rank 역행렬, 직교행렬 행렬식 이차형식 고유값, 고유벡터 행렬미분5. 6주차 돌아보기 기간: 2022. 10. 24 ~ 2022. 10. 29 출처: 프로그래머스 인공지능 데브코스 4기 6주차 강의 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "AI 학습용 데이터 라벨링 교육 - 데이터 기획 과정", "url": "/posts/AI-%ED%95%99%EC%8A%B5%EC%9A%A9-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%9D%BC%EB%B2%A8%EB%A7%81-%EA%B5%90%EC%9C%A15/", "categories": "Education, 인공지능 학습용 데이터 라벨링 교육", "tags": "AI, Deep learning, Machine learning, 데이터 라벨링", "date": "2022-10-17 13:00:00 +0900", "snippet": "AI Data에서 제공하는 AI 학습용 데이터 라벨링 교육의 데이터 기획 과정에 대한 강의 기록. 1. 인공지능 학습용 데이터 기획 개요데이터 기획 개요 RFP 어떤 데이터가 필요한가? 어떻게 데이터를 수집 및 획득할 것인가? 어떻게 데이터를 정제할 것인가? 어떠한 라벨을 이용하여 가공할 것인가? 완성된 인공지능 학습용 데이터를 어떻게 활용할 수 있는가?데이터 기획이 왜 필요한지? 기술 구현을 위한 데이터 수요가 폭증 산업 및 공공의 발전을 견인하는 데이터 기획 필요성이 증대 똑똑한 인공지능을 만들기 위해서는 품질 좋은 대량의 학습 데이터가 필요함RFP (Request For Proposal, 제안요청서) 과제의 수행에 필요한 요구사항을 체계적으로 정리 사용자의 제안이 잘 실행되고 있는지 판단하기 쉽게 만들어줌 RFP가 구체적일수록 제안서의 품질이 높아진다고 할 수 있음 RFP = 제안서 = 계약서인공지능 학습용 데이터 구축 RFP 데이터 개요: 어떤 데이터?, 무엇을 위한 것?, 어떻게 구축?, 얼마만큼 구축? 데이터 구축 목적: 연구 목적, 산업 목적, 활용 방안 데이터 구축 방법: 데이터 구성, 수집 장비 및 방법, 가공 방법, 비식별화 방법 데이터 규모: 데이터 수량 및 형태, 비용 산정2. 인공지능 학습용 데이터 기획 수행 방법개요 유형 및 도메인 선정: 글로벌 기술 동향 및 시장 전망 참고 과제 발굴: 산학연 수요에 맞는 데이터 과제 발굴 (Top-down, Bottom-up) RFP 작성: RFP 자문단 운영 및 과제별 요구사항 구체화데이터 구축 공정 단계별 고려사항 데이터 생애주기는 계획, 구축, 운영, 활용 영역으로 구분 구축 프로세스 품질 관리 구축 데이터 품질 관리 개방 데이터 품질 관리데이터 활용 목적 설정 범용 데이터 학습용 데이터 구축 세부 도메인의 특수 목적의 인공지능 학습용 데이터 구축 국가 전략과의 Alignment AI 학습용 데이터의 활용성 고려 AI 기술 발전 트렌드를 고려 공공성목적에 맞는 데이터 조사 데이터 유형은? 데이터 규모는? 원천 데이터와 라벨은 어떻게 구성해야? 개인정보에 대한 비식별화가 필요한지? 중복성 조사도 중요!3. 인공지능 학습용 데이터 인공지능 서비스는 데이터를 기반으로 모델을 생성하고, 최종 서비스 제공 데이터 설계: 데이터 구축 공정을 개발하여 데이터 작업자에게 제공 데이터 수집: 가공할 원천 데이터를 온오프라인 수집, 제작, 축적 데이터 가공: AI가 인지하고 판단할 정보를 라벨링 데이터 확장: 고차원 정보를 추가하여 데이터 정확도, 규모 확대 데이터 검증: 데이터 품질을 정기적으로 검증, 적합성 평가 4. 구축 공정 개요 임무정의: 구축 계획서 데이터 획득: 원시 데이터 데이터 정제: 원천 데이터 데이터 라벨링: 라벨링 데이터 데이터 학습: 학습 데이터셋5. 학습용 데이터 가치 평가 시장 가치: 시장의 수요 (필요성) 기술: 산업 파급 효과, 데이터 구축 용이성, AI 서비스 기술 구현 가능성, 법제도적 제약 정책: 공공성 획득 시 개인정보가 포함되어 있는 경우 획득 시 저작권, 지적재산권, 초상권 등 이용에 제한 있는 경우 데이터를 직접 제작해야 하는 경우 출처: AI Data 2022년 인공지능 학습용 데이터 라벨링 전문 교육 -&gt; 강의 소개 홈페이지" }, { "title": "AI 학습용 데이터 라벨링 교육 - 보안 과정", "url": "/posts/AI-%ED%95%99%EC%8A%B5%EC%9A%A9-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%9D%BC%EB%B2%A8%EB%A7%81-%EA%B5%90%EC%9C%A14/", "categories": "Education, 인공지능 학습용 데이터 라벨링 교육", "tags": "AI, Deep learning, Machine learning, 데이터 라벨링", "date": "2022-10-17 13:00:00 +0900", "snippet": "AI Data에서 제공하는 AI 학습용 데이터 라벨링 교육의 보안 과정에 대한 강의 기록. 데이터 품질 오남용을 예방하기 위하여 보안 교육을 받음.1. 인공지능 데이터 보호의 개요 인공지능 데이터 보호 프라이버시 침해, 데이터 유출로 인한 피해를 막기 위한 방법 학습용 데이터를 토대로 만들어진 인공지능 모델에 대한 보호 학습용 데이터 품질에 있어 오남용 (Abuse)을 예방하기 위한 신뢰성 프레임워크 적용 방법 인공지능 데이터 보호의 필요성 인공지능 데이터 보호의 목적 학습 데이터셋의 오남용 방지를 위한 신뢰성 확보의 필요성 AI 서비스 ‘이루다’의 개인정보 유출 사례: ‘이루다’의 혐오표현이 학습되어 데이터 보호가 되지 못함 AI 서비스 ‘심심이’의 부적절한 학습 데이터셋을 이용한 결과: 성차별적인 문제를 일으킴 AI를 이용한 정치인 얼굴 합성 변조 사례 AI를 개발을 위한 이미지 무단 도용 사례: 개인정보 오남용 페이스북의 얼굴 인식, ‘태그’ 중단 페이스북의 개인정보 오남용 사례 기술: 얼굴인식 서식 (템플릿) 사례 분석2. 인공지능 데이터 보안 항목 인공지능 학습용 데이터 구축 프로세스 임무 정의 -&gt; 데이터 획득 및 수집 -&gt; 데이터 정제 -&gt; 데이터 라벨링 -&gt; 데이터 학습 데이터 획득 및 수집, 데이터 정제 단계에서는 개인정보나 민감정보 등에 대한 검토 및 수정 필요 데이터 라벨링 단계에서는 허수에 의한 거짓 데이터를 학습하는 행위 등을 조심해야 함 데이터 학습 단계에서는 과적합 학습 배제가 필요함 3. 인공지능 학습용 데이터 도메인 및 유형 데이터란, 수, 영상, 단어 등의 형태로 이루어진 의미 단위로 정보를 구성하는 자료 학습용 데이터란, 머신러닝, 딥러닝 등 AI 모델 학습을 위해 활용되는 데이터를 총칭 이미지: 정사각형 모양의 아주 작은 픽셀들의 집합 축소하거나, 확대하면 이미지의 질이 손상 한 면적에 픽셀을 얼마나 넣는가에 따라 해상도, 용량에 영향 JPG, PNG, TIFF, GIF 등 동영상: 여러 개의 정지 사진을 연속적으로 보여주는 것 하나의 정지 사진이 프레임 (Frame) 초당 프레임 (Frame per Second)가 높을수록 부드럽게 영상이 재생 AVI, MP4, WMV, MKV 등 텍스트: 이미지, 영상, 오디오 등 아무것도 포함되어 있지 않고 순수하게 글만 있는 데이터 글꼴, 기울임, 글씨 크기 등과 같은 데이터도 포함되어 있지 않음 글을 추출하는 파싱과 데이터에 포함되어 있는 단어를 숫자로 표현 (임베딩)하여 사용 TXT, CSV, XML, HTML 등 오디오: 소리, 진동, 파형에 대한 정보를 포함하고 있는 데이터 물체의 진동을 통해서 소리가 발생하고 전달됨 물체의 진동을 파형으로 표현하고 연속적인 그래프로 표현할 수 있음 MP3, ACC&lt; FLAC, WAV 등 센서와 통계: 다양한 센서를 통해서 얻은 정보를 디지털 값으로 변환한 데이터 환경 변화나 사건을 감지하여 다른 전자장치에서 감지된 정보를 인식할 수 있게 해주는 시스템 임베디드 시스템을 통해 출력 값을 숫자로 받거나, 파형의 형태로 출력할 수 있음 객체 생성 및 영상 제작: 영상에 있는 물체 혹은 사람이 무엇인지 인지하기 위한 데이터 경계 박스를 표시하여 객체를 상자 안에 가둠 경계 박스에 있는 객체에 대한 자세한 라벨을 달 수 있고, 비슷한 객체를 생성할 수도 있음 4. 인공지능 학습용 데이터 획득/수집 시 보안 데이터 수집부터 시작하는 Abuse를 예방하기 위한 보안 데이터 버전 관리, 기관 인증, 생명주기 등이 함께 관리되어야 함 따라서 데이터 거버넌스 프레임워크가 필요하다고 할 수 있음 데이터 거버넌스: 데이터의 가용성, 유용성, 통합성, 보안성을 관리하기 위한 정책 및 프로세스를 수립하는 것 유용한 데이터 유형 및 품질 표준 정의 데이터 관리에 대한 역할 할당 및 책임 정의 데이터 거버넌스 구현 계획 데이터의 가용성 보장 데이터의 무결성 보장 데이터 정책에 대한 책임 및 준수 강화 지속적인 피드백 및 모니터링 데이터 거버넌스를 위해서 메타 데이터 관리가 필요함 메타 데이터 관리를 위한 데이터 레이크5. 인공지능 학습 데이터와 민감정보 비식별화 개인정보: 특정 개인에 관한 정보, 개인을 알아볼 수 있게 하는 정보 (이름, 주민등록번호 등) 가명정보: 추가 정보의 사용 없이는 특정 개인을 알아볼 수 없게 조치한 정보 익명정보: 더이상 개인을 알아볼 수 없게 복원 불가능할 정도로 조치한 정보 개인정보 비식별화: 개인정보에서 개인식별 요소를 제거하여 특정 개인을 알아볼 수 없는 형태로 만드는 조치 가명처리, 총계처리, 데이터 삭제, 데이터 범주화, 데이터 마스킹 등 여러가지 기법을 단독 또는 복합적으로 사용 가명처리 기법만 단독 활용된 경우에는 충분한 비식별화 조치로 보기 어려움 비식별화 관련 대표 모델 k-익명성: 단순 삭제, 헤드라인 간단하게. 한 개인이 k명의 다른 사람과 구별되지 않아야 함 L-다양성: 데이터 테이블의 필드값이 적어도 L개의 다양한 민감 정보를 가지고 있어야 함 T-근접성: 민감한 정보의 분포와 전체 데이터의 민감한 정보의 분포 차이를 T 이하로 만들어서 프라이버시 보호 6. 비식별화 오픈소스 도구 ARX (Data Anonymization Tool): 텍스트 기반 비식별화 도구 제공, 유료로 이미지 영상 비식별화 지원 Amnesia: 텍스트 기반 비식별화 도구 제공, 유료로 이미지 영상 비식별화 지원 sdcMicro: 텍스트 기반 비식별화 도구 제공, 유료로 이미지 영상 비식별화 지원7. 데이터 관리 클라이언트 보안 클라이언트의 보안 사용자 권한과 접근을 제어하고, 로그 기록 등으로 내부 및 외부 접근을 통제 인증 (Authentication): 접근 통제 요소, 식별, 인증, 인가, 책임추적성 데이터 보호: 허락되지 않은 사용자나 시스템 접근을 통제하여 데이터 노출을 막는 기밀성 유지 필요 기밀성 (Confidentiality), 무결성 (Integrity), 가용성 (Availability) 데이터 암호와: 데이터 송수신시에는 암호화가 필수 복호화 되지 않도록 암호화 접근 통제: 인증된 사용자가 접근할 수 있는 데이터를 통제하는 것 모니터링: 접근 통제에 대한 정책을 계속해서 모니터링 하고 알림을 수신 받아 이상 징후 식별, 탐지 8. 과적합 (Overfitting) 과대적합이라고도 하고, 인공지능 모델을 학습할 때, 인공지능 학습용 데이터를 과하게 학습하는 것 학습용 데이터에서 최적의 결과를 만들었지만, 인공지능 학습용 데이터 외 새로운 데이터에서는 오차가 커지는 문제 학습이 충분히 이뤄지지 않은 과소적합 (Underfitting)과 반대되는 개념과적합 방지 방법 데이터 증식: 학습용 데이터를 추가적으로 더 수집하는 것 이미지 데이터: 이미지 회전, 세로 및 가로로 늘이기, 이미지 상하좌우 반전 텍스트 데이터: 역번역, 특정 단어 유의어 교체, 임의의 단어를 삽입하거나 삭제 학습 데이터의 대표성: 실제 세상의 데이터 표본으로 여길 수 있을 만큼의 통계적 유사성을 가져야 함 전이학습 (Transfer Learning): 데이터의 다양성 및 대표성을 보완할 수 있는 보조적인 기법 조기 종료: 학습용 데이터에서 학습 데이터 외에 검증 데이터를 준비하여 검증 데이터에 대한 오차를 계산하고, 오차가 감소하다가 다시 증가하는 구간에서 학습 조기 종료 가중치 규제: 딥러닝에서 사용되는 과적합 방지 방법 (손실함수에 패널티를 추가) L1: 가중치들의 절댓값을 손실 함수에 추가하는 방법 L2: 모든 가중치의 제곱합을 손실 함수에 추가하는 방법 Dropout: 딥러닝 학습을 진행할 때, 생성되는 노드들을 무작위로 비활성화 시키는 방법 DropConnect: 랜덤으로 노드를 비활성화 하는 것이 아닌, 가중치를 0으로 만들어서 가중치 값을 생략 노이즈 추가: 인공지능 학습용 데이터 외에 학습에 방해가 될 수 있는 요소를 일부러 넣어주는 방법 배치: 학습용 데이터 중 일부 데이터셋을 뜻하는 것 (Batch 단위로 학습하여 속도를 개선) 정규화: 학습이 진행 될 때, 입력 값의 범위가 너무 크면 계산하는데 시간이 오래 걸리고, 오차가 커짐 배치 정규화: 배치 단위로 정규화 시키는 것 원핫 인코딩: 답에는 1, 나머지는 0으로 표현하는 방식 라벨 스무딩: 확실하게 0과 1로 라벨링 된 값을 0에서 1 사이의 값을 변형하여 라벨을 부드럽게 만듦 출처: AI Data 2022년 인공지능 학습용 데이터 라벨링 전문 교육 -&gt; 강의 소개 홈페이지" }, { "title": "AI 학습용 데이터 라벨링 교육 - 이미지/영상 입문 과정", "url": "/posts/AI-%ED%95%99%EC%8A%B5%EC%9A%A9-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%9D%BC%EB%B2%A8%EB%A7%81-%EA%B5%90%EC%9C%A13/", "categories": "Education, 인공지능 학습용 데이터 라벨링 교육", "tags": "AI, Deep learning, Machine learning, 데이터 라벨링", "date": "2022-10-17 13:00:00 +0900", "snippet": "AI Data에서 제공하는 AI 학습용 데이터 라벨링 교육의 이미지/영상 입문 과정에 대한 강의 기록. 이미지와 영상 분야에서 데이터 라벨링 기법과 적용 사례를 학습하고, datamaker의 라벨링 도구 사용해보기.1. 데이터 라벨러 직무 및 전망 데이터 라벨러: 데이터 정제 및 데이터 라벨링을 수행하는 사람 AI가 학습할 수 있도록 데이터에 정보 (어노테이션)를 부착하는 활동 인공지능은 라벨링 데이터를 바탕으로 개발되기 때문에 데이터 라벨러의 역할은 매우 중요 데이터 라벨러는 체계적인 교육과정 운영과 산업 현장에 필요로 하는 인재 양성을 위해 NCS 정의가 진행 중 데이터 라벨러, 데이터 검수자, QM, PM 인공지능 개발 프로세스 이해, 프로젝트 이해, 라벨링 가이드라인 이해, 데이터 라벨링 수행, 관리자와 소통2. 데이터 학습 처리 과정 원시 데이터 (Raw data): 기계학습을 목적으로 획득 단계에서 수집 및 생성한 음성, 이미지, 영상, 텍스트 등의 데이터 원천 데이터 (Source data): 원시 데이터를 라벨링 공정에 투입하기 위해 필요한 전처리 등 정제 작업을 수행한 데이터 원천 데이터는 라벨링 데이터가 부여되지 않은 상태의 데이터 기계학습 (Machine Learning): 인간이 자연적으로 수행하는 학습 능력을 컴퓨터에서 실현하려는 기술, 방법 인공지능 (Artificial Intelligence): 인간의 지능이 갖는 학습, 추리, 적응 등의 기능을 갖춘 컴퓨터 시스템 데이터 라벨링 (Data labeling): 기계학습에 활용되도록 기능, 목적에 부합하는 정보를 원천 데이터에 부착하는 활동 데이터 라벨러 (Data labeler): 데이터 라벨링을 수행하는 사람 PM (Project Manager): 프로젝트 전반의 전략 수립과 운영을 맡아 관리하는 직책 QM (Quality Manager): 데이터 수집, 가공 및 검수, 인력 관리를 맡아 데이터 품질을 관리하는 직책 라벨 (Label): 데이터와 그에 부착된 라벨링 정보들 (어노테이션)을 지칭하는 용어 어노테이션 (Annotation): 라벨링 공정에서 인간이 부여한 식별 기준을 기계가 이해하도록 데이터에 추가한 정보 라벨링 데이터 (Labeled data): 원천 데이터에 부여한 파일 형식, 해상도, 설명, 주석 등의 어노테이션 집합 클래스 (Class, 카테고리): 분류 및 탐지하고자 하는 대상을 카테고리화 한 것으로, 분류체계를 의미3. 인공지능 개발 프로세스의 이해 데이터 수집: 개발할 AI의 목적에 맞게 현실 세계에서 필요한 데이터를 수집 및 생성 데이터 가공: 라벨링 규칙에 따라 원천 데이터에 정보 (어노테이션)를 부착 데이터 검수: 라벨링 데이터가 규칙에 맞게 라벨링 되었는지 검수 인공지능 모델 학습: 데이터와 라벨링 데이터로 기계학습을 진행하여 인공지능 모델을 생성 AI 서비스 개발: AI 서비스를 개발하고, 배포4. 데이터 라벨링 기법 및 적용 사례 바운딩 박스: 객체의 범위를 사각형 박스로 지정하는 라벨링 기법, 객체 탐지 모델에 주로 사용 3D 바운딩 박스 (Cuboid): 객체의 범위를 직육면체 박스로 지정하는 라벨링 기법, 너비, 높이, 깊이, 방향 정보 포함 OCR (Optic Character Recognition): 이미지, 영상 속 문자를 기계가 읽을 수 있는 문자로 변환하는 라벨링 기법 키포인트: 객체의 주요 지점 (특징)을 점으로 지정하는 라벨링 기법, 이미지 배칭 및 안면 인식, 골격 추출 등에 활용 폴리라인: 선형 객체의 경계나 위치 등을 연속선으로 지정하는 라벨링 기법 폴리곤: 객체의 범위 또는 경계를 다각형으로 지정하는 라벨링 기법, 정교한 인공지능 모델 개발에 사용 시멘틱 세그멘테이션: 이미지의 모든 픽셀에 클래스를 부여, 높은 정확도를 요구하는 CV 기반 응용 프로그램에 사용 비디오 어노테이션: 영상에서 구간 정제, 분류, 객체 태깅 방법. 객체 인식, 객체 추적 등에 주로 사용5. 데이터 라벨링 도구 소개용어 정리 프로젝트: 특정 목표를 성취하기 위해 데이터, 라벨링, 자원/품질 관리 등을 실행하는 과제 단위 저작도구 (Authoring tool, Annotator): 저작에 사용되는 소프트웨어 라벨링 가이드라인: 라벨링 작업 방식과 기준이 기재된 문서 객체 (Object): 라벨링 대상 검수 (Review): 기준에 적합하게 라벨링 되었는지 검사. 작업 완료된 라벨은 검수를 거쳐 반료/완료로 전환 반려 (Return): 기준에 적합하게 라벨링 되지 않아 검수를 통과하지 못한 라벨로, 수정하여 다시 검수해야 함 코멘트: 반려된 라벨을 수정 시 반려 사유를 기재한 평가글도구 (Open source) 소개 CVAT (Computer Vision Annotation Tool): Intel에서 개발한 웹 (크롬) 기반 저작도구 Diffgram: 웹형/설치형 저작도구, 데이터셋 및 워크플로우 관리 기능 Label box: 설치형 저작도구, 자동 라벨링 기능, 관리 및 협업 기능 Labellmg: 설치형 저작도구, 바운딩 박스만 지원 Label Studio: 설치형 저작도구, 다양한 자동 라벨링, 커뮤니티 활성화 VIA (VGG Image Annotator): 설치형 저작도구, 안면 추적 기능, 이미지 리스트에 대한 효과적인 라벨링 가능 VoTT (Visual Object Tagging Tool): Microsoft에서 개발한 설치형 저작도구, 자동 라벨링 기능 출처: AI Data 2022년 인공지능 학습용 데이터 라벨링 전문 교육 -&gt; 강의 소개 홈페이지" }, { "title": "AI 학습용 데이터 라벨링 교육 - 음성/텍스트 입문 과정", "url": "/posts/AI-%ED%95%99%EC%8A%B5%EC%9A%A9-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%9D%BC%EB%B2%A8%EB%A7%81-%EA%B5%90%EC%9C%A12/", "categories": "Education, 인공지능 학습용 데이터 라벨링 교육", "tags": "AI, Deep learning, Machine learning, 데이터 라벨링", "date": "2022-10-17 13:00:00 +0900", "snippet": "AI Data에서 제공하는 AI 학습용 데이터 라벨링 교육의 음성/텍스트 입문 과정에 대한 강의 기록. 음성/텍스트 전사 (라벨링)에 사용되는 저작도구에 대한 사용법 학습 후 실습을 통해 기본적인 작업 학습. 맞춤법, 정제 저작도구, 전사 규칙 등에 대해 학습.1. 용어 개념 정의 전사: 말소리를 음성 문자로 옮겨 적음 속기: 빨리 적다, 속기법으로 적은 기록 음성 싱크 작업: 재생되는 음성과 문자의 내용을 일치시켜 주는 작업 비식별화 작업: 이름이나 전화번호 등 개인정보가 있는 데이터를 전사 단계에서 특정 기호로 표기하는 방법 이중 전사 작업: 비표준어가 음성 파일에서 나타났을 때, 표준어와 함께 표기하는 작업2. 음성/텍스트 데이터의 학습 처리 과정 수집 (녹음) -&gt; 정제 -&gt; 검사 -&gt; 전사 -&gt; 검사 -&gt; 최종 검수 과정을 거쳐 학습 데이터로 완성 원시 데이터 수집 (녹음): 음성 데이터를 얻기 위한 단계. 녹음된 파일도 저작권이 있어서 사전에 이용 허락을 받음 데이터 정제: 음성 원시 데이터 다운로드 및 정제 후, 관리 FTP에 결과물 등록 1&amp;2차 검수: 정성적, 정량적 평가를 통해 데이터의 유효성을 판별 전사: 음성 정제 데이터 다운로드, 전사 작업, 관리 FTP에 결과물 등록 최종 검수: 3차 검수, JSON 변환, 관리 FTP에 결과물 등록 학습: 전처리, 음향모델 학습, 언어모델 학습, 추론3. 데이터 정제/전사 저작도구 및 규칙 음성 데이터 정제 도구 - Audacity 전사 데이터 저작 도구 - 전사툴4. 음성/텍스트 데이터의 학습 처리 유형음성 데이터 전사 (받아쓰기) 방법에 따른 분류 일반 전사: 사람이 말한 그대로 문자화하여 전사하는 방법 (발음 전사) 이중 전사: 한글 맞춤법 표기에 따른 발음과 차이가 있는 경우에 발음 전사와 철자 전사를 병행 화자 전사: 음성 데이터 상에서 등장하는 사람이 여럿일 때 음성마다 화자를 구분하는 작업 배경음 및 화자 감정 태깅: 드라마 등에서 배경음이 나오는 구간을 음성 싱크를 설정하여 태깅하고, 감정이 섞인 음성을 발화했을 때 해당 구간만 음성 싱크를 설정하고, 발화 내용을 전사하는 작업 방송 영상 자막 사전 제작: 청각 장애인을 위해 영화와 같은 프로그램의 내용의 자막을 사전에 제작하는 작업음성 데이터 전사 (받아쓰기) 주체에 따른 분류 사람에 의한 전사: 사람이 직접 전사하는 작업 STT (Speech To Text): 기계가 직접 전사하는 작업음성 데이터 기관에 따른 분류 연구 기관의 과제 전사: AI 엔진의 학습을 위해 정부 연구 기관에서 진행하는 과제에서 음성 자료를 전사하는 것 기업의 콜센터 녹취 전사: 기업에서 보유하고 있는 AI 엔진의 학습을 위해 상담원과 고객의 통화 데이터를 전사하는 것5. 음성/텍스트 데이터 학습 처리 사례 민원 (콜센터) 질의-응답 데이터: 상담원들이 전문 상담에 집중하여 원활한 업무가 진행될 수 있도록 상담사의 업무를 보조할 수 있는 서비스 구축 상담 음성 데이터: AI 상담 센터를 위한 음성 상담, 음성 인식 기술, 언어 생성 연구 및 서비스 개발 분야로 활용 자유대화 음성 (일반남녀) 데이터: 자유대화를 효과적으로 인식하기 위해 인공지능 기반 한국어 자유대화 (일상대화) 데이터 구축 자유대화 음성 (노인남녀) 데이터: 사투리, 억양 등의 발화 특성이 타 연령대와 다른 특성이 존재하여 노인 대상 음성 서비스를 위해 데이터 구축 자유대화 음성 (소아, 유아) 데이터: 소아들의 음성인식 관련 서비스가 증가되지만, 소아들의 발화 특성을 반영한 음성 데이터가 부족하여 데이터 구축 한국인 대화 음성: 다양한 환경 (연령, 원거리, 노이즈 등)을 인식할 수 있는 대화 및 음성 데이터셋 구축 한국인 외래어 발화: 인공지능 기반 한국어 음성인식 서비스의 활성화를 위한 자유대화 지식 데이터 구축6. 음성/텍스트 데이터 학습 처리 사례 WAV, TXT, JSON 포멧의 파일 형태7. 언어 모델의 정의 언어 모델은 주어진 단어나 문장을 통해 다음에 어떤 단어가 등장할지에 대한 확률을 예측하는 모형 음향 모델: 아침을 먹구 학교에 갔다. 언어 모델: 아침을 먹고 학교에 갔다. 주어진 시나리오에 맞는 Q&amp;A 대화 제작 제시된 지문을 읽고 질문을 만들거나 질문에 대한 답을 찾는 작업 일반인을 대상으로 한 텍스트 데이터 수집8. 텍스트 데이터 학습 처리 사례 논문 자료 요약: 다양한 주제의 한국어 학술 논문, 특허명세서에서 요약문을 도출하도록 AI를 훈련하기 위한 데이터셋 도서 자료 요약: 한국어 도서 원문으로부터 생성 요약문을 도출하도록 AI를 훈련하기 위한 데이터셋 도서 자료 기계 독해: 다양한 주제의 도서 자료를 활용한 기계 독해용 데이터셋 구축 일반 상식: 한국어 위키백과 내 주요 문서 15만 개에 포함된 지식을 추출하여 데이터셋 구축9. 음성 데이터 학습 처리에 필요한 맞춤법 띄어쓰기 -&gt; ‘잘’, ‘안’, ‘못’, ‘안 돼’와 ‘안돼’의 띄어쓰기 유의 헷갈리는 단어 -&gt; ‘이에요’, ‘예요’, ‘-오’, ‘-요’, ‘되’, ‘돼’, ‘안’, ‘않’, ‘안되다’, ‘안 되다’의 단어 유의 출처: AI Data 2022년 인공지능 학습용 데이터 라벨링 전문 교육 -&gt; 강의 소개 홈페이지" }, { "title": "AI 학습용 데이터 라벨링 교육 - 필수과정 (인공지능 윤리와 법)", "url": "/posts/AI-%ED%95%99%EC%8A%B5%EC%9A%A9-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%9D%BC%EB%B2%A8%EB%A7%81-%EA%B5%90%EC%9C%A11/", "categories": "Education, 인공지능 학습용 데이터 라벨링 교육", "tags": "AI, Deep learning, Machine learning, 데이터 라벨링", "date": "2022-10-17 13:00:00 +0900", "snippet": "AI Data에서 제공하는 AI 학습용 데이터 라벨링 교육의 필수과정 (인공지능 윤리와 법)에 대한 강의 기록. AI 학습용 데이터 라벨러들에게 개인정보 비식별화, 저작권, 초상권 등의 인공지능 윤리에 대한 지식과 그 필요성을 학습.1. 인공지능 개요AI 학습용 데이터셋 구축 사업 AI 제품 서비스 및 기술 개발에 활용 가치가 높은 대규모 AI 학습용 데이터 구축 및 개방, 응용 개발 AI-hub 데이터 플랫폼에서 데이터 활용 건수가 계속해서 증가하고 있음2. AI 학습용 데이터셋 구축 프로세스 데이터 생애 (Lifecycle) 관점 학습용 데이터의 생애주기는 크게 계획, 구축, 운영, 활용 영역으로 구분 각 영역의 세부 활동은 SW 프로세스 계층, 데이터 프로세스 계층, 데이터 계층, 데이터 서비스 계층 등으로 구분 비정형 보다는, 정형 데이터 위주로 데이터셋을 구축하도록 노력하고 있음2. 인공지능 윤리 및 이해AI의 양면성, 편향성, 윤리적 딜레마 기계학습 모델을 학습시키는데 사용되는 데이터가 사람이나 사회가 가지는 편견을 포함하고 있는 것을 의미 편향성을 가진 데이터를 사용하여 학습한 인공지능은 편향된 결과를 출력할 수 밖에 없고, 차별을 가져올 수도 있음 AI는 새로운 기술의 혜택을 누릴 수 있도록 도울 수 있지만, 오용되는 등의 다양한 윤리적 문제를 야기할 수 있음국내외 주요 인공지능 윤리 기준 AI에 대한 윤리적 권고사항과 개인정보 보호 지침을 발표하며, 활발히 논의 중 사람이 중심이 되는 인공지능 윤리 기준3. 인공지능 개인정보보호 신기술 확산으로 인해 개인정보 침해 가능성이 확대되고 있음 사생활 침해, 데이터 프라이버시 논란 문제인공지능과 개인정보 비식별화 개인정보 비식별화란, 개인정보에서 개인식별 요소를 제거하여 특정 개인을 알아 볼 수 없는 형태로 만드는 조치 다른 정보와 결합하여도 특정 개인을 식별하기 어렵도록 하는 일련의 조치 익명 정보: 정보 수집 단계에서 근원적으로 개인을 식별할 수 없는 형태로 수집한 정보 비식별화 정보: 개인을 식별할 수 있는 상태에서 비식별화 과정을 통해 개인을 식별할 수 없게 처리한 정보4. 인공지능 저작권과 안면인식 초상권 저작권법: 저작자의 권리와 이에 인접하는 권리를 보호하고, 저작물의 공정한 이용을 도모 AI 모델 학습에 사용되는 여러가지 데이터셋의 활용에 대한 이슈 대두 해당 데이터셋들의 주인은 누구인가, 동의 후에 사용할 수 있는가5. 인공지능 지식재산권 AI가 점차 문화, 예술의 영역으로 활동 범위를 넓혀가며, AI가 만든 결과물에 저작권을 부여할 수 있는가? AI 데이터를 구축 및 공개함에 있어서 타인의 지적재산권을 침해하지 않도록 구매, 사용계약 체결 등 적정한 조치 필요6. 인공지능 관련 경력 개발 경로 및 비전 AI 윤리, 법적 책임성 등 공통 교육을 통한 인공지능 기본 지식 함양 인공지능에 필수적인 여러 유형의 라벨링 기술 습득 필요 (다양한 데이터) 전문 라벨러 양성을 통한 고품질 데이터 양산 가능 (고품질 데이터 확보) 인공지능 데이터 구축 및 활용의 성공을 위해서는 양질의 고품질 데이터와 데이터 가공에 숙련된 라벨러가 필요 데이터 라벨링: 인공지능이 기계학습에 활용하도록 기능이나, 목적에 부합하는 정보를 원천 데이터에 부착하는 활동 라벨링 데이터: 원천 데이터에 부여한 파일형식, 해상도 등의 속성, 설명이나 주석 등이 포함된 어노테이션의 집합 국가직무능력표준 (NCS) 설계 진행 중 출처: AI Data 2022년 인공지능 학습용 데이터 라벨링 전문 교육 -&gt; 강의 소개 홈페이지" }, { "title": "프로그래머스 인공지능 데브코스 5주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-5%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-10-17 10:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스의 5주차 강의에 대한 정리입니다. 이번 주에는 파이썬을 활용한 프레임워크인 Django의 세부적인 내용들을 추가적으로 학습합니다. 또한 특별히 지금까지 학습했던 내용들을 모두 통합하여 프로젝트를 할 수 있는 Monthly project가 있습니다. 파이썬으로 데이터를 EDA 하고, 이를 웹 페이지로 구성하여 배포까지 하는 것으로 프로젝트의 목표를 잡습니다. 참고 - 다크 모드가 아닌 화이트 모드로 보시면 사진 자료를 편하게 확인 가능합니다!1. Web Application with Django Django: Python 기반 웹 프레임워크pip install djangodjango-admin startproject &lt;project_name&gt; # django 프로젝트 만들기django-admin startapp &lt;app_name&gt; # django 앱 만들기python manage.py runserver # django 실행하기python manage.py makemigrations # DB migration 만들기python manage.py migrate # default로 만든 DB 정보 반영하기 (DB 연동)python manage.py createsuperuser # 관리자 계정 생성하기 Django project and app 한 project는 아래와 같이 여러 app으로 구성 project app1 app2 app3 Django의 MVT pattern MVC: Model, View, Controller MVT: Model, View, Template URL: urls.py View: views.py Model: DB, ORM Template: html, template 언어 Django에서 view 추가하기 views.py 파일에 함수 만들기 urls.py 파일의 urlpatterns에 path 추가하기 settings.py 파일에서 INSTALLED_APPS에 페이지 이름 추가하기 Django에서는 default로 admin 페이지 확인 가능 (127.0.0.1:8000/admin) Django에서 template 추가하기 views.py 파일과 연동할 수 있는 index.html 파일 만들기 views.py 파일에서 render 함수의 인자로 1번에서 만든 index.html 받아주기 settings.py 파일에서 TEMPLATES 변수에 (index.html 파일이 있는) DIR 추가하기 template 언어를 활용하면, views.py에서 데이터를 받아올 수 있음 template 태그를 활용하면, for, if 등을 활용할 수 있음 2. Django로 동적 웹페이지 만들기 Remind: Django의 MVT pattern URL: urls.py View: views.py Template: html, css, javascript Model: models.py 데이터베이스 (RDB - Relational Database, SQL) ORM: Object (객체) Django에서 admin을 활용하여 DB 연결해보기 models.py에 class로 DB 테이블을 정의하고, 간단한 스키마를 작성 admin.py에 1번에서 만든 class 이름을 admin.site.register로 추가 정리 views.py에 보여주고자 하는 내용을 담은 함수 정의 DB와 연결하고 싶다면, models.py에 DB를 class로 정의 페이지에서 보여주고자 하는 내용을 template 디렉토리 내에 html 파일로 저장 urls.py에 보여주고자 하는 view 내용을 1번에서 정의한 함수로 URL과 함께 정의 settings.py에 INSTALLED_APPS와 TEMPLATES에 내용 추가 3. Monthly project 데이터 시각화 웹 페이지 만들기 데이터 EDA를 했던 결과를 웹 상에서 확인할 수 있도록 하는 웹 페이지 만들어보기 내가 고민했던 것들 어떤 데이터로 하면 좋을까? EDA로 어떤 것들을 보여주면 좋을까? Bootstrap 등 오픈 소스를 활용해볼 수 있을까? 내가 과거에 했었거나, 지금 하고 있는 프로젝트로 적용해볼까? 고민에 대한 생각들 사이드 프로젝트로 하는 것도 결국 웹 구현까지 계획 중이니, 지금 하고 있는 프로젝트로 해보자 수집한 텍스트 데이터로 어떠한 것들을 보여주면 좋을까? Title, Desc, URL, Issued, View_count, Download_count, Region, Label, Keywords 기본적인 데이터 조회가 가능한 News 게시판 같은 형태로 href 걸어서 메인 페이지 구성 Issued된 날짜 별 통계 시각화 Region에 따른 지역 기반 시각화 Label 별 구성 비율에 대한 시각화 (finviz 참고) View_count 및 Download_count에 따른 조회 상태에 대한 통계 시각화 Desc 전처리해서 각 데이터 별 핵심 키워드 추출하고, 그것을 보여줄 수 있는 시각화 실제 구현 index.html: Main page (Menu 구성) Overview: 전반적인 프로젝트 (웹페이지)에 대한 소개 Ref: cards.html, general.html, typography.html, blank-page-header.html Data Detail: 데이터에 대한 EDA를 기록하는 페이지 Ref: data-tables.html, general-table.html Data Search: 데이터를 얻을 수 있는 여러 소스들을 모아서 소개해주기 Ref: influencer-finder.html Commnuity: 유저들끼리 서로 커뮤니케이션 할 수 있는 공간 Ref: influencer-profile.html 최종 결과물 Github4. 5주차 돌아보기 기간: 2022. 10. 17 ~ 2022. 10. 22데브코스를 시작하고 벌써 한 달이 지났고, 올해도 거의 마무리가 되어 가고 있다. 최근에는 갑작스럽게 날씨도 많이 추워져서 연말이 다가오는게 피부로도 느껴지는 듯하다. 다시는 돌아오지 않을 나에게 주어진 조금 특별한 이 시간들을 성실하게 잘 사용해보려고 여러가지로 애를 쓰고 있는데 잘하고 있는지는 잘 모르겠다. 여러가지 하려고 하는 욕심이 마음을 앞서다보니 지금 내가 잘하고 있는건가 하는 의문도 들기도 한다. 이럴때 필요한 것들 중 하나는, 내가 가고자 하는 방향이 올바른지를 돌아보는 것이 아닐까 생각해본다. 생각하지 않으면, 흘러가는대로 살아간다고 하는 것처럼 지금 이 시기를 단순히 그렇게 보내고 싶지는 않다. 내 삶의 주체성을 가지고, 내가 계획한 것들을 성취하며 나아가는 사람이 되고 싶다.특별히 이번주에는 지금까지 데브코스에서 배웠던 내용들을 바탕으로 최종적으로 Monthly project를 진행했다. 꽤 오래 전에 아주 가볍게 배웠던 django를 이번에도 학습하게 되었는데, 그때는 아무것도 모르고 따라하기만 했었다면 이번에는 나름 스스로가 의미있다고 생각될 정도로 결과물이 나온 것 같아서 나름 뿌듯한 것 같다. 물론 당연히, 여전히 부족한게 많이 있겠지만 천천히 하나씩 채워가는 재미도 있는 것 같다.물론 이번 프로젝트를 하면서 추가적으로 느꼈던 것도 당연히 있었다. 하루, 이틀만에 내가 생각했던 것을 코드로 구현하고 최종적으로 웹 페이지라는 눈에 보이는 결과물로 만들었던 것은 꽤나 재밌고, 뿌듯했던 시간이었다. 그러다보니 스스로 거기에 심취(?)해 있던 것도 없지 않았던 것 같다. 조금 시야를 달리보면 내가 회사와 같이 이러한 기술을 사용하는 곳에서는 단순히 내가 이런 프로젝트를 해봤다의 수준이 아닌, 스스로 온전히 프로젝트를 이끌어 갈 수 있을 만큼의 수준을 요구할 것이다. 과거에는 여러가지를 다방면에서 다룰 줄 아는 Generalist의 모습이 좋았던 것 같아 여러가지를 많이 시도해봤던 것 같다. 물론 그 능력도 필요하고, 대단하겠지만 최근에는 오히려 특정 분야의 Specialist가 되어야 할까 하는 생각이 든다.오늘도 여전히 내 진로와 미래에 대해 끝없이 고민하고 생각을 정리해본다. 출처: 프로그래머스 인공지능 데브코스 4기 5주차 강의 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "밑시딥1 4강. 신경망 학습", "url": "/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-4%EA%B0%95-%EC%8B%A0%EA%B2%BD%EB%A7%9D%ED%95%99%EC%8A%B5/", "categories": "Review - IT Book, 밑바닥부터 시작하는 딥러닝1", "tags": "AI, 밑시딥1, Deep learning, Machine learning", "date": "2022-10-14 22:00:00 +0900", "snippet": "이번 글에서는 밑바닥부터 시작하는 딥러닝1 책의 4강에 대한 리뷰를 시작합니다. 딥러닝의 퍼셉트론과 신경망에 대해 학습한 후, 이번에는 어떻게 학습이 진행되는지 학습합니다. 손실 함수를 통해 파라미터가 갱신되는 과정을 확인해보며, 그것을 가능케 하는 경사 하강법을 배웁니다. Chapter Title Main Topics 1강 헬로 파이썬 파이썬 기초 문법 소개, numpy, matplotlib 2강 퍼셉트론 AND, NAND, OR 게이트 3강 신경망 활성화 함수, 다차원 배열 계산, 출력층 설계, MNIST 4강 신경망 학습 손실 함수, 경사 하강법 5강 오차역전파법 역전파, 활성화 함수 구현 6강 학습 관련 기술들 매개변수 갱신, 배치 정규화, 하이퍼파라미터 값 찾기 7강 합성곱 신경망 (CNN) 합성곱 계층, 풀링 계층, CNN 구현 8강 딥러닝 (Deep learning) 초기 역사, 딥러닝 활용 Appendix Softmax with loss 계층의 계산 그래프 - 밑바닥부터 시작하는 딥러닝 1 밑바닥부터 시작하는 딥러닝 1 Github 링크 참고 - 다크 모드가 아닌 화이트 모드로 보시면 자료를 편하게 확인 가능합니다!Chapter 4. 신경망 학습4.1 데이터에서 학습한다! 신경망의 특징은 데이터를 보고, 학습 할 수 있다는 점 학습이란, 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것 학습의 목표는 손실 함수의 결과값을 가장 작게 만드는 가중치 매개변수를 찾는 것4.1.1 데이터 주도 학습 기계학습은 데이터에서 답을 찾고, 데이터에서 패턴을 발견하고 데이터로 이야기를 만드는 것 따라서 기계학습의 중심에는 데이터가 존재한다고 할 수 있음 기계학습에서는 사람의 개입을 최소화하면서 수집한 데이터로 패턴을 찾으려 시도 MNIST 모델에서 숫자를 인식하는 알고리즘이 동작하기 위해서, 이미지에서 특징 (Feature)을 추출하여 그 특징의 패턴을 기계학습 기술로 학습 특징은 입력 데이터에서 본질적인 데이터를 정확히 추출할 수 있도록 설계된 변환기 이미지의 특징은 일반적으로 ‘벡터’로 변환하여 학습 기계학습에서는 모아진 데이터로부터 규칙을 찾아내는 역할을 기계가 한다고 할 수 있음 사람이 직접 설계하는 것에 비해서 부담은 적지만, 이미지를 벡터로 변환하는 등의 과정은 사람이 해야 함 문제에 적합한 특징을 설계하지 (전처리) 못한다면, 좋은 결과를 획득하기도 어렵다고 할 수 있음 입력부터 출력까지 사람의 개입 없이 동작하여 종단간 기계학습 (end-to-end machine learning)이라고도 함4.1.2 훈련 데이터와 시험 데이터 기계학습 문제는 훈련 데이터 (Training data)와 시험 데이터 (Test data)로 나눠 학습과 실험을 수행 훈련 데이터를 통해서 학습하면서 최적의 매개변수를 찾음 그 후에 시험 데이터를 사용하여 앞서 훈련한 모델의 성과를 평가 결국 모델링의 궁극적인 목적은 범용적으로 사용할 수 있는 일반화된 모델이므로, 훈련 데이터와 시험 데이터로 구분 이를 위해서 한번도 보지 못했던 훈련에 포함되지 않은 데이터로 성능을 측정 한 데이터셋에만 지나치게 최적화 된 상태를 오버피팅 (Overfitting)이라고 함4.2 손실 함수 신경망 학습에서는 현재의 상태를 하나의 지표로 표현 그 지표를 가장 좋게 만들어주는 가중치 매개변수 값을 찾는 것이 목적 신경망 학습에서 사용하는 지표는 손실 함수 (Loss function)라고 정의 일반적으로 오차제곱합과 교차 엔트로피 오차를 사용 손실 함수는 신경망의 성능의 나쁨을 나타내는 지표 즉, 현재 신경망이 훈련 데이터를 얼마나 잘 처리하지 못하는지의 성능을 담고 있음 따라서 손실 함수의 값이 클수록 좋지 않는 성능을 갖고 있다고 할 수 있음 4.2.1 오차제곱합 (Sum of Square for Error, SSE)\\[E = \\frac{1}{2}{\\sum_{k} (y_k - t_k)^2}\\] 가장 많이 쓰이는 손실 함수는 오차제곱합이고, 수식은 위와 같음 $y_k$는 신경망의 출력 (신경망이 출력한 값), $t_k$는 정답 레이블, $k$는 데이터의 차원 수를 나타냄 즉, 오차제곱합은 각 원소의 출력과 정답 레이블의 차를 제곱한 후에 그 총합을 구하는 것 파이썬 코드로 오차제곱합을 구현하면, 아래와 같음을 알 수 있음 MNIST에서 정답이 ‘2’라고 했을 때, 모델의 출력 결과가 맞았을 때와 틀렸을 때의 손실함수 값 확인 출력 결과가 맞을 때, 손실 함수 값이 0.0975로 작게 나오는 것을 확인할 수 있음 반면, 출력 결과가 틀렸을 때, 손실 함수 값이 0.5975로 크게 나오는 것을 확인할 수 있음 즉, 손실 함수의 값이 작을수록 정답에 수렴한다고 할 수 있음 import numpy as npdef sum_squares_error(y, t): return 0.5 * np.sum((y - t)**2)# 정답은 '2't = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]# 예1: '2'일 확률이 가장 높을 때y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]sum_squares_error(np.array(y), np.array(t)) # 0.09750000000000003# 예2: '7'일 확률이 가장 높을 때y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]sum_squares_error(np.array(y), np.array(t)) # 0.59754.2.2 교차 엔트로피 오차 (Cross Entropy Error, CEE)\\[E = -{\\sum_{k} t_klog_ey_k}\\] 위 수식은 교차 엔트로피 오차의 수식 log는 밑이 e인 자연로그, $y_k$는 신경망의 출력, $t_k$는 정답 레이블이면서 정답 인덱스만 1 (원-핫 인코딩) 따라서 실질적으로 정답일 때 추정의 자연로그를 계산하는 식 (다른 경우에는 모두 0이기 때문) 즉, 교차 엔트로피 오차는 정답일 때의 출력이 전체 값을 결정 파이썬 코드로 교차 엔트로피 오차를 구현하면, 아래와 같음을 알 수 있음 MNIST에서 정답이 ‘2’라고 했을 때, 모델의 출력 결과가 맞았을 때와 틀렸을 때의 손실함수 값 확인 출력 결과가 맞을 때, 손실 함수 값이 0.5108로 작게 나오는 것을 확인할 수 있음 반면, 출력 결과가 틀렸을 때, 손실 함수 값이 2.3025로 크게 나오는 것을 확인할 수 있음 즉, 위의 오차제곱합과 동일하게 손실 함수의 값이 작을수록 정답에 수렴한다고 할 수 있음 def cross_entropy_error(y, t): delta = 1e-7 return -np.sum(t * np.log(y + delta))# 정답은 '2't = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]# 예1: '2'일 확률이 가장 높을 때y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]cross_entropy_error(np.array(y), np.array(t)) # 0.510825457099338# # 예2: '7'일 확률이 가장 높을 때y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]cross_entropy_error(np.array(y), np.array(t)) # 2.30258409299454544.2.3 미니배치 학습\\[E = -\\frac{1}{N}{\\sum_{n}}{\\sum_{k} t_klog_ey_k}\\] 위 수식은 훈련 데이터 모두에 대한 손실 함수 값을 구하는 수식 앞선 수식과 비슷하고, 데이터 하나에 대한 손실 함수를 단순히 N개의 데이터로 확장한 것 마지막에는 N으로 나눠서 정규화 (평균 손실 함수의 역할) 하지만 현실적으로 빅데이터 안에서 이 모든 데이터를 대상으로 값을 계산하는 것은 비효율적 따라서 데이터 일부를 추려 전체의 근사치로 이용하는 미니배치 (Mini-batch) 방법을 사용 (일부만 골라 학습) 아래 코드는 MNIST 데이터셋에서 np.random.choice 함수를 통해 미니배치로 계산하는 과정을 소개import sys, os, picklegithub_url = '/Users/paul/Desktop/github/deep-learning-from-scratch-master/'sys.path.append(github_url)import numpy as npfrom dataset.mnist import load_mnist### MNIST 데이터셋 불러오기(x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, one_hot_label=True)x_train.shape # (60000, 784)t_train.shape # (60000, 10)### 훈련 데이터에서 무작위로 10장만 추출하기train_size = x_train.shape[0]batch_size = 10batch_mask = np.random.choice(train_size, batch_size)x_batch = x_train[batch_mask]t_batch = t_train[batch_mask]4.2.4 (배치용) 교차 엔트로피 오차 구현하기def cross_entropy_error(y, t): if y.ndim == 1: t = t.reshape(1, t.size) y = y.reshape(1, y.size) batch_size = y.shape[0] # return -np.sum(t * np.log(y + 1e-7)) / batch_size # 원-핫 인코딩이 되어 있는 경우 return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size # 원-핫 인코딩이 되어 있지 않은 경우 배치 데이터를 지원하는 교차 엔트로피 오차 구현 y는 신경망의 출력, t는 정답 레이블 정답에 해당하는 신경망의 출력만으로 교차 엔트로피 오차를 계산할 수 있음4.2.5 왜 손실 함수를 설정하는가? 모델의 궁극적인 목적은 높은 정확도를 끌어내는 매개변수 값을 찾아내는 것 신경망 학습에서는 최적의 매개변수를 탐색할 때 손실 함수의 값을 가능한 작게 하는 매개변수 값을 찾음 이때 매개변수의 미분 (기울기)을 계산하여, 그 값을 단서로 값을 서서히 갱신하는 과정을 반복 가중치 매개변수의 손실 함수 미분이라는 것: 가중치 매개변수 값을 아주 조금 변화시켰을 때, 손실 함수가 어떻게 변하는지에 대한 것 미분 값이 음수면, 그 가중치 매개변수를 양의 방향으로 변화시켜서 손실 함수의 값을 줄일 수 있음 반대로 미분 값이 양수면, 가중치 매개변수를 음의 방향으로 변화시켜서 손실 함수 값을 줄일 수 있음 하지만 미분 값이 0이면, 가중치 매개변수를 어느 쪽으로 움직여도 손실 함수 값은 변화하지 않음 따라서 매개변수 갱신은 중단 정확도를 지표로 삼게 되면, 결과값이 연속적으로 변화하지 못하고, 불연속적으로 띄엄띄엄한 값으로 변화 한편, 손실 함수를 지표로 삼으면, 매개변수 값이 변할 때마다 그에 반응하여 손실 함수도 연속적으로 값이 변화 따라서 활성화 함수로 계단 함수를 사용하지 않는 이유 역시, 미분값이 불연속적으로 계산되기 때문임 시그모이드 함수 같은 경우에는, 출력이 연속적으로 변하면서 곡선의 기울기 역시 연속적으로 변화함4.3 수치 미분 경사법에서는 기울기 (경사) 값을 기준으로 나아갈 방향을 정함4.3.1 미분 미분은 한순간의 변화량을 표시한 것, 수치 미분은 아주 작은 차분으로 미분하는 것 미분을 수식으로 표현하면 아래와 같은데, 이 뜻은 x의 작은 변화가 함수 $f(x)$를 얼마나 변화시키느냐에 대한 것\\[\\frac{df(x)}{dx} = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\\]def numerical_diff(f, x): h = 1e-4 # 0.0001 return (f(x+h) - f(x-h)) / (2*h)4.3.2 수치 미분의 예 $y = 0.01x^2 + 0.1x$를 그래프로 표현하면 아래와 같음 해당 식에서 x가 5일 때와 10일 때의 미분 결과는 각각 0.2, 0.3 정도import matplotlib.pylab as pltdef function_1(x): return 0.01*x**2 + 0.1*xx = np.arange(0.0, 20.0, 0.1) # 0에서 20까지 0.1 간격의 배열 x를 만듦y = function_1(x)plt.xlabel('x')plt.ylabel('f(x)')plt.plot(x, y)plt.show()numerical_diff(function_1, 5) # 0.1999999999990898numerical_diff(function_1, 10) # 0.29999999999863474.3.3 편미분 $f(x_0, x_1) = x_0^2 + x_1^2$ 라는 식을 파이썬으로 구현하면 아래와 같음 이 식을 미분하려고 할때, 주의해야 하는 것은 변수가 2개이므로, 어느 변수에 대한 미분인지가 중요 이처럼 변수가 여럿인 함수에 대한 미분을 편미분이라고 정의 편미분은 변수가 하나인 미분과 마찬가지로 특정 장소의 기울기를 구하는 것 단, 여러 변수들 중에서 목표 변수 하나에 초점을 맞추고, 다른 변수는 값을 고정함def function_2(x): return x[0]**2 + x[1]**24.4 기울기 (Gradient) 모든 변수의 편미분을 벡터로 정리한 것 아래 그림은 $x_0^2 + x_1^2$의 기울기를 나타내는 그림 아래 그림에서 확인할 수 있듯, 기울기는 함수의 가장 낮은 장소 (최솟값)를 가리키는 것 같은 모양 가장 낮은 곳에서 멀어질수록 화살표의 크기가 커짐 하지만 정확하게 말한다면, 기울기는 각 지점에서 낮아지는 방향을 가리킴 즉, 기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향 Global Optima, Local Optima 개념 참고 def numerical_gradient(f, x): h = 1e-4 # 0.001 grad = np.zeros_like(x) # x와 형상이 같은 배열 생성 for idx in range(x.size): # f(x + h) 계산 tmp_val = x[idx] x[idx] = tmp_val + h fxh1 = f(x) # f(x - h) 계산 x[idx] = tmp_val - h fxh2 = f(x) grad[idx] = (fxh1 - fxh2) / (2*h) x[idx] = tmp_val # 값 복원 return gradnumerical_gradient(function_2, np.array([3.0, 4.0])) # array([6., 8.])numerical_gradient(function_2, np.array([0.0, 2.0])) # array([0., 4.])numerical_gradient(function_2, np.array([3.0, 0.0])) # array([6., 0.])4.4.1 경사법 (경사 하강법) 기계학습에서는 학습 단계에서 최적의 매개변수 (가중치와 편향)를 학습에서 찾음 최적이라는 것은 손실함수가 최솟값이 될 때의 매개변수 값 하지만 손실함수는 복잡하기 때문에, 어디가 최솟값인지 찾기 힘듦 따라서 기울기를 잘 이용하여 함수의 (가능한 최대한 작은) 최솟값을 찾으려는 것이 경사법의 개념 각 지점에서 함수의 값을 낮추는 방안을 제시하는 지표가 기울기 하지만 기울기가 가리키는 곳에 함수의 최솟값이 있는지 보장할 수는 없음 복잡한 함수에서는 기울기가 가리키는 방향에 최솟값이 없을 수도 있음 그렇기 때문에 기울기 정보를 단서로 하여 나아갈 방향을 정하는 경사법 개념이 도입 경사법은 현 위치에서 기울어진 방향으로 일정 거리만큼 이동한 후, 이동한 곳에서 기울기를 구하고, 이 과정을 반복 이렇게 함수의 값을 점차 줄이는 것이 경사법 (Gradient method)이고, 기계학습을 최적화 하는데 사용 경사법에서 최솟값을 찾는 과정을 경사 하강법 (Gradient descent method) 경사법에서 최댓값을 찾는 과정을 경사 상승법 (Gradient ascent method) \\[x_0 = x_0 - \\eta \\frac{\\partial f}{\\partial x_0}\\]\\[x_1 = x_1 - \\eta \\frac{\\partial f}{\\partial x_1}\\] 경사법을 수식으로 표현하면 위와 같음 $\\eta$는 갱신하는 양을 나타내고, 신경망 학습에서는 학습률 (Learning rate)이라고 정의 한 번의 학습으로 얼마만큼 학습해야 할지, 즉 매개변수 값을 얼마나 갱신하는지를 정하는 것 일반적으로 학습률은 0.01, 0.001 등의 값으로 정하는데, 이 값이 너무 크거나 작으면 좋은 장소로 찾아가기 힘듦 학습률과 같은 매개변수를 하이퍼파라미터 (Hyper parameter)라고 정의 신경망의 가중치 매개변수는 훈련 데이터와 알고리즘으로 자동으로 획득되는 매개변수 하지만 학습률 같은 하이퍼파라미터는 사람이 직접 설정해야 하는 매개변수 # f = 최적화 하려는 함수, init_x = 초깃값, lr = 학습률, step_num = 경사법에 따른 반복 횟수def gradient_descent(f, init_x, lr=0.01, step_num=100): x = init_x for i in range(step_num): grad = numerical_gradient(f, x) x -= lr * grad return x# 학습률에 따른 경사하강법의 결과init_x = np.array([-3.0, 4.0])gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100) # array([-6.11110793e-10, 8.14814391e-10])gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100) # array([2.34235971e+12, -3.96091057e+12])gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100) # array([-2.99999994, 3.99999992])4.4.2 신경망에서의 기울기 기울기는 가중치 매개변수에 대한 손실 함수의 기울기import sys, osgithub_url = '/Users/paul/Desktop/github/deep-learning-from-scratch-master/'sys.path.append(github_url)import numpy as npfrom common.functions import softmax, cross_entropy_errorfrom common.gradient import numerical_gradientclass simpleNet: # x = 입력 데이터, t = 정답 레이블 def __init__(self): self.W = np.random.randn(2, 3) # 정규분포로 초기화 def predict(self, x): return np.dot(x, self.W) def loss(self, x, t): z = self.predict(x) y = softmax(z) loss = cross_entropy_error(y, t) return loss net = simpleNet()print(net.W) # 가중치 매개변수x = np.array([0.6, 0.9])p = net.predict(x)print(p) # [1.25184467 0.34731474 1.30469603]np.argmax(p) # 최댓값의 인덱스 = 2t = np.array([0, 0, 1]) # 정답 레이블net.loss(x, t) # 2.125447431676497 def f(W): return net.loss(x, t)f = lambda w: net.loss(x, t)dW = numerical_gradient(f, net.W)print(dW)4.5 학습 알고리즘 구현하기 전제: 신경망에는 적용 가능한 가중치와 편향이 있음. 이 값들을 훈련 데이터에 적응하도록 조정하는 것을 학습이라고 정의 1단계: 미니배치 훈련 데이터 중 일부를 무작위로 가져오기 선별한 데이터를 미니배치라고 하고, 그 미니배치의 손실함수 값을 줄이는 것이 목표 2단계: 기울기 산출 미니배치의 손실함수 값을 줄이기 위해 각 가중치 매개변수의 기울기 구하기 기울기는 손실함수의 값을 가장 작게 하는 방향 제시 3단계: 매개변수 갱신 가중치 매개변수를 기울기 방향으로 아주 조금 갱신 4단계: 1~3단계를 반복 이 과정이 신경망 학습이 이뤄지는 순서. 경사하강법으로 매개변수를 갱신하는 방법 이때 데이터를 미니배치로 무작위로 선정하므로, 확률적 경사 하강법 (Stochastic gradient descent, SGD)로 정의4.5.1 2층 신경망 클래스 구현하기import sys, osgithub_url = '/Users/paul/Desktop/github/deep-learning-from-scratch-master/'sys.path.append(github_url)import numpy as npfrom common.functions import sigmoid, softmax, cross_entropy_errorfrom common.gradient import numerical_gradientclass TwoLayerNet: def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01): # 가중치 초기화 self.params = {} self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size) self.params['b1'] = np.zeros(hidden_size) self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) self.params['b2'] = np.zeros(output_size) def predict(self, x): W1, W2 = self.params['W1'], self.params['W2'] b1, b2 = self.params['b1'], self.params['b2'] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) a2 = np.dot(x, W2) + b2 y = softmax(a2) return y # x = 입력 데이터, t = 정답 레이블 def loss(self, x, t): y = self.predict(x) return cross_entropy_error(y, t) def accuracy(self, x, t): y = self.predict(x) y = np.argmax(y, axis=1) t = np.argmax(t, axis=1) accuracy = np.sum(y == t) / float(x.shape[0]) return accuracy def numerical_gradient(self, x, t): loss_W = lambda W: self.loss(x, t) grads = {} grads.params['W1'] = numerical_gradient(loss_W, self.params['W1']) grads.params['b1'] = numerical_gradient(loss_W, self.params['b1']) grads.params['W2'] = numerical_gradient(loss_W, self.params['W2']) grads.params['b2'] = numerical_gradient(loss_W, self.params['b2']) return grads net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)net.params['W1'].shape # (784, 100)net.params['b1'].shape # (100, )net.params['W2'].shape # (100, 10)net.params['b2'].shape # (10, )4.5.2 미니배치 학습 구현하기 미니배치 학습: 훈련 데이터 중 일부를 무작위로 꺼내고 (미니배치), 그 미니배치에 대해 경사법으로 매개변수를 갱신 아래 예시에서는 미니배치 크기를 100으로 설정 60,000개의 훈련 데이터에서 임의로 100개 데이터를 추리고, 이 데이터로 확률적 경사하강법으로 매개변수를 갱신 갱신 횟수 (반복 횟수)는 10,000번으로 설정하고, 갱신 할때마다 계산되는 손실 함수 값을 배열에 추가 결과를 보면, 학습 횟수가 늘어날수록 손실 함수의 값이 줄어드는 것을 알 수 있음 이 결과는 신경망의 가중치 매개변수가 서서히 데이터에 적응하면서 학습되고 있다는 것을 뜻함import numpy as npfrom dataset.mnist import load_mnistfrom ch04.two_layer_net import TwoLayerNet(x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, one_hot_label=True)train_loss_list = []# 하이퍼파라미터iters_num = 10000 # 반복횟수train_size = x_train.shape[0]batch_size = 100 # 미니배치 크기learning_rate = 0.1network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)for i in range(iters_num): # 미니배치 획득 batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] # 기울기 계산 grad = network.numerical_gradient(x_batch, t_batch) # grad = network.gradient(x_batch, t_batch) # 성능 개선판 # 매개변수 갱신 for key in ('W1', 'b1', 'W2', 'b2'): network.params[key] -= learning_rate * grad[key] # 학습 경과 기록 loss = network.loss(x_batch, t_batch) train_loss_list.append(loss)4.5.3 시험 데이터로 평가하기 앞서 훈련된 모델은 훈련 데이터에 대한 결과이므로, 다른 데이터셋에서도 동작하는지 확인이 필요함 즉, 훈련 데이터에서만 학습한 결과인 오버피팅 되었는지를 확인해봐야 함 신경망 학습의 목표는 범용적인 능력을 익히는 것 즉, 일반화라고 할 수 있음import numpy as npfrom dataset.mnist import load_mnistfrom ch04.two_layer_net import TwoLayerNet(x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, one_hot_label=True)network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)# 하이퍼파라미터iters_num = 10000 # 반복횟수train_size = x_train.shape[0]batch_size = 100 # 미니배치 크기learning_rate = 0.1train_loss_list = []train_acc_list = []test_acc_list = []# 1 에폭 당 반복 수iter_per_epoch = max(train_size / batch_size, 1)for i in range(iters_num): # 미니배치 획득 batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] # 기울기 계산 grad = network.numerical_gradient(x_batch, t_batch) # grad = network.gradient(x_batch, t_batch) # 성능 개선판 # 매개변수 갱신 for key in ('W1', 'b1', 'W2', 'b2'): network.params[key] -= learning_rate * grad[key] # 학습 경과 기록 loss = network.loss(x_batch, t_batch) train_loss_list.append(loss) # 1 에폭 당 정확도 계산 if i % iter_per_epoch == 0: train_acc = network.accuracy(x_train, t_train) test_acc = network.accuracy(x_test, t_test) train_acc_list.append(train_acc) test_acc_list.append(test_acc) print(\"train acc, test acc: \" + str(train_acc) + ', ' + str(test_acc))4.6 정리 손실함수를 기준으로 그 값이 가장 작아지는 가중치 매개변수를 찾아내는 것이 신경망 학습의 목표 기계학습에서 사용하는 데이터셋은 훈련 데이터와 시험 데이터로 나눠 사용 훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가 가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치 값을 갱신 반복 출처: 밑바닥부터 시작하는 딥러닝1 책 리뷰 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "대학원생 때 알았더라면 좋았을 것들 책 Review", "url": "/posts/%EB%8C%80%ED%95%99%EC%9B%90%EC%83%9D-%EB%95%8C-%EC%95%8C%EC%95%98%EB%8D%94%EB%9D%BC%EB%A9%B4-%EC%A2%8B%EC%95%98%EC%9D%84-%EA%B2%83%EB%93%A4/", "categories": "Review - Book, 대학원생 때 알았더라면 좋았을 것들", "tags": "대학원, 석사, 박사, 진학", "date": "2022-10-13 01:00:00 +0900", "snippet": " 간단한 책 소개" }, { "title": "프로그래머스 인공지능 데브코스 4주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-4%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-10-10 10:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스의 4주차 강의에 대한 정리입니다. 지금까지 기초 파이썬과 함께 데이터를 다루는 Pandas, Numpy, Matplotlib 등을 학습했습니다. 이번 주에는 앞서 배웠던 내용들을 바탕으로 Flask라는 프레임워크와 함께 데이터를 EDA 하는 방법과, AWS 클라우드를 활용하여 머신러닝 모델을 Serving 하는 API를 만드는 방법에 대해 배웁니다. 지금까지는 모델을 만드는 방법만을 학습했는데, 실제 서비스를 위해 필요한 내용들을 배울 수 있을 것 같아 기대가 됩니다.1. Web Application with FlaskFlask 설치하기 지금까지 학습한 것 Data Structure, Algorithm Numpy, Pandas, Matplotlib, EDA Calculus, Linear Algebra, Probability &amp; Statistics Flask: Python 기반 마이크로 웹 프레임워크 가상환경 설치하기pip install virtualenv # 가상환경을 만들 수 있는 virtualenv 패키지 설치virtualenv venv # 가상환경 이름이 venv인 가상환경 만들기source venv/bin/activate # venv라는 가상환경에 진입하기 (mac OS)./venv/Scripts/activate.bat # venv라는 가상환경에 진입하기 (Windows OS)pip freeze # 현재 가상환경에 설치된 패키지 확인pip install flask # 들어온 가상환경에 flask 패키지를 설치인터넷과 웹 인터넷 (Internet): 전 세계 컴퓨터를 하나로 합치는 거대한 통신망 웹 (Web): 인터넷에 연결된 사용자들이 정보를 공유할 수 있는 공간 Web의 동작 방식 웹은 클라이언트와 서버 사이의 소통 클라이언트가 서버에 정보를 요청 (HTTP Request) 서버는 이 요청받은 정보에 대한 처리를 진행 서버가 클라이언트에게 요청에 대해 응답 (HTTP Response) REST API API (Application Programming Interface): 프로그램들이 서로 상호작용 하는 것을 도와주는 매개체 RESTful (Representational State Transfer) 웹 서버가 요청을 응답하는 방법론 중 하나 데이터가 아닌, 자원 (Resource)의 관점으로 접근 클라이언트의 Context를 서버에서 유지하지 않음 (Stateless - 무상태성) GET 요청이 들어왔다고 해서, 서버 입장에서 요청 받지 않았던 POST 요청을 실행하지 않음 GET 요청이 들어왔다면, GET 요청에 대한 Response만 보냄 HTTP URI를 통해 자원을 명시하고, HTTP Method를 통해 해당 자원에 대한 CRUD를 진행 HTTP Method: GET, POST, PUT, DELETE Postman: API를 테스트 할 수 있음2. 클라우드를 활용한 머신러닝 모델 Serving API 개발클라우드 기초 과거에 인터넷 환경에서 서비스를 제공하려면 서비스 호스팅에 필요한 모든 것을 직접 구축했어야 함 하지만 서버를 직접 구축 및 운영하는 자원과 인력 비용이 크고, 변화에 대응하는 것이 어려움 따라서 서버 운영에 필요한 공간, 네트워크 등을 제공하는 IDC (Internet Data Center) 서비스 등장 하지만 IDC 역시 서버 임대를 통해 자원을 효율적으로 이용하고 비용 절감이 가능하지만, 유연성이 떨어진다는 한계 기존의 서버 구축 및 운영 방식으로는 적절한 시간에 필요한 서비스를 사용자에게 제공하기 힘들었음 사용자가 늘면서 다양한 서비스를 제공하면서 필요할 때, 필요한 만큼 서버를 증설하기 원하는 온디맨드 수요 증가 ex) 접속량이 늘어서 컴퓨팅 수요 증가시에 오토 스케일링 필요, 평상 시에 사용하지 않는 유휴 자원은 비용에서 제거 클라우드 컴퓨팅 (Colud Computing)은 언제 어디서나 필요한 만큼의 컴퓨팅 자원을 필요한 시간만큼 활용 가능 아마존이 2006년 클라우드를 통한 저장공간 및 연산 자원 제공 서비스인 S3과 EC2를 개시하면서 등장 클라우드를 통해 빅데이터 수집, 저장, 분석을 위한 방대한 컴퓨팅 자원과 인공지능 개발을 위한 IT 환경 마련 가능 속도, 접근성, 확장성, 생산성, 보안 및 안정성, 측정 가능성 등의 장점을 갖음 도커와 같은 가상화 기술을 통해 GPU 활용과 소프트웨어 설치 및 배포 등의 작업에 비용과 시간 절감 클라우드 컴퓨팅 운용 모델: 구축 및 배포 유형에 따라 Public, Private, Hybrid로 구분 Public: 모든 인프라와 IT 기술을 클라우드에서 사용, IT 관리 인력 및 인프라 구축 비용 없는 경우 유용 Private: 고객이 자체 데이터센터에서 직접 클라우드 서비스를 구축, 보안이 좋고 커스터마이제이션 가능 Hybrid: 고객이 핵심 시스템은 내부에 두면서 외부 클라우드 활용, Public 경제성과 Private 보안성 활용 클라우드 서비스 제공 방식에 따라서 IaaS, PaaS, SaaS 형태로 구분 On-Premises: Owning a car IaaS: Leasing a car PaaS: Taking a taxi SaaS: Going by bus 클라우드 서비스 제공 사업자: AWS, GCP, Azure, NCP (네이버 클라우드 플랫폼) 등 API to serve ML model Architecture: AWS EC2와 Flask 기반 모델 학습 및 추론을 요청, 응답하는 API 서버 개발 Interface: 사용자는 기계와 소프트웨어를 제어하기 위해 인터페이스를 정해진 메뉴얼에 따라 원하는 경험 획득 API (Application Programming Interface): 기계&amp;기계, 소프트웨어&amp;소프트웨어 커뮤니케이션을 위한 인터페이스 RESTful API for ML/DL Model Interface RESTful API: REST 아키텍처를 따르는 API 데이터나 정보의 교환, 요청 등을 위한 인터페이스를 REST 아키텍쳐를 따라 구현한 API 데이터 값을 담아 요청하고, 모델이 추론한 결과에 대한 return을 json 형태로 반환하도록 설계 RESTful API는 요청 메시지만 봐도 어떤 내용으로 되어 있는지 알 수 있도록 표현 HTTP URI를 통해 자원을 명시하고, HTTP Method를 통해 필요한 연산을 요청하고 반환하는 API Practical process of machine learning 문제 정의, 데이터 준비, 모델 학습 및 검증, 모델 배포, 모니터링 등의 과정을 통해 ML/DL 모델 적용 Model Serving 학습된 모델을 REST API로 배포하기 위해 학습된 모델의 Serialization과 웹 프레임워크를 통해 배포 준비 필요 모델을 서빙할 때는 학습 시의 데이터 분포나 처리 방법과의 연속성 유지 필요 모델을 배포하는 환경에 따라 다양한 Serving Framework를 고려하여 활용 Model Training -&gt; Serializing Model -&gt; Serving Model Serialization &amp; De-serialization: 학습한 모델의 재사용 및 배포를 위해 저장하고 불러오는 것 Serialization을 통해 ML/DL 모델 object를 disk에서 불러와 어디든 전송하고 불러올 수 있는 형태로 변환 De-serialization을 통해 파이썬 혹은 다른 환경에서 모델을 불러와서 추론 및 학습에 사용 모델을 배포하는 환경을 고려하여 환경에 맞는 올바른 방법으로 Serialization 해야지 De-serialization 가능 Model Serving을 위한 다양한 Frameworks: TensorFlow serving, TorchServe, TensorRT Flask 같은 웹 프레임워크는 클라이언트로부터 요청을 처리하기 위해 주로 사용 별도의 모델 추론을 위한 API 서버를 운용하여 내부 혹은 외부 통신을 통해 예측, 추론값 반환 대용량 데이터 배치 처리와 딥러닝 모델 활용이 늘면서 multi node &amp; GPU 환경에서 안정적 모델 서빙을 위함 3. 데이터 씹고 뜯고 맛보고 즐기기 - EDAEDA 데이터 그 자체만으로부터 인사이트를 얻어내는 접근법 EDA의 Process 분석의 목적과 변수 확인 데이터 전체적으로 살펴보기 (결측치, 상관관계 확인 등) 데이터의 개별 속성 파악하기 (각 feature에 대해 특징 확인 등) 타이타닉 데이터를 통한 EDA 각 데이터는 어떤 자료형을 가지고 있는지? 데이터에 결측치는 없는지, 있다면 어떻게 해야 할지? 데이터의 자료형을 바꿔줄 필요가 있는지 (범주형의 One-hot encoding) 데이터에 대한 가설 세워보기 가설을 검증하기 위한 증거를 찾아보기 4. EDA Project5. Weekly Assignment6. 4주차 돌아보기 기간: 2022. 10. 10 ~ 2022. 10. 15데브코스가 시작한지 벌써 한 달이 지났다니 실감이 나지 않는 것 같다. 시간이 정말 빠르다. 퇴사 후에 스스로의 시간을 경영하는 방법을 배우고 있는 것 같은데, 여러가지 계획들과 해야 할 것들을 고민하는 것 역시 좋다고 생각한다. 하지만 가장 중요한 것은 생각하는 것들을 직접 행하는 것이 가장 중요할 것이다. 생각만 하지 말고, 말만 하지 말고 그것들을 실천에 옮길 수 있는 사람이 되자. 기존과 다르게 스스로에게 주어진 많은 시간 속에 행복해하며, 이것도 하고, 저것도 하자는 거창한 계획들 속에서 가장 중요한 것은 그것을 행하는 것이다.데브코스를 진행하면서, 개인적으로 관심사가 비슷한 분들과 함께 사이드 프로젝트도 진행을 해보고 있다. 기술이 가지는 가치 중 하나는, 우리가 불편했지만 그냥 넘겼던 것들에 대해 다시 생각해보면서 기술로써 그 불편함을 해결할 수 있다는 것 같다. 실제로 우리가 평소에 사용하고 있는 대부분의 서비스들은 많은 부연 설명 없이 아주 간단하게 컨셉을 설명할 수 있는 서비스들이다. 이렇듯 이 사이드 프로젝트에서도 우리가 평소에 느꼈던 문제를 공감하고, 그것들을 배우고 있고, 배웠던 기술들을 활용하여 해결해보고자 한다.또 이와 관련하여 공모전도 함께 참여할 계획을 가지고 있는데, 차근히 잘 준비하고 이 블로그에서 또 해당 내용들을 열심히 차근히 기록해보도록 하겠다. 다음 주도 새로운 배움으로 가득하길 기대하자!! 출처: 프로그래머스 인공지능 데브코스 4기 4주차 강의 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "SQL 코딩의 기술 1강. 데이터 모델 설계", "url": "/posts/SQL-%EC%BD%94%EB%94%A9%EC%9D%98-%EA%B8%B0%EC%88%A0-1%EA%B0%95/", "categories": "Review - IT Book, SQL 코딩의 기술", "tags": "SQL, 데이터베이스, SQL 코딩의 기술", "date": "2022-10-07 13:00:00 +0900", "snippet": " 간단한 책 소개 이 책은 데이터베이스를 다룰 수 있는 SQL의 개념과 사용 방법을 소개하고 있습니다. 대표적인 DBMS인 오라클, SQL Server, MySQL, PostgreSQL 등을 비교하면서 보여줍니다. 회사를 다녀보니, 데이터를 다루는 과정에서는 파이썬보다 SQL과 DB에 대한 이해가 더 필요하다는 것을 느꼈습니다. 따라서 데이터베이스를 다룰 수 있는 (거의 유일한) SQL을 학습하며, DB에 대한 이해도를 높이려고 합니다. 이 책에서는 다양한 DBMS를 소개하고 있지만, 실제로 가장 많이 사용되고 있고 제 필요에 따라서, DB의 기초 내용과 MySQL, PostgreSQL 등의 내용을 중점적으로 살펴 볼 예정입니다. SQL 코딩의 기술 SQL 코딩의 기술 Github 링크 Chapter Title Main Topics 1강 데이터 모델 설계 기본키, 외래키, 중복 데이터 제거, 정규화, 역정규화 2강 인덱스 설계와 프로그램적 처리 인덱스, 트리거, 선언적 제약 조건 3강 데이터 모델 설계를 변경할 수 없는 경우 뷰, ETL, 요약 테이블, UNION 4강 데이터 필터링과 검색 관계 대수, CASE, 다중 조건 문제, 데이터 분할, 사거블 쿼리 5강 집계 GROUP BY, HAVING, DISTINCT, 윈도우 함수, 이동 집계 6강 서브쿼리 서브쿼리, CTE, 조인 7강 메타데이터 획득, 분석 메타데이터 수집 방법, 실행 계획의 작동 원리 8강 카티전 곱 로우 조합 9강 탤리 테이블 윈도우 함수, 날짜 테이블, 피벗 10강 계층형 데이터 모델링 인접 리스트 모델, 중첩 집합 Appendix - 데이터 타입, 산술 연산, 함수 Chapter 1. 데이터 모델 설계Better way 1 - 모든 테이블에 기본키가 있는지 확인하자 관계형 모델을 따르기 위해서는 한 테이블에 있는 특정 row와 다른 row를 구별할 수 있어야 함 테이블에 기본키가 없으면, 일관성 없는 데이터가 쌓여 쿼리 속도가 느리고, 정확한 정보 조회가 불가능 할 수도 있음 So, 모든 테이블에는 column 한 개 이상으로 구성된 기본키 (Primary Key)가 필요 기본키는 row마다 유일해야 함 기본키는 null 값을 가질 수 없음 기본키는 안정적인 값이어야 함 (값을 갱신할 필요가 없음) 기본키는 가능한 간단한 형태이어야 함 기본키 설정을 하기 위한 가장 일반적인 방법은 의미 없는 숫자 데이터로 자동 생성되는 컬럼을 기본키로 만드는 것 RDBMS에 따라 이름이 구분되는데, DB2, SQL Server, 오라클 12c에서는 IDENTITY 액세스에서는 AutoNumber, MySQL,에서는 AUTO_INCREMENT, PostgreSQL에서는 serial 컬럼 RDBMS에서 참조 무결성 (Reference Integrity, RI)이라는 개념은 매우 중요 RI를 준수한다는 것은 null이 아닌 외래키 (Foreign Key)가 설정된 자식 테이블의 각 레코드와 일치하는 레코드가 부모 테이블에 존재한다는 것 ex) Orders 테이블에서 고객 정보 컬럼에 외래키를 설정하여 Customers 테이블의 기본키와 연결된 것 이렇게 되면, 같은 이름을 가진 고객이 있어도 Customers 테이블의 각 로우는 유일하기 때문에 고객 식별 가능 복합 기본키 (Compound Primary Key)는 다음의 이유로 효율성이 떨어지므로 지양하기 기본키를 정의 할 때, 해당 컬럼에 유일한 인덱스를 만드는데, 컬럼 두 개 이상에 인덱스를 만드는게 비효율적 기본키로 조인을 수행하는데, 기본키가 여러 컬럼으로 구성되면 쿼리가 복잡하고 느려짐 Better way 2 - 중복으로 저장된 데이터 항목을 제거하자 데이터가 중복으로 저장된다면? 일관되지 않은 데이터 이슈 비정상적인 삽입, 갱신, 삭제 처리 이슈 디스크 공간 낭비 이슈 정규화 (Normalization) 중복 데이터를 저장하면서 발생하는 문제를 없애려고 정보를 주제 (subject) 별로 분할하는 프로세스 여기서 ‘중복’이라는 것은 사용자가 동일한 데이터를 한 군데 이상에서 입력하는 것을 뜻함 정규화의 목표는 한 DB에서 동일한 테이블이든, 다른 테이블이든 반복되는 데이터를 최소화하는 것 외래키 제약 조건: 복수의 테이블 사이에 관계를 선언함으로써 데이터의 무결성을 보장해 주는 역할 그림 1-3 단일 테이블의 중복 데이터 그림 1-4 주제 별로 데이터를 테이블에서 분리위 1-3 그림에서 볼 수 있는 것처럼 기존에는 정규화 되어 있지 않고, CustomerSales 라는 하나의 테이블로 고객 정보와 종업원 정보, 구매 정보 등이 관리되고 있었음. 이 경우에는 고객이 물건을 구매하는 경우에 PurchaseDate에 관련된 정보만 추가되는 것이 아니라, 다른 모든 컬럼들도 영향을 받고 있음. 게다가 고객 정보가 똑같은데, 데이터가 다르게 들어오는 경우에는 처리하는게 복잡하게 될 수 있음.따라서 1-4 그림처럼 주제 (subject) 별로 분할하는 정규화 과정을 수행하여, Customers, Employees, AutomobileModels, SalesTransactions 테이블로 나눠서 관리할 수 있음. 그러면서 기본키와 외래키를 통해 데이터의 중복을 제거하고, 효율적으로 관리할 수 있음. 또한 아래 쿼리를 통해 데이터를 다시 1-3 그림처럼 복구할 수도 있음.SELECT st.SalesID, c.CustFirstName, c.CustLastName, c.Address, c.City, c.Phone, st.PurchaseDate, m.ModelYear, m.Model, e.SalesPersonFROM SalesTransactions st INNER JOIN Customers c ON c.CustomerID = st.CustomerID INNER JOIN Employees e ON e.EmployeeID = st.SalesPersonID INNER JOIN AutomobileModels m ON m.ModelID = st.ModelID;Better way 3 - 반복 그룹을 제거하자 영향도 (비용) 측면에서 컬럼은 비싸고, 로우는 싸다. DB 정규화의 목표는 데이터의 반복 그룹을 제거하고, 스키마 변경을 최소화 하는 것 데이터의 반복 그룹을 제거하면, 인덱싱을 사용하여 데이터 중복을 방지하고, 쿼리도 간소화 할 수 있음 UNION, UNION ALL 쿼리를 활용Better way 4 - 컬럼당 하나의 특성만 저장하자 관계형 용어에서 관계 (테이블)는 오직 한 주제나 액션만 기술해야 함 단일 컬럼에 특성 값을 두 개 이상 저장하는 것은 올바르지 못함 검색을 하거나, 값을 집계할 때 특성 값을 분리하기 어렵기 때문 중요한 개별 특성은 자체 컬럼에 넣는 것을 고려해야 함 Auth ID Auth Name Auth Address 1 John L. Viescas 144 Boulevard Saint-Germain, 75006, Paris, France 2 Douglas J. Steele 555 Sherbourne St., Toronto, ON M4X 1W6, Canada 3 Ben Clothier 2015 Monterey St., San Antonio, TX 78207, USA 4 Tom Wickerath 2317 185th Place NE, Redmond, WA 98052, USA 위 테이블에는 다음과 같은 문제점 존재 불가능하지는 않지만, ‘성’을 찾기 힘듦 이름을 검색할 때, 효율성이 떨어지는 LIKE, substring 연산자를 사용해 이름을 추출해야 함 거리 이름, 도시, 주, 우편번호를 쉽게 찾을 수 없음 데이터를 그룹으로 묶으면, 그룹화 된 데이터에서 우편번호, 주, 국가를 추출하기 힘듦 Auth ID Auth First Auth Mid Auth Last Auth St Num Auth Street Auth City Auth St Prov Auth Postal Auth Country 1 John L. Viescas 144 Boulevard Saint-Germain Paris - 75006 France 2 Douglas J. Steele 555 Sherbourne St. Toronto ON M4X 1W6 Canada 3 Ben - Clothier 2015 Monterey St. San Antonio TX 78207 USA 4 Tom - Wickerath 2317 185th Place NE Redmond WA 98052 USA 이렇게 테이블을 수정하면 컬럼당 특성이 한 개만 있음 따라서 하나 이상의 개별 특성에서 검색이나 그룹핑을 쉽게 할 수 있음 또한 아래 SQL 쿼리를 통해서 원래 데이터를 생성할 수도 있음SELECT AuthorID AS AuthID, CONCAT(AuthFirst, CASE WHEN AuthMid IS NULL THEN ' ' ELSE CONCAT(' ', AuthMid, ' ') END, AuthLast) AS AuthName, CONCAT(AuthStNum, ' ', AuthStreet, ' ', AuthCity, ', ', AuthStProv, ' ', AuthPostal, ', ', AuthCountry) AS AuthAddressFROM Authors; 올바른 테이블 설계는 개별 특성을 자체 컬럼에 할당함. 한 컬럼에 여러 특성이 포함되지 않도록 해야 함 일부 app에서는 주소나 전화번호 같은 컬럼의 일부를 걸러내기 위해 최소 수준의 데이터 조각으로 분할해야 함 보고서나 목록을 뽑으려고 특성들을 재결합 할때는 SQL의 문자열 연결 기능을 사용함Better way 5 - 왜 계산 데이터를 저장하면 좋지 않은지 이해하자 계산 컬럼을 현행화 하는 가장 원시적인 방법은 계산에 사용되는 원천 컬럼이 있는 테이블에 트리거를 추가하는 것 트리거는 대상 테이블에 데이터가 입력, 갱신, 삭제 될 때 수행하는 코드 하지만 트리거는 정확하게 작성하기 어렵고, 비용도 비싸다는 단점이 있음 트리거보다 나은 선택은 테이블을 생성할 때 계산 컬럼을 정의하는 방법이 있음 (몇몇 DB 시스템에서 제공) 이렇게 하면 트리거를 작성할 때 필요한 복잡한 코드를 작성하지 않아도 된다는 장점 SQL Server에서는 AS 키워드 다음에 수행할 계산을 정의하는 표현식을 붙일 수 있음 결정적 (Dterministic) 함수: 특정 값 집합이 입력되면 언제나 동일한 결과를 반환 비결정적 (Nondterministic) 함수: 특정 값 집합이 입력되더라도 매번 다른 값을 반환할 수 있음 테이블을 정의할 때, 계산 컬럼을 정의할 수 있지만, 성능을 고려해야 함 트리거를 사용하여 계산 컬럼을 일반 컬럼처럼 정의할 수 있지만, 작성해야 할 코드가 복잡함 계산 컬럼은 DB 시스템에 추가적인 부하를 일으키므로 득과 실을 따져서 사용해야 함Better way 6 - 참조 무결성을 보호하려면 외래키를 정의하자 그림 1-8 전형적인 Sales Orders 데이터베이스의 테이블 설계 DB 스키마를 제대로 설계하려면 관련된 부모 테이블의 기본키를 포함하도록 테이블에 외래키를 정의하는 것이 좋음 Orders 테이블은 Customers 테이블의 기본키를 가리키는 CustomerID 컬럼을 정의하여 고객 정보 식별 가능 위 사진에서 각 관계선 끝에 위치한 열쇠 기호는 한 테이블의 기본키와 관계를 맺고 있음을 의미 반대편 끝에 있는 무한대 기호는 두 번째 테이블의 외래키와 일대다 관계를 맺고 있음을 의미 선언적 참조 무결성 (Declarative Referential Integrity, DRI)을 정의하여 DB 시스템은 테이블 간 관계를 알고 있음 일대다 관계에서 ‘다’에 해당하는 테이블에 데이터를 입력, 변경하거나 ‘일’에 해당하는 테이블의 데이터를 변경, 삭제할 때, 데이터베이스 시스템이 데이터 무결성을 강화하는데 도움을 줌 일부 DB 시스템에서는 참조 무결성 제약 조건을 정의하면 자동으로 외래키 컬럼에 인덱스를 만듦 조인을 수행할 떄 성능 향상 효과가 있음 외래키 컬럼에 자동으로 인덱스가 만들어지지 않는다면, 따로라도 만드는게 좋음 Better way 7 - 테이블 간 관계를 명확히 하자 출처: SQL 코딩의 기술 책 리뷰" }, { "title": "밑시딥1 3강. 신경망", "url": "/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-3%EA%B0%95-%EC%8B%A0%EA%B2%BD%EB%A7%9D/", "categories": "Review - IT Book, 밑바닥부터 시작하는 딥러닝1", "tags": "AI, 밑시딥1, Deep learning, Machine learning", "date": "2022-10-06 22:00:00 +0900", "snippet": "이번 글에서는 밑바닥부터 시작하는 딥러닝1 책의 3강에 대한 리뷰를 시작합니다. 앞서 딥러닝의 기초 개념인 퍼셉트론을 학습했는데, 이어서 딥러닝의 중요한 개념인 신경망에 대해 학습합니다. 퍼셉트론과 달리 신경망이 어떻게 동작하는지, 그리고 활성화 함수는 무엇인지 등에 대해서도 배울 예정입니다. 마지막으로는, 손글씨 숫자 이미지 데이터로 유명한 MNIST 데이터를 활용하여 결과도 확인해봅니다. Chapter Title Main Topics 1강 헬로 파이썬 파이썬 기초 문법 소개, numpy, matplotlib 2강 퍼셉트론 AND, NAND, OR 게이트 3강 신경망 활성화 함수, 다차원 배열 계산, 출력층 설계, MNIST 4강 신경망 학습 손실 함수, 경사 하강법 5강 오차역전파법 역전파, 활성화 함수 구현 6강 학습 관련 기술들 매개변수 갱신, 배치 정규화, 하이퍼파라미터 값 찾기 7강 합성곱 신경망 (CNN) 합성곱 계층, 풀링 계층, CNN 구현 8강 딥러닝 (Deep learning) 초기 역사, 딥러닝 활용 Appendix Softmax with loss 계층의 계산 그래프 - 밑바닥부터 시작하는 딥러닝 1 밑바닥부터 시작하는 딥러닝 1 Github 링크 참고 - 다크 모드가 아닌 화이트 모드로 보시면 자료를 편하게 확인 가능합니다!Chapter 3. 신경망3.1 퍼셉트론에서 신경망으로 (Multi-layer) 퍼셉트론으로 복잡한 함수를 표현할 수 있음 But, 가중치를 설정하는 작업은 여전히 사람이 해야 함 So, 매개변수의 적절한 값을 데이터로부터 자동으로 학습할 수 있도록 하는 것이 신경망의 특징3.1.1 신경망의 예 신경망은 입력층 (0층), 은닉층 (1층), 출력층 (2층)으로 구성됨 여기서 은닉층의 뉴런은 (입력층과 출력층과 달리) 사람 눈에 보이지 않음3.1.2 퍼셉트론 복습 일반적인 퍼셉트론 편향을 명시한 퍼셉트론 \\[y = \\left\\{ \\begin{array}\\\\ 0 &amp; (b + w_1x_1 + w_2x_2 &lt;= 0) \\\\ 1 &amp; (b + w_1x_1 + w_2x_2 &gt; 0) \\\\ \\end{array}\\right.\\] $b$는 편향을 뜻하며, 뉴런이 얼마나 쉽게 활성화 되는지를 제어 $w_1, w_2$는 각 신호의 가중치를 뜻하며, 각 신호의 영향력을 제어 &lt;편향을 명시한 퍼셉트론&gt; 그림에서는 $x_1, x_2, 1$에 각 신호의 가중치를 곱한 후, 다음 뉴런에 전달 다음 뉴런에서는 이 신호들의 값을 더해서 활성화 될지 여부를 결정 이때, 조건 분기의 동작 (0 이상이면 1 출력, 그렇지 않으면 0 출력)을 다음과 같이 $h(x)$로 정의 입력 신호의 총합이 $h(x)$ 함수를 거쳐서 변환되어, 그 값이 y의 출력됨\\[y = h(b + w_1x_1 + w_2x_2)\\]\\[h(x) = \\left\\{ \\begin{array}\\\\ 0 &amp; (x &lt;= 0) \\\\ 1 &amp; (x &gt; 0) \\\\ \\end{array}\\right.\\]3.1.3 활성화 함수의 등장 위의 $h(x)$ 함수처럼 입력 신호의 총합을 출력 신호로 변환하는 함수를 활성화 (Activation) 함수 라고 정의 위에서 정의한 식을 조금 풀어서 적으면 다음과 같이 표현 가능 이 식에서 $a$는 가중치가 달린 입력 신호와 편향의 총합을 계산 한 값 즉, 가중치 신호를 조합한 결과가 a라는 노드가 되고, $h(x)$를 통과하여 y라는 노드로 변환\\[a = b + w_1x_1 + w_2x_2\\]\\[y = h(a)\\]3.2 활성화 함수 위에서 이야기 했던 $h(x)$ 함수는 임계값을 경계로 출력이 바뀌는데, 이를 계단 (Step) 함수라고 정의 따라서 퍼셉트론에서는 활성화 함수로 계단 함수를 이용 물론 신경망에서는 계단 함수 외에 다른 함수를 사용하고 있음3.2.1 시그모이드 (Sigmoid) 함수\\[h(x) = \\frac{1}{1 + exp(-x)} = \\frac{1}{1 + e^{-x}}\\] 신경망에서는 활성화 함수로 시그모이드 함수를 이용하여 신호를 변환하고, 변환된 신호를 다음 뉴런에 전달 퍼셉트론과 신경망의 주된 차이는 활성화 함수라고 할 수 있음3.2.2 계단 함수 구현하기 계단 함수는 입력이 0을 넘으면 1을 출력하고, 그 외에는 0을 출력하는 함수import numpy as npimport warningswarnings.filterwarnings(action='ignore')def step_func(x): return 1 if x &gt; 0 else 0def array_step_func(arr): return np.array(arr &gt; 0, dtype=np.int)print(step_func(1)) # 1print(step_func(-1)) # 0print(array_step_func(np.array([1, 2]))) # [1 1]print(array_step_func(np.array([1, -1]))) # [1 0]3.2.3 계단 함수의 그래프 아래 그림에서 볼 수 있듯, 계단 함수는 0을 경계로 출력이 0에서 1로 또는 1에서 0으로 바뀜import matplotlib.pyplot as pltx = np.arange(-5, 5, 0.1)y = array_step_func(x)plt.plot(x, y)plt.ylim([-0.1, 1.1])plt.title(\"Step Function graph\")plt.show() 3.2.4 시그모이드 함수 구현하기def sigmoid(x): return 1 / (1 + np.exp(-x))x = np.array([-1, 1, 2])sigmoid(x) # array([0.26894142, 0.73105858, 0.88079708])t = np.array([1, 2, 3])# 브로드캐스트 적용print(1 + t) # [2 3 4]print(1 / t) # [1. 0.5 0.33333333]x = np.arange(-5, 5, 0.1)y = sigmoid(x)plt.plot(x, y)plt.ylim([-0.1, 1.1])plt.title(\"Sigmoid Function graph\")plt.show() 3.2.5 시그모이드 함수와 계단 함수 비교 [차이점] 매끄러움 이 매끄러움이 신경망 학습에서 매우 중요한 역할을 하게 될 것 시그모이드 함수는 부드러운 곡선이며, 입력에 따라서 출력이 연속적으로 변화 한편, 계단 함수는 0을 경계로 출력이 갑자기 바뀜 [차이점] 출력값의 범위가 다름 계단 함수는 0과 1 중 하나의 값만 출력 한편, 시그모이드 함수는 실수도 출력 가능 즉, 퍼셉트론에서는 뉴런 사이에 0이나 1만 흘렀지만, 신경망에서는 연속적인 실수가 흐름 [공통점] 큰 관점에서 보면 같은 모양을 보임 입력이 작을 때는 0에 가깝고, 입력이 클 때는 1에 가까워짐 즉, 두 함수 모두 입력이 중요하면 큰 값을 출력하고, 입력이 중요하지 않으면 작은 값을 출력 또한 입력이 아무리 작거나, 커도 출력은 0과 1 사이의 값을 가짐 [공통점] 비선형 함수 시그모이드 함수는 곡선, 계단 함수는 구부러진 직선 형태의 비선형 함수 꼴을 보임 3.2.6 비선형 함수 $f(x) = ax + b$처럼 직선 형태를 띄는 것을 선형 함수라고 정의 But, 위에서 봤던 시그모이드 함수나 계단 함수처럼 직선 1개로 그릴 수 없는 함수를 비선형 함수라고 정의 신경망의 활성화 함수를 선형 함수로 하는 경우에, 깊은 층이 의미가 없어지므로 비선형 함수를 사용해야 함 은닉층이 없는 네트워크 3.2.7 ReLU (Rectified Linear Unit) 함수 ReLU 함수는 입력이 0을 넘으면 그 입력을 그대로 출력하고, 0 이하면 0을 출력하는 함수 이번 장에서는 시그모이드 함수를 사용하지만, 후반부에서는 ReLU 함수를 활성화 함수로 사용\\[h(x) = \\left\\{ \\begin{array}\\\\ x &amp; (x &gt; 0) \\\\ 0 &amp; (x &lt;= 0) \\\\ \\end{array}\\right.\\]def ReLU(x): return np.maximum(0, x) # 두 입력 중 더 큰 값을 선택해서 반환x = np.arange(-5, 5, 0.1)y = ReLU(x)plt.plot(x, y)plt.ylim([-1, 5.5])plt.title(\"ReLU Function graph\")plt.show() 3.3 다차원 배열의 계산3.3.1 다차원 배열 다차원 배열도 기본은 숫자의 집합 숫자가 한 줄로, 직사각형으로, N차원으로 나열된 것 등을 모두 다차원 배열이라고 정의 2차원 배열은 행렬 (Matrix)이라고 부르고, 가로 방향을 행, 세로 방향을 열이라고 정의A = np.array([1, 2, 3, 4])print(np.ndim(A), A.shape) # 1 (4,)B = np.array([[1, 2], [3, 4], [5, 6]])print(np.ndim(B), B.shape) # 2 (3, 2)3.3.2 행렬의 곱 행렬의 곱은 numpy에서 np.dot() 함수를 통해서 확인 가능 주의해야 할 것은 np.dot(A, B)와 np.dot(B, A)는 달라질 수도 있음 행렬의 곱을 수행하기 위해서는 행렬 A의 열 수와 행렬 B의 행 수가 같아야 함A = np.array([[1, 2], [3, 4]])B = np.array([[5, 6], [7, 8]])print(np.dot(A, B)) # [[19 22] [43 50]] print(np.dot(B, A)) # [[23 34] [31 46]]A = np.array([[1, 2], [3, 4], [5, 6]])B = np.array([7, 8])print(A.shape, B.shape) # (3, 2) (2,) print(np.dot(A, B)) # [23 53 83]3.3.3 신경망에서 행렬의 곱X = np.array([1, 2])W = np.array([[1, 3, 5], [2, 4, 6]])print(X.shape, W.shape) # (2,) (2, 3) print(np.dot(X, W)) # [ 5 11 17]3.4 3층 신경망 구현하기 입력층 (0층)은 2개, 첫 번째 은닉층 (1층)은 3개, 두 번째 은닉층 (2층)은 2개, 출력층 (3층)은 2개의 뉴런3.4.1 표기법 설명3.4.2 각 층의 신호 전달 구현하기\\[a_1^{(1)} = w_{11}^{(1)}x_1 + w_{12}^{(1)}x_2 + b_1^{(1)}\\]\\[A^{(1)} = XW^{(1)} + B^{(1)}\\] 위 그림에서는 편향 $b$을 뜻하는 뉴런 1이 추가 편향은 오른쪽 아래 인덱스가 하나 밖에 없음 (앞 층의 편향 뉴런이 하나 뿐이기 때문)X = np.array([1, 0.5])W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])B1 = np.array([0.1, 0.2, 0.3])print(X.shape, W1.shape, B1.shape) # (2,) (2, 3) (3,) A1 = np.dot(X, W1) + B1print(f\"A1 = {A1}\") # A1 = [0.3 0.7 1.1] 은닉층에서 가중치 합을 a로 표기하고, 활성화 함수 $h()$로 변환된 신호를 $z$로 표기 여기서 활성화 함수는 시그모이드 함수를 활용Z1 = sigmoid(A1)print(f\"A1 = {A1}\") # A1 = [0.3 0.7 1.1]print(f\"Z1 = {Z1}\") # Z1 = [0.57444252 0.66818777 0.75026011] 이번에는 1층의 출력값이었던 Z1이 입력이 된다는 점 빼고는 모두 동일W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])B2 = np.array([0.1, 0.2])print(Z1.shape, W2.shape, B2.shape) # (3,) (3, 2) (2,) A2 = np.dot(Z1, W2) + B2Z2 = sigmoid(A2)print(f\"A2 = {A2}\") # A2 = [0.51615984 1.21402696]print(f\"Z2 = {Z2}\") # Z2 = [0.62624937 0.7710107 ] 출력층의 활성화 함수는 입력을 그대로 출력해주는 항등 함수로 정의 출력층의 활성화 함수를 $\\sigma()$로 표시하여 은닉층의 활성화 함수인 $h()$와 다름을 명시def identity_func(x): return xW3 = np.array([[0.1, 0.3], [0.2, 0.4]])B3 = np.array([0.1, 0.2])print(Z2.shape, W3.shape, B3.shape) # (2,) (2, 2) (2,) A3 = np.dot(Z2, W3) + B3Y = identity_func(A3)print(f\"A3 = {A3}\") # A3 = [0.31682708 0.69627909]print(f\"Y = {Y}\") # Y = [0.31682708 0.69627909]3.4.3 구현 정리 신경망 구현 관례에 따라 가중치만 W1 같이 대문자로 표현, 그 외 편향과 중간 결과는 소문자로 표현# 가중치와 편향을 초기화하고, dic에 할당def init_network(): network = {} network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]]) network['b1'] = np.array([0.1, 0.2, 0.3]) network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]]) network['b2'] = np.array([0.1, 0.2]) network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]]) network['b3'] = np.array([0.1, 0.2]) return network# 입력 신호를 출력으로 변환하는 처리 과정 구현# 신호가 순방향 (입력 -&gt; 출력)으로 전달되므로 forward (순전파)로 정의def forward(network, x): W1, W2, W3 = network['W1'], network['W2'], network['W3'] b1, b2, b3 = network['b1'], network['b2'], network['b3'] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, W2) + b2 z2 = sigmoid(a2) a3 = np.dot(z2, W3) + b3 y = identity_func(a3) return ynetwork = init_network()x = np.array([1, 0.5])y = forward(network, x)print(y) # [0.31682708 0.69627909]3.5 출력층 설계하기 신경망은 분류와 회귀 모두 이용 가능 분류: 데이터가 어느 class에 속하는지를 찾는 유형 회귀: 데이터에서 연속적인 수치를 예측하는 유형 일반적으로 회귀에는 항등 함수, 분류에는 시그모이드 및 소프트맥스 함수를 활성화 함수로 사용3.5.1 항등 함수와 소프트맥스 함수 구현하기 항등 (identity) 함수는 입력을 그대로 출력하므로, 출력층에서 이를 사용하면 입력 신호가 그대로 출력 분류에서 사용하는 소프트맥스 (softmax) 함수 n은 출력층의 뉴런 수 $y_k$는 그 중 $k$번째 출력을 뜻함 소프트맥스 함수의 출력은 모든 입력 신호로부터 화살표를 받고 있음 그 이유는 출력층의 각 뉴런이 모든 입력 신호에서 영향을 받았기 때문\\[y_k = \\frac{exp(a_k)}{\\sum_{i=1}^{n} exp(a_i)}\\] 항등 함수 소프트맥스 함수 a = np.array([0.3, 2.9, 4.0])exp_a = np.exp(a)sum_exp_a = np.sum(exp_a)y = exp_a / sum_exp_aprint(y) # [0.01821127 0.24519181 0.73659691]def softmax(a): exp_a = np.exp(a) sum_exp_a = np.sum(exp_a) return exp_a / sum_exp_a3.5.2 소프트맥스 함수 구현 시 주의점 위 softmax 함수는 컴퓨터로 계산할 때, 오버플로라는 결함이 존재 지수 함수를 사용할 때, 너무 큰 값을 쉽게 내뱉는다는 한계 따라서 소프트맥스 함수를 개선 C라는 임의의 정수를 분자와 분모 양쪽에 곱하기 C를 지수 함수 exp() 안으로 옮겨 logC로 만들기 logC를 C’이라는 새로운 기호로 바꾸기 이를 통해 알 수 있는 것 소프트맥스의 지수 함수를 계산할 때, 어떤 정수를 더하거나 빼도 결과는 바뀌지 않음 C’에 어떤 값을 대입해도 상관 없지만, 오버플로를 막을 목적으로는 입력 신호 중 최댓값을 이용 a = np.array([1010, 1000, 990])# 소프트맥스 함수의 계산np.exp(a) / np.sum(np.exp(a)) # array([nan, nan, nan])c = np.max(a)# nan만 나왔던 위 결과와 달리 정상 값이 나옴print(a - c) # [ 0 -10 -20]np.exp(a - c) / np.sum(np.exp(a - c))# array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])3.5.3 소프트맥스 함수의 특징 소프트맥스 함수의 출력은 0에서 1 사이의 실수 소프트맥스 함수 출력의 총합은 1 이러한 성질들을 통해 함수의 출력 값을 확률로 해석 가능 소프트맥스 함수를 적용해도 각 원소의 대소 관계는 변하지 않음 신경망을 이용한 분류에서는 가장 큰 출력을 내는 뉴런에 해당하는 클래스로만 인식 기계학습 문제 풀이는 학습과 추론의 단계로 이뤄짐 학습 (Train): 데이터를 통해서 모델이 학습하는 단계 추론 (Inference): 학습한 모델로 미지의 데이터에 대해 추론 (분류)을 수행 a = np.array([0.3, 2.9, 4.0])y = softmax(a)# y[0], y[1], y[2]의 확률값print(y) # [0.01821127 0.24519181 0.73659691] np.sum(y) # 1.03.5.4 출력층의 뉴런 수 정하기 출력층의 뉴런 수는 풀려는 문제에 맞게 적절히 정해야 함 분류에서는 분류하고 싶은 클래스 수로 설정하는 것이 일반적 0부터 9 중 하나로 분류하는 문제에서의 출력층 뉴런은 10개로 설정 3.6 손글씨 숫자 (MNIST) 인식3.6.1 MNIST 데이터셋 MNIST라는 데이터셋은 손글씨 숫자 이미지 집합 0부터 9까지의 숫자 이미지로 구성 훈련 이미지는 60,000장, 시험 이미지는 10,000장 MNIST 이미지 데이터는 28 * 28 크기의 회색조 이미지 (1채널) 각 픽셀은 0에서 255까지의 값을 취함 각 이미지에는 그 이미지가 실제 의미하는 숫자가 레이블로 붙어 있음 import sys, osimport picklegithub_url = '/Users/paul/Desktop/github/deep-learning-from-scratch-master/'sys.path.append(github_url)from dataset.mnist import load_mnist(x_train, t_train), (x_test, t_test) = \\ load_mnist(flatten=True, normalize=False)print(x_train.shape) # (60000, 784)print(t_train.shape) # (60000,)print(x_test.shape) # (10000, 784)print(t_test.shape) # (10000,)from PIL import Imagedef img_show(img): pil_img = Image.fromarray(np.uint8(img)) pil_img.show() img = x_train[0]label = t_train[0]print(label) # 5print(img.shape) # (784,)img = img.reshape(28, 28) # 형상을 원래 이미지의 크기로 변형print(img.shape) # (28, 28)img_show(img)3.6.2 신경망의 추론 처리 MNIST 데이터셋은 입력층 뉴런을 784개, 출력층 뉴런을 10개로 구성 입력층 뉴런이 784개인 이유는 이미지 크기가 28 * 28 = 784 출력층 뉴런이 10개인 이유는 0부터 9까지 숫자를 구분하기 때문 은닉층은 총 두 개로, 첫 번째 은닉층에는 50개의 뉴런, 두 번째 은닉층에는 100개의 뉴런 배치 (임의로 설정) 입력 이미지 데이터에 대한 전처리 작업으로 정규화를 수행 정규화 (Normalization): 데이터를 특정 범위로 변환하는 처리 전처리 (Pre-processing): 신경망의 입력 데이터에 특정 변환을 가하는 것 백색화 (Whitening): 전체 데이터를 균일하게 분포시키는 것 def get_data(): (x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, flatten=True, one_hot_label=False) return x_test, t_testdef init_network(): # 가중치와 편향 매개변수가 dictionary 변수로 저장되어 있는 pickle 파일 with open(github_url + \"ch03/sample_weight.pkl\", 'rb') as f: network = pickle.load(f) return networkdef predict(network, x): W1, W2, W3 = network['W1'], network['W2'], network['W3'] b1, b2, b3 = network['b1'], network['b2'], network['b3'] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, W2) + b2 z2 = sigmoid(a2) a3 = np.dot(z2, W3) + b3 y = softmax(a3) return yx, t = get_data()network = init_network() print(network.keys()) # dict_keys(['b2', 'W1', 'b1', 'W2', 'W3', 'b3'])accuracy_cnt = 0for i in range(len(x)): y = predict(network, x[i]) p = np.argmax(y) # 확률이 가장 높은 원소의 인덱스 (clas) if p == t[i]: accuracy_cnt += 1# 가장 마지막 데이터의 예측 확률값과 classprint(y, p)# [4.2882856e-04 2.0043008e-06 2.5405665e-03 2.0168895e-06 5.5917690e-04# 3.1262048e-04 9.9614757e-01 4.3499364e-07 6.3756829e-06 3.7751408e-07] 6 print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))# Accuracy:0.93523.6.3 배치 처리 아래의 결과에서 확인할 수 있듯, 다차원 배열의 대응하는 차원의 원소 수가 일치 가장 마지막 최종 결과는 원소가 10개인 1차원 배열 y가 출력 이미지 100장을 묶어서 나온 결과를 보면 다음과 같음 하나로 묶은 입력 데이터를 배치 (batch)라고 정의### 개별로 predict 한 결과가 아닌, 배치 단위로 predict하여 결과 확인x, t = get_data()network = init_network()batch_size = 100 # 배치 크기accuracy_cnt = 0for i in range(0, len(x), batch_size): # x[0:100], x[100:200], ...과 같은 형태 x_batch = x[i:i+batch_size] y_batch = predict(network, x_batch) p = np.argmax(y_batch, axis=1) accuracy_cnt += np.sum(p == t[i:i+batch_size])# 가장 마지막 데이터의 예측 확률값과 class의 shapeprint(y_batch.shape, p.shape) # (100, 10) (100,)print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x))) # Accuracy:0.93523.7 정리 신경망에서는 활성화 함수로 시그모이드, ReLU 함수 같은 비선형 함수를 활용 numpy의 다차원 배열을 잘 사용하면, 신경망을 효율적으로 구현할 수 있음 출력층의 활성화 함수로 회귀에서는 항등 함수, 분류에서는 소프트맥스 함수를 사용 분류에서는 출력층의 뉴런 수를 분류하려는 클래스 수와 같게 설정 입력 데이터를 묶은 것을 배치라고 하고, 추론 처리를 이 배치 단위로 진행하면 결과를 빨리 얻을 수 있음추가 학습 - tensorflow를 활용한 MNIST 실습import tensorflow as tf# 1. 데이터 불러오기mnist = tf.keras.datasets.mnist(x_train, y_train), (x_test, y_test) = mnist.load_data()# 2. 간단한 데이터 전처리x_train, x_test = x_train / 255.0, x_test / 255.0# 3. 모델 구성model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(256, activation=tf.nn.relu), tf.keras.layers.Dense(10, activation=tf.nn.softmax)])# 4. 모델 컴파일model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])# 5. 모델 훈련history = model.fit(x_train, y_train, epochs=10)# 6 훈련 과정 시각화plt.plot(history.history['accuracy'])plt.plot(history.history['loss'])plt.title('Model accuracy &amp; loss')plt.xlabel('Epoch') ; plt.ylabel('Value')plt.legend(['Accuracy', 'Loss'], loc='upper left')plt.show()# 7. 정확도 평가test_loss, test_acc = model.evaluate(x_test, y_test)print('테스트 정확도:', test_acc)Epoch 1/101875/1875 [==========================] - 4s 2ms/step - loss: 0.2236 - accuracy: 0.9347Epoch 2/101875/1875 [==========================] - 3s 2ms/step - loss: 0.0909 - accuracy: 0.9724Epoch 3/101875/1875 [==========================] - 3s 2ms/step - loss: 0.0602 - accuracy: 0.9815Epoch 4/101875/1875 [==========================] - 3s 2ms/step - loss: 0.0435 - accuracy: 0.9867Epoch 5/101875/1875 [==========================] - 3s 2ms/step - loss: 0.0316 - accuracy: 0.9900Epoch 6/101875/1875 [==========================] - 3s 2ms/step - loss: 0.0241 - accuracy: 0.9922Epoch 7/101875/1875 [==========================] - 3s 2ms/step - loss: 0.0195 - accuracy: 0.9936Epoch 8/101875/1875 [==========================] - 3s 2ms/step - loss: 0.0151 - accuracy: 0.9952Epoch 9/101875/1875 [==========================] - 3s 2ms/step - loss: 0.0131 - accuracy: 0.9956Epoch 10/101875/1875 [==========================] - 3s 2ms/step - loss: 0.0112 - accuracy: 0.9964 313/313 [==========================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9795테스트 정확도: 0.9794999957084656 출처: 밑바닥부터 시작하는 딥러닝1 책 리뷰 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "밑시딥1 2강. 퍼셉트론", "url": "/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-2%EA%B0%95-%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0/", "categories": "Review - IT Book, 밑바닥부터 시작하는 딥러닝1", "tags": "AI, 밑시딥1, Deep learning, Machine learning", "date": "2022-10-05 10:00:00 +0900", "snippet": "이번 글에서는 본격적으로 밑바닥부터 시작하는 딥러닝1 책에 대한 리뷰를 시작합니다. 딥러닝의 가장 기초 개념이라고 할 수 있는 퍼셉트론이 무엇인지에 대해 학습합니다. 또한 AND, NAND, OR 게이트 등을 통해서 퍼셉트론의 구조와 동작 원리도 함께 배울 수 있습니다. Chapter Title Main Topics 1강 헬로 파이썬 파이썬 기초 문법 소개, numpy, matplotlib 2강 퍼셉트론 AND, NAND, OR 게이트 3강 신경망 활성화 함수, 다차원 배열 계산, 출력층 설계, MNIST 4강 신경망 학습 손실 함수, 경사 하강법 5강 오차역전파법 역전파, 활성화 함수 구현 6강 학습 관련 기술들 매개변수 갱신, 배치 정규화, 하이퍼파라미터 값 찾기 7강 합성곱 신경망 (CNN) 합성곱 계층, 풀링 계층, CNN 구현 8강 딥러닝 (Deep learning) 초기 역사, 딥러닝 활용 Appendix Softmax with loss 계층의 계산 그래프 - 밑바닥부터 시작하는 딥러닝 1 밑바닥부터 시작하는 딥러닝 1 Github 링크Chapter 2. 퍼셉트론2.1 퍼셉트론이란? 신경망 (딥러닝)의 기원이 되는 알고리즘인 퍼셉트론 퍼셉트론의 구조를 배우는 것은 신경망 및 딥러닝을 배우는데 기초가 될 것 퍼셉트론은 다수의 신호 (흐름이 있는 것)를 입력으로 받아서 하나의 신호를 출력하는 것 이 그림은 입력으로 2개의 신호를 받은 퍼셉트론의 예 그림에서 원은 뉴런 혹은 노드라고 부름 입력 신호가 뉴런에 보내질 때는 각각 고유한 가중치가 곱해짐 $x_1, x_2$는 입력 신호, $y$는 출력 신호, $w_1, w_2$는 가중치 뉴런에서 보내온 신호의 총합이 정해진 한계를 넘어설 때만 1을 출력 (뉴런 활성화) 한계값을 임계값이라고 하고, $\\theta$로 표현 퍼셉트론은 복수의 입력 신호 각각에 고유한 가중치 부여 가중치는 각 신호가 결과에 주는 영향력을 조절하는 요소로 작용 (신호가 클수록 그만큼 중요하다는 것)2.2 단순한 논리 회로2.2.1 AND 게이트 AND 게이트는 입력이 둘이고, 출력은 하나 AND 게이트는 두 입력이 모두 1일 때만, 1을 출력하고 그 외에는 0을 출력2.2.2 NAND 게이트와 OR 게이트 NAND 게이트는 Not AND를 의미하고, AND 게이트의 출력을 뒤집은 것 OR 게이트는 입력 신호 중 하나 이상이 1이면 출력이 1이 되는 것2.3 퍼셉트론 구현하기2.3.1 간단한 구현부터def AND(x1, x2): w1, w2, theta = 0.5, 0.5, 0.7 tmp = x1*w1 + x2*w2 return 0 if tmp &lt;= theta else 1for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = AND(xs[0], xs[1]) print(str(xs) + \" -&gt; \" + str(y))(0, 0) -&gt; 0(1, 0) -&gt; 0(0, 1) -&gt; 0(1, 1) -&gt; 12.3.2 가중치와 편향 도입 기존에 퍼셉트론 동작 원리의 식에서 $\\theta$를 $-b$로 치환하면 다음의 식 확인 가능 여기에서 $b$를 편향 (bias)이라 하고, $w_1, w_2$는 그대로 가중치 퍼셉트론은 입력 신호에 가중치를 곱한 값과 편향을 더해서, 출력값을 결정2.3.3 가중치와 편향 구하기 $w_1, w_2$ (가중치)는 각 입력 신호가 결과에 주는 영향력 (중요도)을 조절하는 매개변수 $b$ (편향)는 뉴런이 얼마나 쉽게 활성화 (결과를 1로 출력) 하느냐를 조정하는 매개변수 $b$가 -0.1이면, 각 입력 신호에 가중치를 곱한 값들의 합이 0.1을 초과하면 활성화 $b$가 -20.0이면, 각 입력 신호에 가중치를 곱한 값들이 20을 넘어야 활성화 이처럼 편향의 값은 뉴런이 얼마나 쉽게 활성화 되는지 결정할 수 있음 import numpy as npdef AND(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.7 tmp = np.sum(w*x) + b return 0 if tmp &lt;= 0 else 1 for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = AND(xs[0], xs[1]) print(str(xs) + \" -&gt; \" + str(y))(0, 0) -&gt; 0(1, 0) -&gt; 0(0, 1) -&gt; 0(1, 1) -&gt; 1def NAND(x1, x2): x = np.array([x1, x2]) w = np.array([-0.5, -0.5]) b = 0.7 tmp = np.sum(w*x) + b return 0 if tmp &lt;= 0 else 1for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = NAND(xs[0], xs[1]) print(str(xs) + \" -&gt; \" + str(y))(0, 0) -&gt; 1(1, 0) -&gt; 1(0, 1) -&gt; 1(1, 1) -&gt; 0def OR(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.2 tmp = np.sum(w*x) + b return 0 if tmp &lt;= 0 else 1for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = OR(xs[0], xs[1]) print(str(xs) + \" -&gt; \" + str(y))(0, 0) -&gt; 0(1, 0) -&gt; 1(0, 1) -&gt; 1(1, 1) -&gt; 1 기존에 퍼셉트론 동작 원리의 식에서 $\\theta$를 $-b$로 치환하면 다음의 식 확인 가능 여기에서 $b$를 편향 (bias)이라 하고, $w_1, w_2$는 그대로 가중치 퍼셉트론은 입력 신호에 가중치를 곱한 값과 편향을 더해서, 출력값을 결정2.4 퍼셉트론의 한계2.4.1 도전! XOR 게이트 XOR 게이트는 배타적 논리합이라는 논리 회로 $x_1, x_2$ 중에서 하나가 1일 때만 1을 출력2.4.2 선형과 비선형 선형식 (직선)으로 XOR 게이트를 표현하는 것은 사실상 불가 하지만 비선형 (곡선)으로는 다음과 같이 표현 가능 즉, 퍼셉트론은 직선 하나로 나눈 영역만 표현할 수 있다는 한계가 있음2.5 다층 퍼셉트론이 출동한다면 단일 퍼셉트론으로는 XOR 게이트를 구현할 수 없었음 하지만 층을 쌓아서 올리는 다층 퍼셉트론 (Multi-layer perceptron)으로는 구현 가능2.5.1 기존 게이트 조합하기2.5.2 XOR 게이트 구현하기def XOR(x1, x2): s1 = OR(x1, x2) s2 = NAND(x1, x2) y = AND(s1, s2) return yfor xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = XOR(xs[0], xs[1]) print(str(xs) + \" -&gt; \" + str(y))(0, 0) -&gt; 0(1, 0) -&gt; 1(0, 1) -&gt; 1(1, 1) -&gt; 0 XOR 게이트는 다음과 같은 다층 구조의 네트워크 이처럼 층이 여러 개인 퍼셉트론을 다층 퍼셉트론이라고 함 0층의 두 뉴런이 입력 신호를 받아서 1층의 뉴런으로 신호를 보냄 1층의 뉴런이 2층의 뉴런으로 신호를 보내고, 2층의 뉴런은 y를 출력 단층 퍼셉트론으로는 표현하지 못한 것을 층을 하나 더 늘려서 구현 퍼셉트론은 층을 깊게 쌓아서 더 다양한 것들을 표현할 수 있음2.6 NAND에서 컴퓨터까지 NAND 게이트의 조합만으로 컴퓨터가 수행하는 일을 재현할 수 있음2.7 정리 퍼셉트론은 입출력을 갖춘 알고리즘 퍼셉트론은 입력을 주면, 정해진 규칙에 따른 값을 출력 퍼셉트론은 가중치와 편향을 매개변수로 설정 퍼셉트론으로 AND, OR 같은 논리회로 표현 가능 XOR 게이트는 단층 퍼셉트론 (직선)은 불가능하지만, 다층 퍼셉트론 (곡선)으로 구현 가능 출처: 밑바닥부터 시작하는 딥러닝1 책 리뷰 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "프로그래머스 인공지능 데브코스 3주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-3%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-10-03 10:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스의 3주차 강의에 대한 정리입니다. 지금까지 기본적인 파이썬의 자료구조와 알고리즘 그리고 크롤링과 기초 수학 등을 학습했습니다. 이번 주에는 파이썬에서 데이터를 다루는데 필요한 기초 패키지인 Numpy와 Pandas를 학습합니다. 파이썬으로 데이터를 다뤄보신 분들이라면, 익히 들어보셨을 해당 패키지들의 기본적인 내용을 보겠습니다.1. Numpy 실습import numpy as np### Numpy array shapeA = np.array([[1, 2, 3], [3, 4, 5], [6, 3, 4]]) # shape_of_A = (3, 3)### Numpy one, zero arrayA = np.ones(shape=(2, 1, 3))B = np.zeros(shape=(3, 4, 2))### Numpy random arrayA = np.random.randn(4, 3, 3)B = np.random.normal(loc=1.56, scale=0.67, size=(5, 6)) # 평균 1.56, 표준편차 0.67C = np.random.randint(10, 21, size=(3, 4)) # 10부터 20까지 임의의 정수를 담은 배열### Numpy indexingarr = np.random.randn(4, 5, 7, 8)answer = arr[2, 2, 3, 3] # arr의 (2, 2, 3, 3) 번째 요소 값 읽기### Numpy changing certain elementarr = np.random.randn(5, 3, 3, 6, 7)arr[1, 2, 2, 3, 4] = 0 # arr의 (1, 2, 2, 3, 4) 번째 요소 값을 0으로 변경### Numpy addition (+)arr_A = np.array([[1, 2, 3], [3, 4, 5]])arr_B = np.ones(shape=(2, 3))np_result = arr_A + arr_B # A와 B 배열의 합### Numpy multiply (*)arr_A = np.array([[3, 6], [2, 7]])arr_B = np.ones(shape=(2, 2))np_result = arr_A * arr_B # A와 B 배열의 곱 지금까지의 연산은 shape이 같은 두 배열 사이에서 적용된 것들 즉, 두 배열 사이에 shape이 다르다면, 연산이 제대로 동작하지 않음 그런데 Numpy에서 같은 shape이 아니더라도 연산이 가능한 경우가 있음 Numpy에서 배열의 shape이 다르더라도 자동으로 맞춰 연산하는 것을 브로드캐스팅이라고 함import numpy as np### Numpy dotA = np.random.randint(1, 4, size=(2, 3))B = np.random.randint(1, 4, size=(3, 2))C = np.dot(A, B) # A와 B의 행렬 곱 연산### Numpy 1d array slicingarr = [i * j for j in range(10) for i in range(10)]arr = np.array(arr)result = arr[42:57] # arr의 42번 인덱스부터 56번 인덱스까지 슬라이싱arr[35:50] = 1 # arr의 35번 인덱스부터 49번 인덱스까지 요소 값을 1로 변경### Numpy 2d array slicingarr = [[i * j for i in range(10)] for j in range(10)]arr = np.array(arr)result = arr[3:7, 7:10] # arr의 (3, 7)에서 (6, 9)까지 슬라이싱arr[2:6, 3:8] = 0 # arr의 (2, 3)부터 (5, 7)까지 요소 값을 0으로 변경### Numpy 2d array가 주어질 때, (y1, x1)에서 (y2, x2)까지 요소에 2를 곱한 배열 반환def solution(arr, y1, x1, y2, x2): arr[y1:y2+1, x1:x2+1] *= 2 return arr### Numpy 내적 연산def solution(x, w, b): return np.dot(x, w) + b ### Numpy bool 인덱싱arr = np.random.randint(0, 100, size=(5, 6, 3))result = arr[(arr &gt; 10) &amp; (arr &lt;= 20)] # 10보다 크고, 20보다 작거나 같은 요소 추출### Numpy 관계 연산A = np.random.randint(0, 100, size=(3, 3, 3))result = (A == 52) | (A == 1) # A 안에 52 또는 1인 요소와 같은 위치에 True, 다른 곳은 False### Numpy 배열 만들기A = [1, 2, 3, 4, 5]np_A = np.array(A) # np.array()를 이용하여 numpy.ndarray 타입의 배열 만들기### Numpy matmul() 함수a = np.random.randn(3, 16, 64)b = np.random.randn(3, 64, 8)dot_result = np.dot(a, b)matmul_result = np.matmul(a, b)### Numpy 브로드캐스팅 스칼라a = np.array([[2, 7, 5], [6, 6, 1]])result = a * 2 # 행렬 a에 모든 요소 별로 2를 곱함### Numpy any(), all()arr = np.random.randint(0, 100, size=(3, 3, 3))result1 = ((arr == 52) | (arr == 1)).any() # arr에 52 또는 1이 있는지 확인result2 = (arr[0, :, :] &gt;= 20).all() # 해당 범위의 요소가 모두 20 이상의 수를 가지고 있는지 확인Numpy의 np.dot()과 np.matmul()의 차이 numpy 패키지에서 dot 함수 documentation numpy 패키지에서 matmul 함수 documentation dot과 matmul 함수는 2d array까지의 결과는 동일 But, 2차원보다 더 큰 nd array에서는 결과가 다르다는 것을 확인할 수 있음import numpy as np### 2d array dot, matmula = np.array([[1,2], [2,3]])b = np.array(([8,4], [4,7]))print(np.dot(a,b)) # [[16 18] [28 29]]print(np.matmul(a, b)) # [[16 18] [28 29]]print(a @ b) # np.matmul()과 @ 연산은 동일### 3d array dot, matmula = np.random.rand(2, 3, 3)b = np.random.rand(2, 3, 3)c = (a @ b)d = np.dot(a,b)print(c, c.shape) # shape: (2, 3, 3)print(d, d.shape) # shape: (2, 3, 2, 3)2. Python으로 데이터 다루기 - Numpy[참고] Git과 Github 그리고 Branch란 무엇인가? Git은 분산 버전관리 시스템 (Distributed version control system) 원격 Repository와 로컬 Repository로 구분하여 협업하는데 사용 Git 저장소에서 파일의 상태를 주목하라 Local working directory (Unstaged area) Local staging area Local repository, Remote repository Branch: 코드의 흐름을 분산 - 가지치기 (Git-Flow) Github: 가장 대표적인 원격 저장소 Pull Request를 만들어서 다른 사람들과 함께 협업하기git init # 로컬 저장소 생성git status # 저장소의 상태 확인git add example.py # example.py를 unstaged에서 staged로 이동git commit -m \"Add example.py\" # commit message 작성git log # commit 기록 확인 (author, commitor, date 등)git branch &lt;branch_name&gt; # 새로운 branch 생성git checkout &lt;branch_name&gt; # 현재 작업 중인 branch를 전환git merge &lt;branch_name&gt; # 현재 작업 중인 branch_name를 원하는 branch에 병합git branch -d &lt;branch_name&gt; # branch를 삭제git remote add &lt;별칭&gt; &lt;원격저장소 주소&gt; # 원격 저장소 설정git push &lt;원격_레포_이름&gt; &lt;branch_name&gt; # 로컬 작업을 원격 레포지토리에 pushgit clone &lt;repo_uri&gt; # 원격 저장소를 로컬에 저장하기Numpy 연산, 선형 대수 Array의 Indexing, Slicing: python의 list와 유사 Array의 Boradcasting: (m * n &amp; m * 1), (m * n &amp; 1 * n), (m * 1 &amp; 1 * n) 영벡터 (영행렬): np.zeros(dim)을 통해서 생성할 수 있음 일벡터 (일행렬): np.ones(dim)을 통해서 생성할 수 있음 대각행렬: np.diag(main_diagonal)을 통해서 생성할 수 있음 항등행렬: main diagonal이 1인 대각행렬. np.eye()를 통해서 생성할 수 있음 행렬곱 (dot product): 행렬 간의 곱 연산 트레이스: main diagonal의 합. np.trace()를 통해서 생성할 수 있음 행렬식 (determinant): 행렬을 대표하는 값들 중 하나. np.linalg.det()으로 계산 가능 역행렬: 행렬 A에 대해 AB = BA = 1를 만족하는 행렬 B = A^-1. np.linalg.inv()으로 계산 가능 고유값과 고유벡터 (eigenvalue, eigenvector): np.linalg.eig()으로 계산 가능3. Python으로 데이터 다루기 - PandasPandas 시작하기 Table: 행과 열을 이용해서 데이터를 저장하고 관리하는 자료구조 (컨테이너) Series: 1d labeled array, 인덱스를 지정해 줄 수 있음 Series는 name 속성을 가지고 있음 처음 Series를 만들 때, 이름을 붙일 수 있음 DataFrame: 2d labeled table, 인덱스를 지정해 줄 수 있음 DataFrame의 각 column은 Series 형태임 head(): 처음 n개의 데이터 참조 tail(): 마지막 n개의 데이터 참조 loc[row, col]: 인덱스를 이용해서 가져오기 iloc[rowidx, colidx]: 숫자 인덱스를 이용해서 가져오기 split: 특정한 기준을 바탕으로 DataFrame 분할 apply: 통계함수 (sum, mean, median 등)를 적용해서 각 데이터 압축 combine: apply 된 결과를 바탕으로 새로운 Series 생성 4. Python으로 시각화하기 - MatplotlibMatplotlib 시작하기 Matplotlib: 파이썬의 데이터 시각화 라이브러리 꺾은선 그래프, 산점도, 박스 그림, 막대 그래프, 히스토그램, 원형 그래프 박스 그림: Q1, Q2, Q3, min, max 정보를 담고 있음 Seaborn: Matplotlib을 기반으로 더 다양한 시각화 방법을 제공하는 라이브러리 커널밀도그림, 카운트그림, 캣그림, 스트립그림, 히트맵 5. Python으로 시각화 프로젝트 Mission 1. Netflix and Code 넷플릭스 데이터를 활용 한국 작품은 총 얼마나 있는지? 가장 많은 작품이 올라간 국가는 어디이고, 얼마나 많은 작품이 있는지? Mission 2. 가상화폐 가즈아! 비트코인 데이터를 활용 이더리움 데이터를 활용 비트코인의 2016.6 ~ 2017.6 기간의 5일 이동평균선 (5-MA, Moving Average) 비트코인 가격 그래프 그리기 이더리움의 2016.6 ~ 2017.6 기간의 5일 이동평균선 (5-MA, Moving Average) 이더리움 가격 그래프 그리기 비트코인과 이더리움 그래프를 함께 비교 6. 3주차 돌아보기 기간: 2022. 10. 03 ~ 2022. 10. 089월 말 일자를 기준으로 퇴사를 하게 되어 이번 주는 데브코스 3주차이면서, 퇴사 후 첫번째 주차이기도 했다. 아무래도 회사에 있을 때보다는 시간적 그리고 심적 여유가 생긴 주차였다. 데브코스에서는 이번 주까지 해서 파이썬의 기초와 자료구조와 알고리즘, 크롤링, 기초 수학 그리고 pandas, numpy까지 학습을 마무리 했다. 아무래도 이 주제들은 과거에 접해보았거나, (끝은 없겠지만) 고민해보았던 주제여서 그나마 지금까지 따라가는데 어려움은 없었던 것 같다.지금까지 경험하지 못했던 시간적 여유 속에 참 역설적이지만 내 시간의 주인이 온전히 내가 된 것 같은 느낌이었다. 대학교를 다닐 때는 수업과 과제 그리고 모임으로 내 시간을 스스로 통제하기 보다는 외부적 요인으로 통제 당했던 것 같다. 물론 회사를 다녔던 그 시기도 동일할 것이다. 그런데 지금은 그 시간 속에 내가 주체성을 가지고 통제하고 있는 것 같다. 지금껏 느껴보지 못했던 기분이라서 처음에는 조금 어색했지만, 성향상 가만히 있지 못하고 나름의 계획을 세우기 시작했다.학교 다니면서, 회사 다니면서 하고 싶었지만 하지 못했던 많은 것들을 조금씩 정리해두었는데, 이 시간들이 나에게는 그것들을 하기에 너무 좋은 기회라는 생각이 들었다. 완전한 (것 같으면서도 그렇지 않는) 자유 속에서 이 시간들을 아주 소중히, 그리고 뜻깊게 사용하고 싶다. 크고 작은 계획들을 세우고 기록하고 있는데, 잘 정리되고 마무리가 된다면 블로그에도 기록해두고 싶다.다음 주에는 데브코스에서는 flask와 AWS 등의 새로운 주제를 배울텐데, 또 새로운 것들을 배울 수 있는 기회에 감사하다! 출처: 프로그래머스 인공지능 데브코스 4기 3주차 강의 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "밑시딥1 1강. 헬로 파이썬", "url": "/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-1%EA%B0%95-%ED%97%AC%EB%A1%9C-%ED%8C%8C%EC%9D%B4%EC%8D%AC/", "categories": "Review - IT Book, 밑바닥부터 시작하는 딥러닝1", "tags": "AI, 밑시딥1, Deep learning, Machine learning", "date": "2022-10-01 14:00:00 +0900", "snippet": " 간단한 책 소개 이 책은 신경망과 딥러닝의 기본을 직접 만들면서 그 개념을 소개하고 있습니다. 일반적으로 잘 알려진 딥러닝 프레임워크인 TensorFlow나 PyTorch가 잘 되어 있긴 하지만, 밑바닥부터 딥러닝의 모델을 직접 만들어보는 것은 매우 중요하다고 생각합니다. 그런 부분에 대한 니즈가 항상 있었는데, 프로그래머스 부트캠프를 하면서 팀원들과 같이 스터디 교재로 이 책을 선정하여 기록하고, 공부해보려고 합니다. 밑바닥부터 시작하는 딥러닝 1 밑바닥부터 시작하는 딥러닝 1 Github 링크 Chapter Title Main Topics 1강 헬로 파이썬 파이썬 기초 문법 소개, numpy, matplotlib 2강 퍼셉트론 AND, NAND, OR 게이트 3강 신경망 활성화 함수, 다차원 배열 계산, 출력층 설계, MNIST 4강 신경망 학습 손실 함수, 경사 하강법 5강 오차역전파법 역전파, 활성화 함수 구현 6강 학습 관련 기술들 매개변수 갱신, 배치 정규화, 하이퍼파라미터 값 찾기 7강 합성곱 신경망 (CNN) 합성곱 계층, 풀링 계층, CNN 구현 8강 딥러닝 (Deep learning) 초기 역사, 딥러닝 활용 Appendix Softmax with loss 계층의 계산 그래프 - Chapter 1. 헬로 파이썬1.1 파이썬이란? 파이썬은 간단하고 배우기 쉬운 프로그래밍 언어 오픈소스로 무료로 자유롭게 사용 가능 영어와 유사한 문법으로 프로그램 작성 가능 불편한 컴파일 과정이 따로 필요 없음 기계학습 같은 데이터 과학 분야에 널리 사용되고 있음1.2 파이썬 설치하기 파이썬 설치 링크 아나콘다 설치 링크1.3 파이썬 인터프리터 산술 연산 (덧셈, 뺄셈, 나눗셈, 곱셈 등) 자료형 (int, float, str 등) 변수 파이썬은 동적 언어로 분류 동적이라는 것은 변수의 자료형을 상황에 맞게 자동으로 결정하는 것 자동 형변환 리스트 (indexing, slicing) 딕셔너리 (key &amp; value) bool (True &amp; False) if/else 문 for, while 문 함수1.4 파이썬 스크립트 파일 클래스 (생성자 - init) 인스턴스 변수class Man: def __init__(self, name): self.name = name print(\"Initialized!\") def hello(self): print(\"Hello \" + self.name + \"!\") def goodbye(self): print(\"Good-bye \" + self.name + \"!\") m = Man(\"David\")m.hello()m.goodbye()Initialized!Hello David!Good-bye David!1.5 넘파이 numpy 패키지 공식 Documentation 배열이나 행렬 계산에 용이한 numpy 패키지 numpy 패키지 불러오기 - import numpy as np 배열 생성, 산술 연산, 브로드캐스트1.6 matplotlib matplotlib 패키지 공식 Documentation 시각화에 용이한 matplotlib 패키지1.7 정리 파이썬 소개 딥러닝 (신경망)을 구현하는데 필요한 프로그래밍 기본 학습 출처: 밑바닥부터 시작하는 딥러닝1 책 리뷰 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "프로그래머스 인공지능 데브코스 2주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-2%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-09-26 14:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스의 2주차 강의에 대한 정리입니다. 기본적인 파이썬의 자료구조와 알고리즘을 학습한 후에, 이번 주에는 크롤링 (스크래핑)과 함께 기초 수학에 대해 배웁니다. 인공지능을 잘 활용하기 위해서 가장 처음으로 필요한 것은 아마 데이터 수집 과정이라고 할 수 있을 것입니다. 데이터 수집 방법은 다양하게 있겠지만, 스스로 필요한 데이터를 수집하는 크롤링은 배워두면 매우 유용할 것 같습니다. 1. HTTP 요청 주고 받기 - requestsJupyter Lab 시작하기 Interactive한 python 코드 작성 / 공유를 위한 개발 도구 Jupyterlab을 pip 명령어를 통해서 install Code cell (명령 모드), Markdown cell (입력 모드)### jupyterlab installpip install jupyterlab### 마크다운 문법# 1. Header# Hello world## Hello world### Hello world# 2. Italic*Hello world*_Hello world_# 3. Bold**Hello world***__Hello world__# 4. Strikethrough (취소선)~Hello world~# 5. Unordered List- Hello- world* Hello* world# 6. Ordered List1. Hello2. world# 7. Code`Hello world`# 8. Code Block```Hello world```인터넷 사용자 간의 약속, HTTP 두 컴퓨터를 연결하는 네트워크 (Network)의 탄생 이 네트워크를 묶어서 근거리 지역 네트워크 (Local Area Network, LAN) 탄생 범지구적으로 연결된 네트워크인 인터넷 (Inter Network, Internet) 탄생 인터넷에서 정보를 교환할 수 있는 환경인 www (World Wide Web) 탄생 즉, 인터넷은 여러 컴퓨터끼리 네트워크를 연결한 것. 웹은 인터넷 상에서 정보를 교환하기 위한 시스템 웹에서 정보를 주고 받는 방법 정보를 요청하는 컴퓨터를 클라이언트 (Client), 정보를 제공하는 컴퓨터를 서버 (Server) 클라이언트가 서버에게 정보를 요청 요청에 대해서 서버가 작업을 수행 수행한 작업의 결과를 클라이언트에게 응답 HTTP (Hypertext Transfer Protocol)의 구조 웹 상에서 정보를 주고 받기 위한 약속 클라이언트에서 서버로 정보를 요청하는 것을 HTTP 요청 (Request) 요청된 정보에 대해 서버가 클라이언트에게 응답하는 것을 HTTP 응답 (Response) HTTP로 정보 요청하기 GET / HTTP 1.1 HOST: www.programmers.com User-Agent: Mozilla/5.0 HTTP / 1.1 200 OK 웹페이지와 HTML 웹 속에 있는 문서 하나는 웹 페이지, 웹 페이지의 모음은 웹 사이트 웹 브라우저는 HTML 요청을 보내고, HTTP 응답에 담긴 HTML 문서를 보기 쉬운 형태로 화면을 그려주는 역할 웹 페이지는 HTML 이라는 형식으로 되어 있고, 웹 브라우저는 HTTP 요청을 보내고, 응답받은 HTML 코드를 렌더링 HTML (HyperText Markup Language) 구조 HTML 코드는 Head (문서의 정보 - 제목, 언어 등)와 Body (문서의 내용 - 글, 이미지, 동영상 등)로 나뉨 HTML은 여러 태그(Tag)로 감싼 요소(Element)의 집합으로 이뤄짐 태그로 묶어서 글의 형식을 지정할 수 있음 태그는 그에 맞는 속성 (attribute)을 갖을 수도 있음 나의 첫 HTTP 통신 코드 requests는 python을 이용해서 간단히 HTTP 통신을 진행할 수 있는 라이브러리 정보를 달라고 요청하기, GET 정보를 갱신하는 것을 요청하기, POST### requests installpip install requests윤리적으로 웹 스크래핑, 크롤링 진행하기 웹 크롤링, 웹 스크래핑의 차이는? 웹 크롤링은 크롤러 (Crawler)를 이용해서 웹 페이지의 정보를 인덱싱하는 것에 초점 웹 스크래핑은 웹 페이지들로부터 우리가 원하는 정보를 추출하는 것에 초점 올바르게 HTTP 요청하기 웹 크롤링, 웹 스크래핑을 통해 어떤 목적을 달성하고자 하는가? (저작권 이슈) 내 웹 크롤링, 웹 스크래핑이 서버에 영향을 미치지는 않는가? 로봇 배제 프로토콜 (Robots Exclusion Standard, REP): 크롤러들은 이 규칙을 지키면서 크롤링을 진행 robots.txt를 가져오는 방법은 웹 페이지 주소에 /robots.txt를 붙이면 됨 www.naver.com/robots.txt www.programmers.com/robots.txt 2. 똑똑한 HTML 분석기 - BeautifulSoup4웹 브라우저가 HTML을 다루는 방법 Document Object Model (DOM) 문서를 렌더링하는 가장 최초의 단계 브라우저의 렌더링 엔진은 웹 문서를 로드한 후에 파싱을 진행 DOM의 목적 DOM: Document, html, head, body, style, ul, li … 각 노드를 객체로 생각하면 문서를 더욱 편리하게 관리할 수 있음 DOM Tree를 순회해서 특정 원소를 추가할 수 있음 / 찾을 수 있음 브라우저는 왜 HTML을 DOM으로 바꿀까? 원하는 요소를 동적으로 변경해줄 수 있음 원하는 요소를 쉽게 찾을 수 있음 브라우저는 HTML을 파싱해서 DOM을 생성하므로, 이를 바탕으로 요소를 찾을 수 있음 따라서 파이썬으로 HTML을 분석하는 HTML Parser가 필요함! HTML을 분석해주는 BeautifulSoup BeautifulSoup Documentation 크롬 브라우저의 개발자 도구를 이용하면, HTML 코드를 확인할 수 있음HTML의 Locator로 원하는 요소 찾기 tagname: 태그의 이름 id: 하나의 고유 태그를 가리키는 라벨 class: 여러 태그를 묶는 라벨3. 웹 브라우저 자동화 - Selenium동적 웹 페이지와의 만남 정적 웹 사이트와 동적 웹 사이트 HTML 내용이 고정된 정적 (Static) 웹 사이트 HTML 내용이 변하는 동적 (Dynamic) 웹 사이트 - 인스타그램 등 정적 웹 사이트는 HTML 문서가 완전하게 응답됨 동적 웹 사이트는 응답 후 HTML이 렌더링 될 때까지 지연시간이 존재 웹 브라우저에서는 자바스크립트라는 프로그래밍 언어가 동작하며, 비동기 처리로 필요한 데이터를 채움 동기 처리: 요청에 따른 응답을 기다리는 것 -&gt; 렌더링이 마무리 되어야만 데이터 처리가 됨 비동기 처리: 요청에 따른 응답을 기다리지 않음 -&gt; 렌더링과 데이터 처리가 같이 이뤄지게 됨 따라서 비동기 처리가 된 경우에, 상황에 따라 데이터가 완전하지 않는 경우가 발생할 수 있음 웹 브라우저와 파이썬의 만남 웹 브라우저를 자동화하는 라이브러리 Selenium 응답 후 시간을 지연시킬 수 있음 UI와 상호작용이 가능함 동적 웹 사이트는 응답 후 바로 정보를 추출하기 어려움 다양한 키보드 입력과 마우스 클릭 등의 상호작용이 필요함 이를 해결하기 위해 웹 브라우저를 Selenium을 이용하여 파이썬으로 조작하는 전략을 취함브라우저를 자동화하기, Selenium Selenium은 파이썬을 이용하여 웹 브라우저를 조작할 수 있는 자동화 프레임워크Wait and Call Selenium은 동적 웹 사이트에 대한 지원을 진행하기 위해 명시적 (Explicit) / 암묵적 (Implicit) 기다림이 있음 명시적 기다림 (Explicit wait): 다 로딩이 될 때까지 지정한 시간 동안 기다리기 (다 로딩이 될 때까지 5초 동안 기다려) 암묵적 기다림 (Implicit wait): 특정 요소에 대한 제약을 통한 기다리기 (이 태그를 가져올 수 있을떄까지 기다려)마우스 및 키보드 이벤트 처리하기 Selenium Documentation4. 시각화로 결과 요약하기 - Seaborn시각화 라이브러리, Seaborn scraping의 결과가 너무 분산되어 있으므로, 시각화로 표현해보도록 함! matplotlib을 기반으로 하는 시각화 패키지, Seaborn 다양한 그래프를 고수준에서 쉽게 그릴 수 있음뭉게뭉게 단어구름, Wordcloud 자연어 문장에서 키워드를 추출하여 해당 키워드의 빈도 수를 측정 앞에서 전처리한 정보와 Wordcloud 라이브러리를 바탕으로 워드클라우드 생성5. 인공지능 수학선형시스템 (Linear system) 선형시스템의 표현: Ax = b, 연립일차방정식의 대수적 표현 선형대수 (Linear algebra)의 목표 어떤 연립일차방정식 즉, 선형 시스템 문제라도 정형적인 방법으로 표현하고 해결하는 방법을 배우는 것 선형시스템의 구성 요소: 선형방정식 (Linear equations) 선형시스템은 3개의 방정식으로 구성 선형시스템은 우리가 알아내려는 3개의 미지수 (unknown, variable) x, y, z를 가지고 있음 즉, 3개의 Linear equations과 3개의 variables로 구성된 연립일차방정식은 다음과 같이 표현 3 * 3 linear system = 식의 개수 * 미지수의 개수 linear system 3x + y + z = 4 x - 2y - z = 1 x + y + z = 2 m * n 선형시스템의 대수적 표현 (Ax = b 형태) 선형시스템의 unknowns (미지수)를 모아서 column vector (열 벡터) x 로 표현 선형시스템의 선형방정식에 대해 다음을 수행 coefficients (계수)를 모아서 A의 row vector (행 벡터)로 표현 constant (상수)를 모아서 b에 표현 식은 행이고, 행은 식 (linear equations &lt;-&gt; row) m은 linear equation (선형방정식)의 개수, n은 unknown (미지수)의 개수 A는 m * n 행렬, x는 n 벡터, b는 m 벡터 가우스 소거법 선형시스템의 해 a의 역수 (inverse)가 존재하지 않는 경우, a가 특이 (singular)하다고 함 해가 있으면 선형시스템이 consistent 하다고 정의 해가 없으면 선형시스템이 inconsistent 하다고 정의 해가 하나인 경우: 3x = 6 해가 없는 경우: 0x = 6 해가 여러 개인 경우: 0x = 0 가우스 소거법 (Gauss elimination) 가우스 소거법은 임의의 m * n 선형시스템의 해를 구하는 가장 대표적인 방식 가우스 소거법은 다음의 두 단계로 수행됨 전방 소거법 (Forward elimination): 주어진 선형시스템을 아래로 갈수록 더 단순한 형태로 변형 후방 대임법 (Back-substitution): 아래에서부터 위로 미지수를 실제값으로 대체 소거법에 쓰이는 기본행연산 (Elementary Row Operations, EROs) Replace (치환): j번째 행을 기준 행인 i번째 행을 m배 하여 빼서 업데이트 Interchange (교환): j번째 행과 i번째 행의 위치를 서로 바꿈 Scaling (스케일링): j번째 행을 s배 스케일링 전방 소거법의 가치 주어진 선형시스템을 가장 풀기 쉬운 꼴로 변형 주어진 선형시스템의 rank를 알려줌 선형시스템이 해가 있는지 (consistent) 또는 없는지 (inconsistent) 알려줌 LU 분해 행렬분해 (Matrix decomposition) LU 분해 (LU decomposition): 가우스 소거법의 전방소거법을 행렬로 코드화 한 것 L: Lower triangular matrix (하삼각행렬) 행렬 A를 전방 소거하는데 쓰인 replacement와 scaling에 대한 EROs를 기록해 둔 행렬 U: Upper triangular matrix (상삼각행렬) 행렬 A를 전방 소거한 후 남은 upper triangular matrix (상삼각행렬) P: 행렬 A를 전방 소거하는데 쓰인 interchange에 대한 EROs를 기록해둔 행렬 (옵션) Ax = b =&gt; (LU)x = b =&gt; L (Ux) = b =&gt; Ly = b (단, Ux = y) Forward-substitution (전방 대치법)으로 y 구하기 Back-substitution (후방 대치법)으로 x 구하기 LU 분해가 가우스 소거법의 전방 소거법과 거의 같다고 할 수 있음 QR 분해 (QR decomposition) 특이값 분해 (Singular Value Decomposition, SVD) LU 분해를 활용하는 이유 수치적 안정성: 선형시스템의 해를 역행렬을 통해 구하는 것보다 PLU 분해를 이용하는 것이 수치적으로 안정적 b가 자주 업데이트 되는 경우: 행렬 A를 미리 PLU로 분해해두면, b가 업데이트 될때마다 x를 바로 계산 가능 행렬연산과 선형조합 행렬 (Matrix)은 직사각형 구조에 숫자들을 담아놓은 구조 각 숫자들은 행렬의 요소 (Entry)라고 정의 하나의 행이나 열을 가지는 행렬은 각각 행 벡터 (row vector), 열 벡터 (column vector)라고 정의 일반적으로 벡터라고 하면, 열 벡터의 형태라고 생각 1 * 1 행렬은 스칼라 (scalar)와 동일 m * n 행렬에 대한 전치 행렬 (Transpose Matrix)은 n * m 행렬의 형태를 갖음 행렬의 모든 요소가 0이면, 해당 행렬을 영 행렬 (Zero Matrix) 라고 하고, O라고 표기 영 행렬은 숫자의 -과 같은 존재로 행렬 합에 대한 항등원 역할 행과 열의 개수가 모두 n인 정사각형 모양의 행렬을 n차 정방 행렬 (Square Matrix) 이라고 정의 주대각선 (Main diagonal)이 1이고, 나머지 요소는 0인 n차 정방행렬을 항등행렬 (Identity Matrix) 이라고 정의 행렬의 곱에서 반드시 숙지해야 할 사항 행렬 C의 각 요소 C_ij는 A의 i번째 행 벡터와 B의 j번째 열 벡터의 내적 (inner product) 따라서 두 행렬의 곱 AB에 대해 A의 열 개수와 B의 행 개수는 일치해야 함 AB와 BA는 일반적으로 일치하지 않음 (행과 열을 뽑아오는 방법이 다르기 때문) 행렬의 곱은 병렬 처리 (parallel processing)를 통해서 가속 할 수 있음 스칼라 -&gt; 벡터 -&gt; 행렬 -&gt; 텐서 스칼라는 숫자 하나로 구성됨 이 스칼라를 벡터로 표현하면 1개의 구성 요소로 이뤄진 1-벡터 이 스칼라를 행렬로 표현하면 1개의 구성 요소로 이뤄진 1 * 1 행렬 벡터는 여러 숫자가 일열로 늘어선 구조 이 벡터를 행렬로 표현하면, 다양한 모양의 행렬로 표현 가능 행렬은 사각형 구조에 여러 숫자가 행과 열로 늘어선 구조 텐서는 스칼라, 벡터, 행렬을 아루르는 개념 숫자가 늘어설 수 있는 방향이 k개면, k-텐서라고 정의 0-텐서: 스칼라 1-텐서: 벡터 2-텐서: 행렬 분할 행렬 (Partitioned Matrix): 추상적 구조로 행렬 연산 수행 행렬을 조각 단위로 분할한 것으로 생각할 수 있음 행렬은 부분 행렬 (submatrix)로 이뤄진 직사각형 구조로 확장해서 생각할 수 있음 행렬을 구조적으로 보는 방법을 분할 행렬 또는 블록 행렬이라고 함 분할 행렬로 행렬의 곱 이해하기 두 행렬의 곱 AB = C를 matrix-column vector product로 볼 수 있음 두 행렬의 곱 AB = C를 row vector-matrix product로도 볼 수 있음 선형 조합 (Linear Combination) 행렬은 열 벡터의 리스트 각 열 벡터는 m-벡터이므로, m * n 행렬은 m-벡터가 n개 있다고 해석 가능 Ax = b는 행렬 A가 가지고 있는 열 벡터의 선형 조합 선형대수에서는 이처럼 벡터들에 대한 가중치 합을 특히 선형 조합 (linear combination) 이라고 정의 행렬 A의 열 벡터를 가중치 합으로 선형 조합 =&gt; 벡터 b를 만들 수 있는 가중치 조합이 존재하면 Ax = b의 해 존재 그 해는 가중치 x_i로 구성된 x라고 할 수 있음 열 벡터들에 대한 가능한 모든 선형 조합의 결과를 모아 집합으로 만든 것을 column space (열 공간)이라고 정의 좌표계 변환 (Change of Basis) 벡터의 물리적 표현: 벡터 v를 화살표로 표현 v의 크기: 화살표의 길이 v의 방향: 화살표의 방향 벡터의 수학적 표현: 벡터 v를 화살표로 표현 좌표계를 도입한 후, 벡터의 시작점을 원점에 맞추고, 끝점의 위치를 벡터 v의 수학적 표현으로 정의 v의 크기: 화살표의 길이를 계산 v의 방향: 화살표의 방향을 벡터로 표현 선형 변환 (Linear Transformation) 함수의 입력이 n-벡터이고, 출력이 m-벡터인 함수 T가 있다고 가정 이와 같이 함수의 입출력이 벡터인 함수를 변환 (Transformation) 이라고 함 이때, n = m인 경우에 해당 변환을 연산자 (Operator) 라고 함 행렬 변환 (Matrix Transformation) m * n 행렬 A에 대해 Ax는 n-벡터를 입력으로 받아, m-벡터를 출력으로 내는 변환 Ax라고 볼 수 있음 이 변환은 행렬이 정의하기 때문에 행렬 변환 (Matrix Transformation) 이라고 함 그런데 행렬 변환은 선형 함수 성질을 모두 만족하기 때문에 선형 변환 (Linear Transformation) 임 6. 2주차 돌아보기 기간: 2022. 09. 26 ~ 2022. 10. 01이번 주차에서는 웹 스크래핑과 기초 수학에 대해 학습했는데, 옛날에 배웠던 내용들을 다시 복습하는 계기가 되었다. 난이도 측면에서는 아직은 까다롭거나 하는 부분은 없어서 잘 따라가고 있는 것 같다. 개인적으로는, 이미 알고 있는 부분들에 대해서는 시간을 조금 아껴서 사용하는 것도 고려해보면 좋을 것 같다.특별히 이번 주에는 개인적으로 큰 일이 있었던 한 주였는데, 그 이유는 첫 퇴사를 했던 주차였기 때문이다. 대학 졸업하기도 전부터 결정된 첫 회사에서 데이터 사이언티스트부터 백엔드 엔지니어까지 스스로 엄청 잘했다고 이야기하는 것은 어려울 것 같지만, 나름 많은 것들을 경험하고 배울 수 있는 기회가 됐던 것 같다. 회사에서 많은 좋은 사람들을 만날 수 있어서 부족한 내 모습도 볼 수 있었고, 누군가에게는 배우고 싶은 모습을, 누군가에게는 배우고 싶지 않은 모습들도 함께 보면서 학습할 수 있었던 것 같다.퇴사를 결정하면서, 이번 주에 유난히 현재 그리고 과거의 회사 동료 분들과 회식 자리를 많이 가지게 되었는데, 옛날 생각도 많이 나면서 앞으로의 시간들을 어떻게 보내야 할지 나름의 동기부여를 갖게 되는 시간이었다. 전 회사에서 스스로 느꼈던 개인의 한계와 배움의 한계 속에서 나의 가치를 스스로가 증명할 수 있는 온전한 실력을 갖추고 싶다. 부족하겠지만, 대신 교만하지 않고 겸손하게 실력을 갈고 닦고 싶다. 나에게 주어진 지금 이 시간을 소중히 사용하자. 출처: 프로그래머스 인공지능 데브코스 4기 2주차 강의 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "프로그래머스 인공지능 데브코스 1주차 정리 및 후기", "url": "/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-1%EC%A3%BC%EC%B0%A8/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-09-20 21:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스 합격 후기에 이어서 1주차 강의에 대한 정리입니다. 지원 과정에서 코딩 테스트가 있었긴 했지만, 기본적인 자료구조나 알고리즘은 매우 중요합니다. 그러한 이유 때문인지 이번 1주차에서는 기본적인 github 사용법과 함께 자료구조와 알고리즘을 배웁니다. 그리고 배운 내용과 연관 되어 있는 코딩 테스트 문제도 함께 풀어보는 시간을 갖습니다.1. [K-Digital-Training] 인공지능 데브코스코드 리뷰 하는 방법 깃헙 (GitHub) 사용 방법을 배우자. 브랜치 만들고, 해당 브랜치로 이동 -&gt; git checkout -b &lt;branch name&gt; 작업한 내용 커밋 및 메시지 남기기 -&gt; git commit -a -m &lt;commit message&gt; 커밋한 내용 브랜치에 푸쉬하기 -&gt; git push 깃헙 페이지에서 PR (Pull Request) 생성하기 깃헙 페이지에서 PR 리뷰 및 merge 깃헙을 사용하는 이유는 여러 사람들과 함께 작업하기 위함이므로 나름의 규칙을 지키자. 코드 공유 및 리뷰는 서로 더 나은 코드를 만들기 위한 커뮤니케이션 과정 feature 브랜치 생성 방법 및 규칙, PR의 제목 형태 참고할 수 있는 링크 Basic Git commands by Atlassian 코드 리뷰 가이드 by thoughbot, 김용균님 번역 리뷰어의 의견에 대처하는 방법, Soojin Ro 알고리즘 이야기 - 요약 얼핏 보기에는 특정 라이브러리나 프레임워크를 잘 다뤄서 서비스를 만드는 코딩이 중요해보인다. 하지만 실제 개발자에게 가장 필요한 것 중 하나는 문제 해결 능력의 기반이 되는 알고리즘이다. 알고리즘은 자신의 논리적 사고나 문제 해결 능력의 기반이 되어줄 수 있다. 알고리즘 문제를 풀었다면, 어떻게 풀었는지 정리하고, 다른 사람들의 코드를 많이 보며 배우자. 간결하고 가독성 좋은 코드를 작성하자. 일관성 있는 코드를 작성하자. 참고할 수 있는 링크 visualgo algorithm-visualizer 2. 어서와! 자료구조와 알고리즘은 처음이지? (1)안녕, 자료구조 &amp; 알고리즘! 문자열 (str), 리스트 (list), 사전 (dict), 순서쌍 (tuple), 집합 (set) 해결하고자 하는 문제에 따라 최적의 해법은 서로 다를 수 있다. 따라서 자료구조 공부가 필요하다. 알고리즘이란? 어떤 문제를 해결하기 위한 절차, 방법, 명령어들의 집합 주어진 문제의 해결을 위한 자료구조와 연산 방법에 대한 선택 선형 배열 (Linear Array) 배열: 원소들을 순서대로 늘어놓은 것 리스트 (배열) 연산 -&gt; 리스트의 길이에 비례하여 선형적으로 시간이 걸림 가장 마지막에 원소 덧붙이기 -&gt; append() 가장 마지막 원소 꺼내고, 리스트 반환하기 -&gt; pop() 특정 위치에 원소 삽입하기 -&gt; insert(index위치, 삽입할 값) 특정 리스트의 위치에 있는 원소 삭제하기 -&gt; del(리스트[index]) 찾고자 하는 원소 index 탐색하기 -&gt; index(찾고자 하는 원소) 정렬 (Sort), 탐색 (Search) 파이썬 리스트의 정렬 sorted(): 내장 함수, 정렬된 새로운 리스트를 얻음 sort(): 리스트의 메서드, 해당 리스트를 정렬함 정렬 순서를 반대로 하고 싶은 경우에는 reverse = True 조건 추가 문자열로 이루어진 리스트에서 정렬 순서는 사전 순서를 따름 L = [ {'name': 'John', 'score': 83}, {'name': 'Paul', 'score': 92} ]L.sort(key = lambda x: x['name']) # name 순서로 정렬L.sort(key = lambda x: x['score']) # score 순서로 정렬 선형 탐색 (Linear Search): 앞에서 부터 뒤에까지 순차적으로 탐색하는 방법 값을 찾을 때까지 리스트의 길이만큼 반복 리스트의 길이에 비례하는 시간 소요 -&gt; O(n) 최악의 경우에는 모든 원소를 다 비교해봐야 함 def linear_search(L, x): i = 0 while i &lt; len(L) and L[i] != x: i += 1 if i &lt; len(L): return i else: return -1 이진 탐색 (Binary Search): 탐색하려는 리스트가 이미 정렬된 경우에만 적용 가능 크기 순으로 정렬되어 있다는 성질 이용 한 번 비교가 일어날 때마다 리스트를 절반씩 줄임 (divide &amp; concuer) -&gt; O(log n) def binary_search(L, x): idx = -1 lower, upper = 0, len(L) - 1 while lower &lt;= upper: middle = (lower + upper) // 2 if L[middle] == x: return middle elif L[middle] &lt; x: lower = middle + 1 else: upper = middle - 1재귀 알고리즘 기초 재귀함수 (Recursive function): 하나의 함수에서 자신을 다시 호출하여 작업을 수행하는 것 이진 트리 (Binary trees): 이진 탐색과 유사하게 접근할 수 있음 예제 1. 1부터 n까지 모든 자연수의 합 구하기def sum(n): # O(n) if n &lt;= 1: return n # 종결 조건 (trivial case), 점화식 else: return n + sum(n - 1)def sum(n): # O(n) s = 0 while n &gt;= 0: s += n n -= 1 return s 예제 2. 펙토리얼 (!)의 재귀 함수def factorial(n): if n &lt;= 1: return 1 else: return n * factorial(n - 1) 예제 3. 피보나치 순열의 재귀 함수def fibonacci(x): if x == 0: return 0 elif x == 1: return 1 else: return solution(x - 1) + solution(x - 2)재귀 알고리즘 응용 예제 1. 조합의 수 계산 - n개의 서로 다른 원소에서 m개를 선택하는 경우의 수from math import factorial as fdef combi(n, m): return f(n) / (f(m) * f(n - m))def combi(n, m): if n == m: return 1 elif m == 0: return 1 return combi(n - 1, m) + combi(n - 1, m - 1)알고리즘의 복잡도 시간 복잡도 (Time Complexity): 문제의 크기와 이를 해결하는데 걸리는 시간 사이의 관계 공간 복잡도 (Space Complexity): 문제의 크기와 이를 해결하는데 필요한 메모리 공간 사이의 관계 평균 시간 복잡도 (Average Time Complexity): 임의의 입력 패턴을 가정했을 때, 소요되는 시간의 평균 최악 시간 복잡도 (Worst-case Time Complexity): 가장 긴 시간을 소요하게 만드는 입력에 따라 소요되는 시간 Big-O Notation: 점근 표기법의 하나 - 어떤 함수의 증가 양상을 다른 함수와의 비교로 표현 입력의 크기가 n 이라고 할 때, O(logn)은 입력의 크기의 로그에 비례하는 시간이 소요된다는 것 O(n)은 입력의 크기에 비례하여 시간이 소요된다는 것 계수는 그다지 중요하지 않음 선형 시간 알고리즘: n개의 무작위로 나열된 수에서 최댓값을 찾기 위해 선형 탐색 알고리즘 적용 -&gt; O(n) 로그 시간 알고리즘: n개의 크기 순으로 정렬된 수에서 특정 값을 찾기 위해 이진 탐색 알고리즘 적용 -&gt; O(logn) 이차 시간 알고리즘: 삽입 정렬 (insertion sort) -&gt; O(n^2) 보다 낮은 복잡도를 갖는 정렬 알고리즘: 병합 정렬 (merge sort) -&gt; O(nlogn) 복잡한 문제: 배낭 문제 (Knapsack problem)연결 리스트 (Linked Lists) 추상적 자료구조 (Abstract Data Structures) Data: 정수, 문자열, 레코드 A set of operations: 삽입, 삭제, 순회, 정렬, 탐색 기본적인 연결 리스트 (Node)는 데이터와 Link (next)를 포함하고 있음 연산 정의: 특정 원소 참조, 리스트 순회, 길이 얻어내기, 원소 삽입 및 삭제, 두 리스트 합치기 배열과 비교한 연결 리스트 특징 배열 연결 리스트 저장 공간 연속한 위치 임의의 위치 특성 원소 지칭 매우 간편 선형 탐색과 유사 Big-O 표기 O(1) O(n) class LinkedList: def __init__(self): self.nodeCount = 0 self.head = None self.tail = None def getAt(self, pos): if pos &lt;= 0 or pos &gt; self.nodeCount: return None i = 1 curr = self.head while i &lt; pos: curr = curr.next i += 1 return curr 원소의 삽입def insertAt(self, pos, newNode): if pos &lt; 1 or pos &gt; self.nodCount + 1: return False if pos == 1: newNode.head = self.head self.head = newNode else: if pos == self.nodeCount + 1: prev = self.tail else: prev = self.getAt(pos - 1) newNode.head = prev.next prev.next = newNode if pos == self.nodCount + 1: self.tail = newNode self.nodeCount += 1 return True 연결 리스트 원소 삽입의 복잡도 맨 앞에 삽입하는 경우: O(1) 중간에 삽입하는 경우: O(n) 맨 끝에 삽입하는 경우: O(1) 연결 리스트가 힘을 발휘할 때: 삽입과 삭제가 유연하다는 것양방향 연결 리스트 (Doubly Linked Lists) 한 쪽으로만 링크를 연결하지 말고, 양쪽으로 링크를 연결하자 앞으로도 (다음 Node), 뒤로도 (이전 Node) 진행 가능3. 어서와! 자료구조와 알고리즘은 처음이지? (2)스택 (Stacks) 자료 (Data element)를 보관할 수 있는 선형 구조 단, 넣을 때에는 한 쪽 끝에서 밀어 넣어야 하고 (push 연산) 꺼낼 때에는 같은 쪽에서 뽑아 꺼내야 하는 제약이 있음 (pop 연산) 후입선출 (LIFO - Last In First Out) 특징을 갖는 선형 자료 구조 스택의 추상적 자료 구조 구현 배열을 이용하여 구현: Python 리스트와 메서드 이용 연결 리스트 (Linked list)를 이용하여 구현: 양방향 연결 리스트 이용 size(): 현재 스택에 들어 있는 데이터 원소의 수 isEmpty(): 현재 스택이 비어 있는지 판단 push(x): 데이터 원소 x를 스택에 추가 pop(): 스택의 맨 위에 저장된 데이터 원소를 제거 및 반환 peek(): 스택의 맨 위에 저장된 데이터 원소를 반환 (제거하지 않음) 수식의 후위 표기법 중위 표기법 (infix notation): 연산자가 피연산자들의 사이에 위치 -&gt; (A + B) * (C + D) 후위 표기법 (postfix notation): 연산자가 피연산자들의 뒤에 위치 -&gt; A B + C D + * 중위 표현식을 왼쪽부터 한 글자씩 읽어서 피연산자이면 그냥 출력 ’(‘ 이면 스택에 push, ‘)’ 이면 ‘(‘가 나올 때까지 스택에서 pop, 출력 연산자이면 스택에서 이보다 높거나 같은 우선순위 것들을 pop, 출력 큐 (Queues) 자료를 보관할 수 있는 선형 구조 단, 넣을 때에는 한 쪽 끝에서 밀어 넣어야 하고 (enqueue, 인큐 연산) 꺼낼 때에는 반대 쪽에서 뽑아야 하는 제약 (dequeue, 디큐 연산) 선입선출 (First In First Out, FIFO) 특징을 갖는 선형 자료구조 큐의 추상적 자료구조 구현 size(): 현재 큐에 들어 있는 데이터 원소의 수를 구함 - O(1) isEmpty(): 현재 큐가 비어 있는지를 판단 - O(1) enqueue(x): 데이터 원소 x를 큐에 추가 - O(1) dequeue(): 큐의 맨 앞에 저장된 데이터 원소를 제거 및 반환 - O(n) peek(): 큐의 맨 앞에 저장된 데이터 원소를 반환 (제거하지 않음) - O(1) 환형 큐 (Circular Queue) 큐의 활용 자료를 생성하는 작업과 그 자료를 이용하는 작업이 비동기적으로 일어나는 경우 자료를 생성하는 작업이 여러 곳에서 일어나는 경우 자료를 생성하는 작업과 그 자료를 이용하는 작업이 양쪽 다 여러 곳애서 일어나는 경우 자료를 처리하여 새로운 자료를 생성하고, 나중에 그 자료를 또 처리해야 하는 작업의 경우 환형 큐 정해진 개수의 저장 공간을 빙 돌려가면서 이용 큐가 가득차면, 더이상 원소를 넣을 수 없음 환형 큐의 추상적 자료구조 구현 기존의 큐의 추상적 자료구조 구현 내용과 동일 isFull(): 큐에 데이터 원소가 꽉 차 있는지를 판단 우선순위 큐 (Priority Queue) 큐가 FIFO 방식을 따르지 않고, 원소들의 우선순위에 따라 큐에서 빠져나오는 방식 우선순위 큐의 구현 enqueue 할 때, 우선순위 순서를 유지하도록 구현 연결 리스트 (Linked List)를 이용하여 구현 이진 트리 (Binary Trees) - 깊이 우선 순회 이진 트리의 추상적 자료구조 size(): 현재 트리에 포함되어 있는 노드의 수를 구함 depth(): 현재 트리의 깊이 또는 높이를 구함 순회 (traversal) 이진 트리의 순회 깊이 우선 순회 (depth first traversal) 중위 순회 (in-order traversal) 전위 순회 (pre-order traversal) 후위 순회 (post-order traversal) 넓이 우선 순회 (breadth first traversal) 이진 트리 (Binary Trees) - 넓이 우선 순회 원칙 수준이 낮은 노드를 우선으로 방문 같은 수준의 노드들 사이에는, 부모 노드 방문 순서에 따라 방문 왼쪽 자식 노드를 오른쪽 자식 보다 먼저 방문 재귀는 적합하지 않을 수 있음 한 노드를 방문 했을 때, 나중에 방문할 노드를 순서대로 기록해야 함 (큐를 이용!) 넓이 우선 순회 알고리즘 구현 초기화 -&gt; traversal = 빈 리스트, q = 빈 큐 빈 트리가 아니면, root node를 q에 추가 (enqueue) q가 비어 있지 않는 동안 q에서 원소를 추출 (dequeue) node를 방문 node의 왼쪽, 오른쪽 자식들을 q에 추가 q가 빈 큐가 되면, 모든 노드 방문 완료 이진 탐색 트리 (Binary Search Trees) 모든 노드에 대해서 다음의 성질을 만족하는 이진 트리 왼쪽 서브 트리에 있는 데이터는 모두 현재 노드의 값보다 작음 오른쪽 서브 트리에 있는 데이터는 모두 현재 노드의 값보다 큼 정렬된 배열을 이용한 이진 탐색과 비교 장점은 데이터 원소의 추가, 삭제가 용이 단점은 공간 소요가 큼 -&gt; O(logn)의 탐색 복잡도 이진 탐색 트리의 추상적 자료구조 각 노드는 (key, value) 쌍을 가지고 있음 키를 이용해서 검색 가능, 보다 복잡한 데이터 레코드로 확장 가능 insert(key, data): 트리에 주어진 데이터 원소를 추가 remove(key): 특정 원소를 트리에서 삭제 lookup(key): 특정 원소를 검색 inorder(): 키의 순서대로 데이터 원소를 나열 min(), max(): 최소 키, 최대 키를 갖는 원소를 각각 탐색 이진 탐색 트리에서 원소를 삭제 키를 이용하여 노드를 찾음 (찾은 노드의 부모 노드도 알고 있어야 함) 찾은 노드를 제거하고도 이진 탐색 트리 성질을 만족하도록 트리의 구조를 정리 삭제되는 노드가 말단 (Leaf) 노드인 경우 - 그 노드를 없애면 됨 (부모 노드 링크 조정) 삭제되는 노드가 자식을 하나 갖고 있는 경우 - 삭제되는 노드 자리에 그 자식을 대신 배치 삭제되는 노드가 자식을 둘 갖고 있는 경우 - 삭제되는 노드보다 바로 다음 큰 가지는 노드를 찾아 대신 배치 힙 (Heaps) 이진 트리의 한 종류 (이진 힙 - Binary Heap) 루트 노드가 언제나 최댓값 또는 최솟값을 가짐 완전 이진 트리여야 함 이진 탐색 트리와의 비교 원소들은 완전히 크기 순으로 정렬되어 있는가? 특정 키 값을 가지는 원소를 빠르게 검색할 수 있는가? 부가의 제약 조건은 어떤 것인가? 최대 힙의 추상적 자료구조 init(): 빈 최대 힙을 생성 insert(item): 새로운 원소를 삽입 remove(): 최대 원소를 반환 및 이 노드를 삭제 최대 힙에 원소 삽입 트리의 마지막 자리에 새로운 원소를 임시로 저장 부모 노드와 키 값을 비교하여 위로, 위로, 이동 부모 노드와의 대소 비교 최대 횟수는 log2n 최악의 복잡도는 O(logn)의 삽입 연산 최대 힙에 원소 삭제 루트 노드의 제거 -&gt; 이것이 원소들 중 최댓값 트리 마지막 자리 노드를 임시로 루트 노드의 자리에 배치 자식 노드들과의 값 비교와 아래로, 아래로, 이동 원소의 개수가 n인 최대 힙에서 최대 원소 삭제 최대 횟수는 2 * log2n 최악의 복잡도는 O(logn)의 삭제 연산 최대 및 최소 힙의 응용 우선 순위 큐 (Priority queue) enqueue 할 때, 느슨한 정렬을 이루고 있도록 함 - O(logn) dequeue 할 때, 최댓값을 순서대로 추출 - O(logn) 힙 정렬 (Heap sort) 정렬되지 않은 원소들을 아무 순서대로 최대 힘에 삽입 - O(logn) 삽입이 끝나면, 힙이 비게 될 떄까지 하나씩 삭제 - O(logn) 원소들이 삭제된 순서가 원소들의 정렬 순서 정렬 알고리즘의 복잡도: O(nlogn) 4. 파이썬을 무기로, 코딩테스트 광탈을 면하자! (1) 해시 활용 - 완주하지 못한 선수 문제 탐욕법 (Greedy) 활용 - 체육복 문제 정렬 (Sort) 활용 - 가장 큰 수 문제 탐욕법 (Greedy) 활용 - 큰 수 만들기 문제5. 파이썬을 무기로, 코딩테스트 광탈을 면하자! (2) Heap 활용 - 더 맵게 문제 동적계획법 활용 - N으로 표현 문제 DFS/BFS 활용 - 여행경로 문제6. 코딩테스트 풀이 참고 자료 PEP8 스타일 가이드7. 1주차 돌아보기 기간: 2022. 09. 19 ~ 2022. 09. 24퇴사를 앞두며, 다음 스텝을 준비하기 위해 고민하던 중에 프로그래머스 데브코스를 참여하게 됐다. 그리고 그 첫 주가 시작되었고, 잠깐이지만 회사와 병행해야 했던 이번 주는 개인적으로 조금 힘들었던 것 같다. 물론 배우는 내용들은 의미있고, 재밌긴 했지만 아무래도 회사와 함께 시간을 사용해야 되다보니 약간 벅찼던 것 같다.그럼에도 파이썬의 알고리즘과 자료구조를 다시 공부할 수 있는 기회가 되고, 누군가의 코딩테스트 문제 풀이 과정을 복기하며 내 사고를 돌아볼 수 있는 기회를 갖게 된 것 같은 참 뜻깊었던 것 같다. 나 역시 코딩테스트를 오랫동안 준비해봤던 것이 아니라, 부족한 부분들이 많이 있을텐데 이번 기회에 그런 문제점들과 개선해야 하는 부분들을 조금씩 확인할 수 있는 기회가 되었다.다음 주부터는 회사에서는 연차를 사용하면서 퇴사를 앞두고 있는데, 퇴사 후에 나에게 주어진 시간들을 어떻게 써야 할지를 고민하며 이 시간에 대해 더 고민하고, 또 고민해보도록 하자. 출처: 프로그래머스 인공지능 데브코스 4기 1주차 강의 -&gt; 강의 내용 정리 깃허브 링크" }, { "title": "프로그래머스 인공지능 데브코스 4기 합격 후기", "url": "/posts/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-AI-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4/", "categories": "Education, 프로그래머스 인공지능 데브코스 4기", "tags": "AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training", "date": "2022-09-02 21:00:00 +0900", "snippet": "이번 글에서는 프로그래머스 인공지능 데브코스 4기의 합격 후기를 적어보려고 합니다. 해당 프로그램을 처음 보시는 분들이 있을 수도 있기 때문에 간단히 이 프로그램에 대해 소개하고, 지원부터 합격 발표까지 과정은 어떠했는지, 지원서는 어떻게 작성했는지 등에 대해서 나눠보려고 합니다. 또한 이 프로그램을 통해서 개인적으로 기대하는 부분도 함께 말씀드리려고 합니다! 향후 프로그래머스에서 진행하는 데브코스에 관심이 있거나, 이 분야를 준비하시는 분들에게 도움이 되었으면 좋겠습니다.1. 인공지능 데브코스 4기 소개 AI 분야 주니어 개발자가 갖춰야 할 역량은 실존하는 다양한 모델을 그저 쓰는 것에 그치지 않고, 그 구성 요소를 이해하고 상황에 맞게 응용할 수 있는 능력이 필요합니다. -&gt; 학습 내용: 파이썬, 수학, 머신러닝 및 딥러닝, NLP, CV, 추천 시스템, Spark, DB, SQL프로그래머스에서는 내일배움카드 (K-digital training)를 통해 소위 말하는 ‘부트캠프’를 운영하고 있습니다. 이번에 소개하는 인공지능 데브코스 4기 외에도 프론트엔드, 백엔드, 자율주행 분야로 기수 별로 모집하고 있습니다. 이 프로그램에서는 약 5개월 동안 인공지능 모델 뿐 아니라, 프로젝트를 통해 기획부터 웹 배포까지 경험해볼 수 있습니다. 또한 대학 교수님 및 실리콘 벨리의 현직 전문가 등의 강사진으로부터 해당 지식들을 학습할 수 있습니다. 아래의 링크 및 표를 통해 어떠한 내용들을 학습하는지 개괄적으로 확인할 수 있습니다.인공지능 데브코스 커리큘럼 요약-&gt; 자세한 커리큘럼 링크 (노션) 주차 학습 주제 세부 내용 1개월 (1주차) OT, 파이썬 기초 진행방식 및 운영 소개, 파이썬 문법 학습, 알고리즘 및 자료구조 학습 1개월 (2주차) 웹 스크래핑 기초 BeautifulSoup 및 Selenium 학습, Matplot을 통한 시각화 1개월 (3주차) 파이썬으로 데이터 다루기 Numpy 및 Pandas 학습, 데이터프레임 다루기 1개월 (4주차) 파이썬으로 웹 다루기 Flask 및 Django를 통한 웹 서버 학습, AWS를 통한 머신러닝 모델 API 2개월 (1주차) 머신러닝 기초 E2E ML 프로젝트 (데이터 전처리, 모델학습), Probability distributions 2개월 (2주차) 인공지능 개론 및 수학 기계학습 소개, 신경망 및 딥러닝 기초 소개, Kaggle 경진대회 2개월 (3주차) Linear models (회귀, 분류) 선형대수학, Matrix calculus 리뷰 2개월 (4주차) CNN과 RNN 특징 및 논문 리뷰 1 CNN, RNN, Deep learning 최적화 3개월 (1주차) CNN과 RNN 특징 및 논문 리뷰 2 CNN, RNN, Deep learning 최적화, 코드 리뷰 3개월 (2주차) SQL과 실무 DB (Spark) 1 Spark, Spark MLlib, Spark Dataframe 실습 및 소개 3개월 (3주차) SQL과 실무 DB (Spark) 2 Spark, Spark MLlib, Spark Dataframe 실습 및 소개 3개월 (4주차) NLP (Text classification) Text representation, fastText model 4개월 (1주차) Visual recognition Object recognition, Domain/style Transfer, GAN 4개월 (2주차) 추천 시스템 추천 시스템 소개 및 실습 4개월 (3주차) 추천 시스템 및 GAN 추천 시스템 구현, GAN 기반 딥러닝 처리 4개월 (4주차) 강화학습, 중간 프로젝트 발표 강화학습 알고리즘, 중간 프로젝트 기획서 발표 5개월 최종 프로젝트 최종 프로젝트 진행 상황 공유, 멘토링, 발표, 수료식 2. 지원 동기저는 개인적으로 유튜브 EO 채널을 좋아하는데, 이 채널에서 인사이트 가득한 한 분을 뵐 수 있었습니다. 한기용님의 인터뷰에서 지금까지의 삶 속에서 경험하신 것들을 진솔하게 말씀해주신 과정에서 울림이 있었습니다. 삶을 살다보면, 내 선택에 대한 아쉬움과 후회 그리고 감사함과 기쁨 등의 다양한 감정을 느낄 수 있을텐데, 한국과 실리콘 벨리에서의 삶 속에서 경험한 모든 것들을 솔직하게 이야기하고, 조언해주신 것들이 와닿았습니다. 이렇게 인상 깊었던 한기용님을 기억했다가, 이번 인공지능 데브코스 4기에서 강사님으로 계신다는 소식을 들었습니다. 그래서 조금 더 가까이에서 이 분과 교제하고, 배우며, 이야기를 나눠보고 싶은 마음에 지원을 결심하게 되었습니다. 뿐만 아니라, 지금까지 머신러닝 위주로 학습했던 한계를 조금이나마 극복하기 위해서 딥러닝 분야의 지식을 쌓고, 인공지능 모델을 비롯하여 SQL이나 데이터베이스를 비롯해 spark 등의 내용을 학습할 수 있는 것도 좋았습니다. 데이터 엔지니어링 분야 역시 관심을 가졌던 분야이므로, 이러한 내용들을 학습해보고자 합니다.3. 지원서 작성이번 데브코스는 아래와 같은 총 5개의 문항으로 이뤄져 있습니다. 그리고 이 문항들에 대해 제가 어떤 식으로 자기소개서를 작성했는지 소개해보려고 합니다. (1) 어떻게 프로그래밍을 학습했는지, 앞으로 어떻게 학습할 계획인지 소개이 문항에 대해서는 원래 문과생이였던 제가 왜, 어떠한 이유로 프로그래밍을 학습하게 됐는지 그 계기를 설명했습니다. 저는 프로젝트 안에서 기획적인 측면을 담당하며 직접 스스로 무엇인가를 만들며 실현하지 못한다는 아쉬움이 있었습니다. 이러한 한계점을 극복하고자 처음으로 프로그래밍 특히, 데이터 사이언스를 공부하게 되었다고 소개했습니다. 이후, 데이터 분석에서부터 시작해서 데이터 사이언티스트, 백엔드 엔지니어로 가게 된 배경을 설명했습니다. 그리고 언어의 기본적인 문법을 학습한 후에, 다양한 프로젝트를 통해서 더 깊이 있게 해당 분야를 이해할 수 있는 것처럼, 지금까지 해왔던 프로젝트를 통해 성장했었고, 이번 데브코스의 프로젝트를 통해 더 성장할 수 있음을 어필했습니다. 또한 배운 것들을 기록하고, 남기는 것의 중요성을 이야기하면서 이번 데브코스에서 기록하는 습관을 조금 더 기르며, 배웠던 것들을 잘 정리해보고 싶다고 이야기했습니다. 실제 이 블로그를 작성하는 것 역시도 이 내용의 일환입니다!(2) 인공지능 분야로 진출하려고 하는 이유인공지능 분야로 진출하려고 하는 동기에서는 문제 정의의 중요성을 계속해서 강조했습니다. 개인적으로 백엔드 엔지니어로 있을 때 아쉬웠던 점은 기획 과정에 참여하지 않고 요구 사항만을 개발한다는 점이었습니다. 이러한 한계를 극복할 수 있는 데이터 사이언스는, 직접 문제 정의부터 어떻게 문제를 풀어갈지 주체적으로 고민합니다. 결국 기술은 사용자에게 의미 있을 때, 그 기술 역시 가치가 있을 수 있으므로 이러한 문제를 풀고 싶음을 강조했습니다. 최종적으로는, 단순히 코드를 짜는 사람이 되기보다, 우리 사회가 가진 문제를 해결하는 사람이 되고 싶다는 것과 특별히 그 문제를 ‘인공지능’ 이라는 도구를 통해 해결하고 싶다는 것을 어필했습니다.(3) 과거에 인공지능 관련 학습 또는 프로젝트를 했던 경험 소개이 문항에서는 지금까지 했던 프로젝트 중에서 유의미한 성과라고 생각한 세 개 요약하고, 깃헙 링크를 첨부했습니다. 세 가지 프로젝트에 대해 아래와 같이 프로젝트에 대한 타이틀과 얻었던 성과를 적고, 설명을 적었습니다. 단기간에 대회 목표에 맞게 하루 만에 웹 페이지를 개발했던 성과 (광주인공지능사관학교 온라인 해커톤 장려상) 끊임 없이 데이터를 전처리하고, 다루며 데이터와 더욱 가까워 질 수 있었던 성과 (2021 국토 도시 데이터 분석 장려상) 문제 정의와 아이디어 그리고 프로그래밍의 융합으로 얻었던 유의미한 성과 (2020 뉴스빅데이터 해커톤 대상)첫 번째로는, 과거 광주인공지능사관학교에 있을 때, 하루만에 해커톤 주제에 맞게 서비스를 개발하는 것이 과제였고, 이를 통해 실제 문제를 정의하며 배웠던 내용들을 활용해 서비스를 만들어 본 경험이 있음을 강조했습니다. 두 번째로는, LH에서 주관하여 대전시의 교통사고 데이터를 분석하여 위험 지역을 도출하는 과제였습니다. 이 과정에서 교통사고 및 그 외에 다양한 데이터들이 주어지고 수집했는데, 많은 양의 데이터들을 바라 보면서 어떻게 분석할 수 있을지, 어떻게 주어진 문제를 해결할 수 있을지를 팀원들과 같이 고민했던 내용들을 설명했습니다. 마지막으로는, 문화체육관광부에서 주관했던 뉴스 데이터를 활용하여 유의미한 서비스를 만드는 해커톤이었습니다. 이 역시 많은 사람들이 공감할 수 있는 문제를 정의하면서, 이 문제를 기술과 서비스를 통해 풀어갔던 내용들을 스토리텔링 하면서 배운 기술들을 활용해본 경험이 있고, 잘 활용할 수 있음을 강조했던 것 같습니다.(4) 이 프로그램을 통해 특히 더 집중해서 배우고자 하는 분야이 문항에서는 딥러닝과 데이터 엔지니어링 분야를 조금 더 공부해보고 싶음을 강조해서 답을 적었습니다. 빠르게 발전하며 성과를 내고 있는 딥러닝 분야 안에서 다양한 이론들과 모델을 학습해보고 싶음을 강조했습니다. 뿐만 아니라, 데이터 엔지니어링 분야에도 역시 관심이 있었기 때문에 백엔드 엔지니어로 경험을 해봤던 것과 조직 안에서 데이터가 잘 흐르는 조직에 대한 동경심(?) 등을 설명하면서 이 분야를 학습하고 싶다고 적었습니다. 마지막으로는, 그 분야에서 실제 일하고 계시는 현직자 분들의 강의를 통해 데이터 엔지니어링 프로세스는 어떻게 되는지, 가능하다면 그 분야에서 사용되고 있는 kafka, airflow 등의 툴은 어떻게 사용되는지 등에 대해서도 궁금함을 적었습니다.(5) 앞선 질문에서 미처 답하지 못한 나의 장단점 소개마지막 문항에서는 앞선 질문들에 대한 답변들을 최종적으로 요약하면서 스스로가 느끼는 자신의 장단점을 설명했습니다. 그리고 이 프로그램을 통해서 배워서 남주자 라는 제 개인적인 목표와 비전을 성취해가고 싶음을 언급하면서 이번 프로그래머스 인공지능 데브코스 4기가 제게 있어서 아주 큰 기회가 될 수 있음을 강조했습니다.4. 최종 합격자기소개서 작성 후에 코딩 테스트가 있었는데, 공고문 상에서는 프로그래머스 레벨 2~3 정도의 수준으로 안내되었습니다. 코테 준비를 많이 하지는 못했었기 때문에 약 1주일 정도 프로그래머스 사이트 내에서 레벨 1~3 까지의 문제를 풀었습니다. 문제를 풀어보신 분들은 아시겠지만, 프로그래머스 내에서 난이도 1과 2, 3은 많이 차이가 있기 때문에 나름 걱정을 했는데, 생각했던 것만큼은 문제가 많이 어렵게 나오지는 않았기 때문에 잘 해결할 수 있었던 것 같습니다. 저는 총 4문제 중에서 약 3문제 정도를 맞추게 되었고, 최종적으로 합격했다는 메일을 다음과 같이 받을 수 있었습니다. 5. 기대하는 점저는 약 1년 정도 다녔던 핀테크 스타트업을 퇴사하고, 이번 프로그램에 참여하는 것으로 결정했습니다. 회사를 다니면서 여러가지 고민이 많이 있었는데, 이러한 고민들을 조금 내려놓고 개인의 시간을 가지면서 제가 하는 분야에 대한 전문성을 기르고 싶다는 생각을 하게 되었습니다. 지금도 여전히 고민은 진행중이고, 향후 진로에 대해서도 취업과 대학원 진학, 창업 등으로 고민을 많이 하고 있지만, 앞서 이야기 했듯 어느 방향으로 가든 제 분야에 대한 전문성과 실력을 기르고 싶다는 마음이 가장 큰 것 같습니다. 이번 프로그램에서는 아래와 같이 계획과 목표를 세우고 참여해보고 싶습니다. 딥러닝의 주요한 모델들에 대한 기본적인 이론 및 응용력 학습하기 데이터 엔지니어링 분야에 대하여 학습해보고, 해당 분야에 대해 조금 더 구체화 시켜보기 팀원들과 함께하는 프로젝트를 통해 유의미한 성과 내보기 (공모전, 논문, 특허 등) 내 진로, 향후 계획 등에 대해서 조금 더 진지하게 고민할 수 있는 시간 갖기 참여하는 약 40명 정도의 교육생 분들과 이야기 나누고, 교제하며 서로 동기부여 받기" }, { "title": "ISLR 2강. 통계학습", "url": "/posts/ISLR-2%EA%B0%95-%ED%86%B5%EA%B3%84%ED%95%99%EC%8A%B5/", "categories": "Review - IT Book, An Introduction to Statistical Learning", "tags": "AI, ISLR, Deep learning, Machine learning, Statistical learning", "date": "2022-07-24 21:00:00 +0900", "snippet": "2.1 통계학습이란?통계학습을 설명하기 위해서 두 가지 예를 들어보도록 한다. 첫 번째로는, 마케팅 과정에서 TV, 라디오, 신문이라는 세 요소를 통해 특정 제품의 광고를 하려고 한다. 이때, 이 세 매체를 통한 광고 예산은 입력변수(Input)로, 매출은 출력변수(Output)으로 정의할 수 있다. 즉, 세 매체에 대한 광고 예산의 조합을 통해 매출을 예측할 수 있는 모델을 만들어볼 수 있다는 것이다. 두 번째로는, 개인의 교육 기간 데이터와 그에 따른 소득 데이터를 통해서 관계를 확인해보려고 한다. 같은 방식으로 이때의 입력변수(Input)는 교육 기간이고, 출력변수(Output)는 소득으로 정의할 수 있다. 1) 매출 = TV 예산 + 라디오 예산 + 신문 예산 + e (error term) 2) 개인의 소득 = 개인의 교육 기간 + e (error term)이렇듯, 일반적으로 입력(설명, 예측, 독립, feature) 변수는 X로, 출력(반응, 응답, 종속) 변수는 Y를 사용하여 표현한다. 따라서 Y = f(x) + e 라는 수식으로 출력 변수는 입력 변수들의 방정식에 대한 결과값이라고 이야기할 수 있다. 또한 함수 f는 2개 이상의 입력 변수에 표현되며, 통계학습은 이 함수 f를 추정하는 일련의 기법으로 정의할 수 있다.2.1.1 f를 추정하는 이유는?함수 f를 추정하는 두 가지 주요한 이유는 예측과 추론이라고 할 수 있다. 예측: Y 예측값의 정확성은 축소가능 오차 (reducible error)와 축소불가능 오차 (irreducible error)로 정의 축소가능 오차: 아무리 좋은 모델이라도 완벽하게 추정하지 못하지만, 어느 정도까지는 최소화 시킬 수 있는 오차 최대한 좋은 모델을 활용하여 오차를 최소화시켜 함수 f와 f의 예측값을 최대한 줄일 수 있는 값 (오차) 즉, 가장 적절한 통계학습 기법을 통해 f를 추정하여 f의 예측값을 개선할 수 있으므로 이 오차는 축소 가능 축소가능 오차가 0보다 큰 이유는, e는 Y를 예측하는데 유용한 측정되지 않은 변수를 포함할 수 있기 때문 축소불가능 오차: 완벽한 모델로 f를 추정할 수 있다고 하더라도, 예측값은 여전히 e라는 오차 값을 가짐 Y는 e의 함수인데, 설명 변수 X를 통해서는 e를 완벽히 예측할 수 없기 때문 즉, 아무리 좋은 모델도 e와 관련된 변동성을 줄일 수 없기 때문에 이 오차는 축소 불가능 e는 측정할 수 없는 변동성을 포함할 수 있음 추론: 각 개별 변수 (독립변수)가 Output (종속변수)에 어떠한 영향을 미치는지 고려하는 것 여러 매체를 통해 광고를 했을 때, 얻게 되는 최종적인 효과 (매출)에 집중하지 않는 것 즉, 매출에 가장 긍정적인 영향을 미치는 매체는 무엇인지, 각 매체 사이의 상관관계는 어떠한지 등에 대한 것 일반적으로 선형 모델은 비교적 간단하고 해석 가능한 추론을 할 수 있지만, 다른 기법만큼 정확한 예측은 불가능 반대로 높은 성능을 갖는 비선형적인 기법들은 예측의 정확도는 높을 수 있지만, 추론은 어려울 수 있음 2.1.2 어떻게 f를 추정하는가?n개의 다른 데이터 포인트를 관측한다고 할 때, 이 관측치들은 훈련 데이터 (Training data)라고 정의할 수 있다. 단어 그대로 이 데이터들을 훈련시켜서 함수 f를 어떻게 추정할 수 있을지 고려하기 때문이다. 최종적인 목적은 통계 학습 방법을 훈련 데이터에 적용하여 알려지지 않은 함수 f를 추정하는 것이라고 할 수 있다. 이를 위한 대부분의 통계 학습 방법은 모수적 (Parametric) 또는 비모수적 (Non-parametric)으로 구분할 수 있다. 모수적 방법: 함수 f에 대해 선형 함수와 같이 형태나 모양을 가정하여 그에 따라 함수를 추정하는 방법 모델이 선택된 후에는 훈련 데이터를 통해 학습하여 모델을 도출함 하지만 이 방법의 단점은 선택하는 모델이 알려지지 않은 f와 비슷하지 않을 수도 있다는 것 성능이 너무 나오지 않아서 모델을 복잡하게 구성한다면, 일반화 되지 않고 과적합 (Overfitting)의 우려도 존재 비모수적 방법: 함수 f에 대해 명시적인 가정을 하지 않고, 데이터와 가능하면 가까워지는 f를 추정하는 방법 함수의 형태를 따로 정의하지 않으므로, 더 넓은 범위의 f 형태에 정확하게 적합될 수 있음 하지만 f에 대해 정확히 추정하기 위해서는 아주 많은 수의 관측치가 필요할 수 있음 이 방식 역시 앞서 이야기 했던 과적합에 대한 우려가 있으므로, 일반화를 목적으로 모델을 개발해야 함 2.1.3 예측 정확도와 모델 해석력 사이의 절충 (Trade-off) 일반적인 최소제곱 선형 회귀는 비교적 유연하지는 않지만 해석력은 상당히 좋음 추론이 목적일 때는 비교적 단순하고 유연한 통계 학습 방법을 사용하는 것이 좋을 수 있음2.1.4 지도학습과 비지도학습 일반적인 모델링은 반응 변수를 설명 변수에 관련시키는 모델로 추정하는 과정이라고 할 수 있음 즉, 이 목적은 미래 예측에 대해 반응 변수를 정확하게 예측 또는 추론하는 것 (지도학습) 지도학습과 달리 비지도학습은 군집 분석과 같이 보여지는 패턴에 대해 학습하는 것이 아님 지도학습과 비지도학습 사이에서의 준지도학습 (Semi-supervised learning) 이라는 개념도 존재함2.1.5 회귀와 분류 문제 변수는 양적 또는 질적 변수로 구분할 수 있음. 양적 변수는 수치를, 질적 변수는 카테고리 등의 값을 가짐 보통 양적 반응변수를 가지는 문제를 회귀 문제로, 질적 반응변수가 관련된 문제는 분류 문제라고 함 일반적으로 반응변수가 질적 또는 양적인지에 따라서 통계 학습 방법을 선택하는 경향도 존재함 주식 가격을 예측하는 문제는 가격이라는 연속적인 숫자를 예측하기 때문에 회귀 문제로 정의 공부 시간이나 태도에 따라 학점을 예측하는 문제는 A+~F라는 Label로 답을 예측하므로 분류 문제로 정의 2.2 모델의 정확도 평가2.2.1 적합의 품질 측정2.2.2 편향-분산 절충2.2.3 분류 설정2.3 Lab: R에 대한 소개" }, { "title": "ISLR 1강. 도입", "url": "/posts/ISLR-1%EA%B0%95-%EB%8F%84%EC%9E%85/", "categories": "Review - IT Book, An Introduction to Statistical Learning", "tags": "AI, ISLR, Deep learning, Machine learning", "date": "2022-07-19 21:00:00 +0900", "snippet": " 간단한 책 소개 이 책은 머신러닝 분야 속에서 기초가 되는 기초 통계와 활용 기법을 소개하고 있습니다. ‘R’이라는 프로그래밍 언어를 활용하여 모델링과 예측 기법들을 Lab 문제로 확인해 볼 수 있는데, 이 블로그에서는 R 언어 뿐 아니라, 같은 내용을 Python으로도 적용해보는 것을 목표로 기록해보려고 합니다. 인공지능 분야에서도 기초가 되는 머신러닝 내용들을 복습하며, 개념들을 다시 정리할 것입니다. 이 책을 정리한 후에는 머신러닝 및 딥러닝 분야에 대해서도 기록해볼 예정입니다. 번역서: 가볍게 시작하는 통계학습 - R로 실습하는 원서: An Introduction to Statistical Learning with application in R Chapter Title Main Topics 1강 도입 (Introduction) 통계학습 개요 및 역사, 표기법 설명 2강 통계학습 (Statistical Learning) 통계학습 개념, 지도 및 비지도학습, 회귀 및 분류, 모델 평가 3강 선형회귀 (Linear Regression) 단순선형회귀, 다중선형회귀, K-최근접이웃 4강 분류 (Classification) 로지스틱회귀, 선형판별분석, LDA, QDA, KNN 5강 재표본추출 방법 교차검증 (Cross-Validation), 붓스트랩, K-fold 6강 선형모델 선택 및 정규화 Lasso, 차원축소, 주성분회귀 7강 선형성을 넘어서 다항식회귀, 회귀 및 평활 스플라인, 일반화가법모델 8강 트리 기반의 방법 의사결정트리, 배깅, 랜덤포레스트, 부스팅 9강 서포트 벡터 머신 (SVM) 최대 마진 분류기, 서포트 벡터 분류기, 로지스틱 회귀에 대한 상관관계 10강 비지도학습 주성분 분석, 클러스터링 (K-평균, 계층적) 1.1 통계학습의 개요통계학습 (Statistical Learning)은 데이터에 대한 이해를 위한 방대한 도구 집합을 뜻한다. 이러한 도구들은 지도 (Supervised) 학습과 비지도 (Unsupervised) 학습으로 분류될 수 있다. 지도 학습: 하나 이상의 입력 변수를 기반으로 출력 변수를 예측하거나 추정하는 통계적 모델을 만드는 것 비지도 학습: 출력 변수 없이 입력 변수만 있지만 자료의 상관관계와 구조를 파악할 수 있는 것 그렇다면, 통계학습 (Statistical Learning)과 기계학습 (Machine Learning)의 차이는 무엇일까요? 책에서도 경계를 명확히 나누지 않고, 두 분야 사이에 밀접한 연관성도 있지만 호기심을 가지고 조금 찾아 보았습니다. 일반적으로 두 학습 방식들 모두 데이터에 의존적이라는 공통점이 있을 것입니다. 하지만 통계학습은 변수 사이의 관계 등과 같이 rule-based approach 이라는 측면이 있다고 하면, 기계학습은 기계가 데이터를 통해 스스로 학습한다는 측면에서 명시적인 프로그래밍으로 접근하지는 않습니다. 또한 많은 양의 데이터를 통해 학습이 이뤄지는 기계학습은 지도 및 비지도 학습에 조금 더 포커스를 맞춘다고 하면, 비교적 적은 데이터를 다루는 통계학습은 표본이나 모집단, 가설 등과 같은 통계적 개념들로 접근한다고 할 수 있습니다. 결국, 통계학습은 통계학을 기반으로 하여 해석의 영역에 있어서 유의미하게 적용이 될 수 있을 것이고, 반대로 기계학습은 사람의 노력을 최소화 한 상태에서 숨겨진 패턴 등을 발견하는데 유용하게 사용될 수 있을 것입니다. 참고 - Machine Learning VS. Statistical Learning1.2 통계학습의 간단한 역사통계 및 기계학습이라는 용어는 어색할 수 있지만, 이 분야의 기초가 되는 개념들은 오래 전에 개발되었다. 19세기 초반 르장드르와 가우스는 최소제곱법에 대한 논문을 발표하면서, 지금은 선형회귀로 알려진 형태를 구현했다. 양적 데이터에 적용되는 선형회귀를 기반으로 질적 데이터에 적용할 수 있도록 피셔는 1936년 선형판별분석을 제안했다. 1940년대에는 대안적인 방법으로 로지스틱 회귀가 제안되었고, 1970년대 초에는 일반화된 선형모델들이 정의되었다. 1980년대 중반에는 브라이먼, 프리드먼, 올쉔, 스톤이 분류 및 회귀 나무를 도입했고, 해스티와 티브시라니는 1986년에 일반화된 선형모델의 비선형적 확장에 대해 일반화가법모델을 제안했다.1.3 표기법과 간단한 행렬 대수데이터 표본에서 데이터 포인트 수나 관측치 수는 n으로 사용하고, 예측하는데 사용하는 변수들의 수는 p로 사용한다. 일반적으로 i번째 관측치에 대한 j번째 변수의 값은 x_ij로 표현하며, X는 n * p 행렬을 나타낸다. 이를 바탕으로 기본적인 행렬 및 벡터에 대한 개념, 전치 (Transpose), 행렬 연산 등을 다루게 된다.1.4 Lab과 연습문제에 사용된 자료이 책에서는 통계학습 방법들을 마케팅, 금융, 생물학, 그리고 다른 분야에 적용하여 설명한다. Lab과 연습문제에서 사용한 자료 리스트 및 추가적인 자료들은 ISLR 라이브러리에서 참고할 수 있다." } ]
