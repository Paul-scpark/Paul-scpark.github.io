---
title: 프로그래머스 인공지능 데브코스 2주차
date: 2022-09-26 14:00:00 +0900
categories: [프로그래머스 인공지능 데브코스 4기]
tags: [AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training]
description: 프로그래머스 인공지능 데브코스 2주차 강의 기록
toc: true
toc_sticky: true
toc_label: 목차
math: true
mermaid: true

---

## 1. HTTP 요청 주고 받기 - requests

### Jupyter Lab 시작하기

- Interactive한 python 코드 작성 / 공유를 위한 개발 도구
- Jupyterlab을 pip 명령어를 통해서 install
- Code cell (명령 모드), Markdown cell (입력 모드)

```python
### jupyterlab install
pip install jupyterlab

### 마크다운 문법
# 1. Header
# Hello world
## Hello world
### Hello world

# 2. Italic
*Hello world*
_Hello world_

# 3. Bold
**Hello world***
__Hello world__

# 4. Strikethrough (취소선)
~Hello world~

# 5. Unordered List
- Hello
- world

* Hello
* world

# 6. Ordered List
1. Hello
2. world

# 7. Code
`Hello world`

# 8. Code Block
```Hello world```
```

### 인터넷 사용자 간의 약속, HTTP

- 두 컴퓨터를 연결하는 **네트워크 (Network)**의 탄생
- 이 네트워크를 묶어서 **근거리 지역 네트워크 (Local Area Network, LAN)** 탄생
- 범지구적으로 연결된 네트워크인 **인터넷 (Inter Network, Internet)** 탄생
- 인터넷에서 정보를 교환할 수 있는 환경인 **www (World Wide Web)** 탄생
- 즉, 인터넷은 여러 컴퓨터끼리 네트워크를 연결한 것. 웹은 인터넷 상에서 정보를 교환하기 위한 시스템

- 웹에서 정보를 주고 받는 방법
    - 정보를 요청하는 컴퓨터를 **클라이언트 (Client)**, 정보를 제공하는 컴퓨터를 **서버 (Server)**
    - 클라이언트가 서버에게 정보를 요청
    - 요청에 대해서 서버가 작업을 수행
    - 수행한 작업의 결과를 클라이언트에게 응답

- HTTP (Hypertext Transfer Protocol)의 구조
    - 웹 상에서 정보를 주고 받기 위한 약속
    - 클라이언트에서 서버로 정보를 요청하는 것을 **HTTP 요청 (Request)**
    - 요청된 정보에 대해 서버가 클라이언트에게 응답하는 것을 **HTTP 응답 (Response)**

- HTTP로 정보 요청하기
    - GET / HTTP 1.1
    - HOST: www.programmers.com
    - User-Agent: Mozilla/5.0
    - HTTP / 1.1 200 OK

### 웹페이지와 HTML

- 웹 속에 있는 문서 하나는 **웹 페이지**, 웹 페이지의 모음은 **웹 사이트**
- 웹 브라우저는 HTML 요청을 보내고, HTTP 응답에 담긴 HTML 문서를 보기 쉬운 형태로 화면을 그려주는 역할
- 웹 페이지는 HTML 이라는 형식으로 되어 있고, 웹 브라우저는 HTTP 요청을 보내고, 응답받은 HTML 코드를 렌더링

- HTML (HyperText Markup Language) 구조
    - HTML 코드는 Head (문서의 정보 - 제목, 언어 등)와 Body (문서의 내용 - 글, 이미지, 동영상 등)로 나뉨
    - HTML은 여러 태그(Tag)로 감싼 요소(Element)의 집합으로 이뤄짐
    - 태그로 묶어서 글의 형식을 지정할 수 있음
    - 태그는 그에 맞는 속성 (attribute)을 갖을 수도 있음

### 나의 첫 HTTP 통신 코드

- `requests`는 python을 이용해서 간단히 HTTP 통신을 진행할 수 있는 라이브러리
- 정보를 달라고 요청하기, GET
- 정보를 갱신하는 것을 요청하기, POST

```python
### requests install
pip install requests
```
### 윤리적으로 웹 스크래핑, 크롤링 진행하기

- 웹 크롤링, 웹 스크래핑의 차이는?
    - 웹 크롤링은 크롤러 (Crawler)를 이용해서 웹 페이지의 **정보를 인덱싱**하는 것에 초점
    - 웹 스크래핑은 웹 페이지들로부터 우리가 **원하는 정보를 추출**하는 것에 초점

- 올바르게 HTTP 요청하기
    - 웹 크롤링, 웹 스크래핑을 통해 어떤 목적을 달성하고자 하는가? (저작권 이슈)
    - 내 웹 크롤링, 웹 스크래핑이 서버에 영향을 미치지는 않는가?
    - 로봇 배제 프로토콜 (Robots Exclusion Standard, REP): 크롤러들은 이 규칙을 지키면서 크롤링을 진행
    - `robots.txt`를 가져오는 방법은 웹 페이지 주소에 `/robots.txt`를 붙이면 됨
        - `www.naver.com/robots.txt`
        - `www.programmers.com/robots.txt`

## 2. 똑똑한 HTML 분석기 - BeautifulSoup4

### 웹 브라우저가 HTML을 다루는 방법
- Document Object Model (DOM)
    - 문서를 렌더링하는 가장 최초의 단계
    - 브라우저의 렌더링 엔진은 웹 문서를 로드한 후에 **파싱**을 진행

- DOM의 목적
    - DOM: Document, html, head, body, style, ul, li ...
    - 각 노드를 객체로 생각하면 문서를 더욱 편리하게 관리할 수 있음
    - DOM Tree를 순회해서 특정 원소를 추가할 수 있음 / 찾을 수 있음

- 브라우저는 왜 HTML을 DOM으로 바꿀까?
    - 원하는 요소를 동적으로 변경해줄 수 있음
    - 원하는 요소를 쉽게 찾을 수 있음
    - 브라우저는 HTML을 파싱해서 DOM을 생성하므로, 이를 바탕으로 요소를 찾을 수 있음
    - 따라서 파이썬으로 HTML을 분석하는 HTML Parser가 필요함!

### HTML을 분석해주는 BeautifulSoup
- [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- 크롬 브라우저의 개발자 도구를 이용하면, HTML 코드를 확인할 수 있음

### HTML의 Locator로 원하는 요소 찾기
- `tagname`: 태그의 이름
- `id`: 하나의 고유 태그를 가리키는 라벨
- `class`: 여러 태그를 묶는 라벨

## 3. 웹 브라우저 자동화 - Selenium

### 동적 웹 페이지와의 만남

- 정적 웹 사이트와 동적 웹 사이트
    - HTML 내용이 고정된 정적 (Static) 웹 사이트
    - HTML 내용이 변하는 동적 (Dynamic) 웹 사이트 - 인스타그램 등
    - 정적 웹 사이트는 HTML 문서가 완전하게 응답됨
    - 동적 웹 사이트는 응답 후 HTML이 렌더링 될 때까지 **지연시간**이 존재
    - 웹 브라우저에서는 **자바스크립트**라는 프로그래밍 언어가 동작하며, `비동기 처리`로 필요한 데이터를 채움
    - `동기 처리`: 요청에 따른 응답을 기다리는 것 -> 렌더링이 마무리 되어야만 데이터 처리가 됨
    - `비동기 처리`: 요청에 따른 응답을 기다리지 않음 -> 렌더링과 데이터 처리가 같이 이뤄지게 됨
    - 따라서 비동기 처리가 된 경우에, 상황에 따라 **데이터가 완전하지 않는 경우**가 발생할 수 있음

- 웹 브라우저와 파이썬의 만남
    - 웹 브라우저를 자동화하는 라이브러리 `Selenium`
    - 응답 후 **시간**을 지연시킬 수 있음
    - UI와 **상호작용**이 가능함

- 동적 웹 사이트는 응답 후 바로 정보를 추출하기 어려움
- 다양한 키보드 입력과 마우스 클릭 등의 상호작용이 필요함
- 이를 해결하기 위해 웹 브라우저를 Selenium을 이용하여 파이썬으로 조작하는 전략을 취함

### 브라우저를 자동화하기, Selenium

- Selenium은 파이썬을 이용하여 웹 브라우저를 조작할 수 있는 자동화 프레임워크

### Wait and Call

- Selenium은 동적 웹 사이트에 대한 지원을 진행하기 위해 명시적 (Explicit) / 암묵적 (Implicit) 기다림이 있음
- 명시적 기다림 (Explicit wait): 다 로딩이 될 때까지 지정한 시간 동안 기다리기 (다 로딩이 될 때까지 5초 동안 기다려)
- 암묵적 기다림 (Implicit wait): 특정 요소에 대한 제약을 통한 기다리기 (이 태그를 가져올 수 있을떄까지 기다려)

### 마우스 및 키보드 이벤트 처리하기

- [Selenium Documentation](https://www.selenium.dev/documentation/)

## 4. 시각화로 결과 요약하기 - Seaborn

### 시각화 라이브러리, Seaborn

- scraping의 결과가 너무 분산되어 있으므로, **시각화**로 표현해보도록 함!
- matplotlib을 기반으로 하는 시각화 패키지, Seaborn
- 다양한 그래프를 고수준에서 쉽게 그릴 수 있음

### 뭉게뭉게 단어구름, Wordcloud

- 자연어 문장에서 키워드를 추출하여 해당 키워드의 빈도 수를 측정
- 앞에서 전처리한 정보와 Wordcloud 라이브러리를 바탕으로 워드클라우드 생성

## 5. 인공지능 수학

### 선형시스템 (Linear system)

- 선형시스템의 표현: Ax = b, 연립일차방정식의 대수적 표현
- 선형대수 (Linear algebra)의 목표
    - 어떤 연립일차방정식 즉, 선형 시스템 문제라도 정형적인 방법으로 표현하고 해결하는 방법을 배우는 것
- 선형시스템의 구성 요소: 선형방정식 (Linear equations)
    - 선형시스템은 3개의 방정식으로 구성
    - 선형시스템은 우리가 알아내려는 3개의 미지수 (unknown, variable) x, y, z를 가지고 있음
    - 즉, 3개의 Linear equations과 3개의 variables로 구성된 연립일차방정식은 다음과 같이 표현
    - __3 * 3 linear system__ = 식의 개수 * 미지수의 개수 linear system
        - 3x + y + z = 4
        - x - 2y - z = 1
        - x + y + z = 2
- m * n 선형시스템의 대수적 표현 (Ax = b 형태)
    - 선형시스템의 unknowns (미지수)를 모아서 column vector (열 벡터) x 로 표현
    - 선형시스템의 선형방정식에 대해 다음을 수행
        - coefficients (계수)를 모아서 A의 row vector (행 벡터)로 표현
        - constant (상수)를 모아서 b에 표현
    - 식은 행이고, 행은 식 (linear equations <-> row)
    - m은 linear equation (선형방정식)의 개수, n은 unknown (미지수)의 개수
    - A는 m * n 행렬, x는 n 벡터, b는 m 벡터

### 가우스 소거법

- 선형시스템의 해
    - a의 역수 (inverse)가 존재하지 않는 경우, a가 특이 (singular)하다고 함
    - 해가 있으면 선형시스템이 consistent 하다고 정의
    - 해가 없으면 선형시스템이 inconsistent 하다고 정의
        - 해가 하나인 경우: 3x = 6
        - 해가 없는 경우: 0x = 6
        - 해가 여러 개인 경우: 0x = 0
- 가우스 소거법 (Gauss elimination)
    - 가우스 소거법은 임의의 m * n 선형시스템의 해를 구하는 가장 대표적인 방식
    - 가우스 소거법은 다음의 두 단계로 수행됨
        - 전방 소거법 (Forward elimination): 주어진 선형시스템을 아래로 갈수록 더 단순한 형태로 변형
        - 후방 대임법 (Back-substitution): 아래에서부터 위로 미지수를 실제값으로 대체
- 소거법에 쓰이는 기본행연산 (Elementary Row Operations, EROs)
    - Replace (치환): j번째 행을 기준 행인 i번째 행을 m배 하여 빼서 업데이트
    - Interchange (교환): j번째 행과 i번째 행의 위치를 서로 바꿈
    - Scaling (스케일링): j번째 행을 s배 스케일링
- 전방 소거법의 가치
    - 주어진 선형시스템을 가장 풀기 쉬운 꼴로 변형
    - 주어진 선형시스템의 rank를 알려줌
    - 선형시스템이 해가 있는지 (consistent) 또는 없는지 (inconsistent) 알려줌

### LU 분해

- 행렬분해 (Matrix decomposition)
    - LU 분해 (LU decomposition): 가우스 소거법의 전방소거법을 행렬로 코드화 한 것
        - L: Lower triangular matrix (하삼각행렬)
            - 행렬 A를 전방 소거하는데 쓰인 replacement와 scaling에 대한 EROs를 기록해 둔 행렬
        - U: Upper triangular matrix (상삼각행렬)
            - 행렬 A를 전방 소거한 후 남은 upper triangular matrix (상삼각행렬)
        - P: 행렬 A를 전방 소거하는데 쓰인 interchange에 대한 EROs를 기록해둔 행렬 (옵션)
        - Ax = b => (LU)x = b => L (Ux) = b => Ly = b (단, Ux = y)
        - Forward-substitution (전방 대치법)으로 y 구하기
        - Back-substitution (후방 대치법)으로 x 구하기
        - LU 분해가 가우스 소거법의 전방 소거법과 거의 같다고 할 수 있음
    - QR 분해 (QR decomposition)
    - 특이값 분해 (Singular Value Decomposition, SVD)
- LU 분해를 활용하는 이유
    - 수치적 안정성: 선형시스템의 해를 역행렬을 통해 구하는 것보다 PLU 분해를 이용하는 것이 수치적으로 안정적
    - b가 자주 업데이트 되는 경우: 행렬 A를 미리 PLU로 분해해두면, b가 업데이트 될때마다 x를 바로 계산 가능

<br/>

---

## 6. 2주차 돌아보기

<br/>
<br/>

> 출처: 프로그래머스 인공지능 데브코스 4기 2주차 강의 -> [강의 내용 정리 깃허브 링크](https://github.com/Paul-scpark/AI-dev-course/tree/main/2%EC%A3%BC%EC%B0%A8)