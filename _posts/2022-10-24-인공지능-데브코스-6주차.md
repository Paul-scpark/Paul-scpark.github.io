---
title: 프로그래머스 인공지능 데브코스 6주차 정리 및 후기
date: 2022-10-24 00:00:00 +0900
categories: [Education, 프로그래머스 인공지능 데브코스 4기]
tags: [AI, Deep learning, Machine learning, 프로그래머스, 인공지능 데브코스, K-digital training]
description: 프로그래머스 인공지능 데브코스 6주차 강의 기록
toc: true
toc_sticky: true
toc_label: 목차
math: true
mermaid: true

---

이번 글에서는 프로그래머스 인공지능 데브코스의 6주차 강의에 대한 정리입니다. <br/>

---

## 1. 인공지능과 기계학습 소개

- 일상 속 인공지능
  - 음성인식 (Siri), 추천 시스템 (Netfilx), 자율주행
  - 실시간 객체 인식 (Face ID), 로봇, 번역 (papago)
- 데이터 기반의 접근
- 기술에 집중하기 보다는, 인간 중심의 소통이 중요
- 인공지능 == 도구
  - 도구를 만드는 방법을 배우는 것도 중요하지만, 도구를 사용하는 방법도 배워야 함

<br/>

<figure>
    <img src="https://itwiki.kr/images/0/0e/ABriefHistoryofAI.png">
    <figcaption align="center">출처: https://itwiki.kr/w/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5</figcaption>
</figure>

<br/>

- 기계도 학습이 가능한가? 경험을 통해 점진적으로 성능이 향상되는 기계를 만들 수 있다!
- 인공지능: 인간의 학습, 추론, 지각, 자연언어 이해 등의 지능적 능력을 기기로 실현한 기술
- 학습: 경험의 결과로 나타나는, 비교적 지속적인 행동의 변화나 그 잠재력의 변화 또는 지식을 습득하는 과정
- 경험 E를 통해, 주어진 작업 T에 대한, 성능 P의 향상 (E * T = P)
- 인공지능의 주도권 전환
  - 지식 기반 -> 기계 학습 -> 심층 학습 (표현 학습, Deep learning, Representation learning)
  - 데이터 중심 접근 방식으로 전환
- 예측은 회귀 (Regression) 문제와 분류 (Classification) 문제로 나뉨
  - 회귀는 목표치가 실수, 분류는 종류의 값

### 기계 학습 개념
- 훈련집합 (Training set)
- 가설: 눈대중으로 데이터 양상이 직선 형태를 보임 -> 모델을 직선으로 선택 가정
- 기계 학습의 훈련 (Train)
  - 주어진 문제인 예측을 정확하게 할 수 있는 최적의 매개변수를 찾는 과정
  - 처음에는 임의의 매개변수로 시작하지만, 개선하여 정량적인 최적 성능 (Performance)에 도달
- 훈련을 마치면, 추론 (Inference)을 수행
  - 새로운 특징에 대응되는 목표치의 예측에 사용
- 기계 학습의 궁극적인 목표
  - 훈련집합에 없는 새로운 데이터에 대한 오류를 최소화 (새로운 데이터 = 테스트 집합)
  - 테스트 집합에 대한 높은 성능을 일반화 (Generalization) 능력이라 부름
- 기계 학습의 필수 요소
  - 학습할 수 있는 데이터가 있어야 함
  - 데이터 규칙이 존재해야 함
  - 수학적으로 설명이 불가능
- 차원의 저주 (Curse of Dimensionality): 차원이 높아짐에 따라 발생하는 현실적인 문제들
- 기술 추세
  - 기계 학습 알고리즘과 응용의 다양화
  - 표현 학습이 중요해짐
  - 심층 학습이 기계 학습의 주류
  - 심층 학습은 현대 인공지능 실현에 핵심 기술
- 인공지능의 단계: 초인공지능, 강인공지능, 약인공지능

### 데이터에 대한 이해
- 데이터 수집 -> 모델 정립 (가설) -> 예측
- 기계 학습: 데이터를 설명할 수 있는 학습 모델을 찾아내는 과정
- 주어진 과업에 적합한 다양한 데이터를 충분한 양만큼 수집 => 과업 성능 향상

### 간단한 기계 학습의 예
- 목적 함수 (비용 함수, Objective function, Cost function)
- 과업을 달성하기 위해 모델의 성능이 개선되는지 객관적으로 확인할 수 있는 지표
- 비용 함수의 예 중 하나는 평균제곱오차 (Mean Squared Error, MSE)
- 비용 함수를 최소화 시킬 수 있는 파라미터를 찾는 것이 목표
- 조금 더 현실적인 상황: 실제 세계는 선형 데이터가 아니고 잡음이 섞임 (비선형 모델이 필요)

### 모델 선택
- 과소적합 (Underfitting): 모델의 용량 (자유도)이 작아서 오차가 클 수 밖에 없는 현상
  - 과소적합을 극복하기 위해서는 더 많은 데이터를 사용하거나, 비선형 모델을 사용하라
- 과잉적합 (Overfitting): 고차원으로 근사한다면, 훈련 집합에 대해 거의 완벽하게 추정 가능
  - 하지만 새로운 데이터를 예측하는 경우에는 문제가 발생할 수 있음
  - 모델의 용량이 크기 때문에 학습 과정에서 잡음까지도 학습해버림
- 따라서 적절한 용량의 모델을 선택하는 모델 선택 작업이 필요함

- 편향 (Bias)과 분산 (변동, Variance) => trade-off 관계
  - 훈련집합을 여러 번 수집하여 1~12차에 반복해서 적용하는 실험
  - 저차원에서는 오차가 크고, 편향도 큼. 하지만 비슷한 모델을 얻음 (낮은 변동)
  - 고차원에서는 오차가 작고, 편향도 작음. 하지만 크게 다른 모델을 얻음 (높은 변동)
  - 용량이 작은 모델 (과소적합)은 편향이 크고, 분산이 작음
  - 용량이 복잡한 모델 (과대적합)은 편향이 작고, 분산이 큼
- 기계 학습의 궁극적인 목표
  - 낮은 편향과 낮은 분산을 가진 예측 모델을 만드는 것이 목표
  - 하지만 모델의 편향과 분산은 상충 관계
  - 따라서 편향을 최소로 유지하며, 분산도를 최대로 낮추는 전략이 필요함
  - 모델의 용량이 증가한다는 것은 편향이 감소하고, 분산이 증가하는 경향이 있음
- 검증집합을 이용한 모델 선택
  - 훈련집합과 테스트집합과 다른 별도의 검증집합 (Validation set)을 가진 상황
- 부트스트랩 (Bootstrap)
  - 임의의 복원 추출 샘플링 (Sampling with replacement) 반복
  - 데이터 분포가 불균형 일 때 사용
- 현대 기계 학습의 전략
  - 용량이 충분히 큰 모델을 선택한 후에,
  - 선택한 모델이 정상을 벗어나지 않도록 여러 규제 (Regularization) 기법을 적용
    - 데이터 확대: 데이터를 많이 수집할수록 일반화 능력이 향상됨
    - 가중치 감쇠: 개선된 목적함수를 이용하여 가중치를 작게 조절하는 규제 기법

### 지도 방식에 따른 유형
- 지도 학습 (Supervised Learning)
  - 특징 벡터와 목표치 (정답)가 모두 주어진 상황
  - 회귀와 분류 문제로 구분
- 비지도 학습 (Unsupervised Learning)
  - 특징 벡터는 주어지는데, 목표치가 주어지지 않는 상황 (정답이 없음)
  - 군집화 (Clustering), 밀도 추정 (Density estimation), 특징 공간 변환 (PCA) 과업 
- 강화 학습 (Reinforcement Learning)
  - 상대적인 목표치가 주어지는데, 지도 학습과 다른 형태 (보상)
- 준지도 학습 (Semi-supervised Learning)
  - 일부는 특징 벡터와 목표치를 모두 가지지만, 나머지는 특징 벡터만 가지는 상황
  - 최근, 대부분의 데이터가 특징 벡터 수집은 쉽지만, 목표치는 수작업이 필요하여 최근 중요성 부각

### 다양한 기준에 따른 유형
- 오프라인 학습과 온라인 학습 (Offline, Online Learning)
  - 보통은 오프라인 학습을 다룸
  - 온라인 학습은 IoT 등에서 추가로 발생하는 데이터 샘플을 가지고 점증적 학습 수행
- 결정론적 학습과 확률적 학습 (Deterministic, Stochastic Learning)
  - 결정론적에서는 같은 데이터를 가지고 다시 학습하면 같은 예측 모델이 만들어짐
  - 확률적 학습은 학습 과정에서 확률 분포를 사용하므로, 같은 데이터로 학습하면 다른 예측 모델이 나옴
- 분별 모델과 생성 모델 (Discriminative, Generative Models)
  - 분별 모델은 부류 예측에만 관심. 즉, `P(y|x)`의 추정에 관심
  - 생성 모델은 P(x) 또는 `P(x|y)`를 추정하여 새로운 샘플을 생성하여 사용할 수 있음

## 2. 기계학습과 수학 리뷰

## 3. ML Basics - E2E

## 4. ML Basics - Linear Algebra

## 5. 6주차 실습

---

## 4. 6주차 돌아보기

- 기간: 2022. 10. 24 ~ 2022. 10. 29



<br/>
<br/>

> 출처: 프로그래머스 인공지능 데브코스 4기 6주차 강의 -> [강의 내용 정리 깃허브 링크](https://github.com/Paul-scpark/AI-dev-course/tree/main/6%EC%A3%BC%EC%B0%A8)
