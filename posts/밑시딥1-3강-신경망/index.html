<!DOCTYPE html><html lang="ko" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="밑시딥1 3강. 신경망" /><meta property="og:locale" content="ko" /><meta name="description" content="밑시딥1 3강 내용 정리" /><meta property="og:description" content="밑시딥1 3강 내용 정리" /><link rel="canonical" href="https://paul-scpark.github.io/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-3%EA%B0%95-%EC%8B%A0%EA%B2%BD%EB%A7%9D/" /><meta property="og:url" content="https://paul-scpark.github.io/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-3%EA%B0%95-%EC%8B%A0%EA%B2%BD%EB%A7%9D/" /><meta property="og:site_name" content="Paul’s Insights" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-10-06T22:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="밑시딥1 3강. 신경망" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-10-13T01:46:12+09:00","datePublished":"2022-10-06T22:00:00+09:00","description":"밑시딥1 3강 내용 정리","headline":"밑시딥1 3강. 신경망","mainEntityOfPage":{"@type":"WebPage","@id":"https://paul-scpark.github.io/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-3%EA%B0%95-%EC%8B%A0%EA%B2%BD%EB%A7%9D/"},"url":"https://paul-scpark.github.io/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-3%EA%B0%95-%EC%8B%A0%EA%B2%BD%EB%A7%9D/"}</script><title>밑시딥1 3강. 신경망 | Paul's Insights</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Paul's Insights"><meta name="application-name" content="Paul's Insights"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/main_image.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Paul's Insights</a></div><div class="site-subtitle font-italic">Space to learn, to record experiences.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/Paul-scpark" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://www.linkedin.com/in/%EC%84%B1%EC%B0%AC-%EB%B0%95-35a84b219/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['solver.paul','google.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>밑시딥1 3강. 신경망</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>밑시딥1 3강. 신경망</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1665061200" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Oct 6, 2022 </em> </span> <span> Updated <em class="" data-ts="1665593172" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Oct 13, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/Paul-scpark">Seongchan Park</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="5422 words"> <em>30 min</em> read</span></div></div></div><div class="post-content"><p>이번 글에서는 밑바닥부터 시작하는 딥러닝1 책의 3강에 대한 리뷰를 시작합니다. <br /> 앞서 딥러닝의 기초 개념인 퍼셉트론을 학습했는데, 이어서 딥러닝의 중요한 개념인 신경망에 대해 학습합니다. <br /> 퍼셉트론과 달리 신경망이 어떻게 동작하는지, 그리고 활성화 함수는 무엇인지 등에 대해서도 배울 예정입니다. <br /> 마지막으로는, 손글씨 숫자 이미지 데이터로 유명한 MNIST 데이터를 활용하여 결과도 확인해봅니다.</p><hr /><div class="table-wrapper"><table><thead><tr><th style="text-align: center">Chapter<th style="text-align: center">Title<th style="text-align: center">Main Topics<tbody><tr><td style="text-align: center">1강<td style="text-align: center">헬로 파이썬<td style="text-align: center">파이썬 기초 문법 소개, numpy, matplotlib<tr><td style="text-align: center">2강<td style="text-align: center">퍼셉트론<td style="text-align: center">AND, NAND, OR 게이트<tr><td style="text-align: center"><span style="color:red">3강</span><td style="text-align: center"><span style="color:red">신경망</span><td style="text-align: center"><span style="color:red">활성화 함수, 다차원 배열 계산, 출력층 설계, MNIST</span><tr><td style="text-align: center">4강<td style="text-align: center">신경망 학습<td style="text-align: center">손실 함수, 경사 하강법<tr><td style="text-align: center">5강<td style="text-align: center">오차역전파법<td style="text-align: center">역전파, 활성화 함수 구현<tr><td style="text-align: center">6강<td style="text-align: center">학습 관련 기술들<td style="text-align: center">매개변수 갱신, 배치 정규화, 하이퍼파라미터 값 찾기<tr><td style="text-align: center">7강<td style="text-align: center">합성곱 신경망 (CNN)<td style="text-align: center">합성곱 계층, 풀링 계층, CNN 구현<tr><td style="text-align: center">8강<td style="text-align: center">딥러닝 (Deep learning)<td style="text-align: center">초기 역사, 딥러닝 활용<tr><td style="text-align: center">Appendix<td style="text-align: center">Softmax with loss 계층의 계산 그래프<td style="text-align: center">-</table></div><ul><li><a href="http://www.yes24.com/Product/Goods/34970929">밑바닥부터 시작하는 딥러닝 1</a><li><a href="https://github.com/WegraLee/deep-learning-from-scratch">밑바닥부터 시작하는 딥러닝 1 Github 링크</a></ul><p><br /></p><blockquote><p>참고 - 다크 모드가 아닌 화이트 모드로 보시면 자료를 편하게 확인 가능합니다!</p></blockquote><hr /><h2 id="chapter-3-신경망"><span class="mr-2"><font color="orange">Chapter 3. 신경망</font></span><a href="#chapter-3-신경망" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="31-퍼셉트론에서-신경망으로"><span class="mr-2">3.1 퍼셉트론에서 신경망으로</span><a href="#31-퍼셉트론에서-신경망으로" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>(Multi-layer) 퍼셉트론으로 복잡한 함수를 표현할 수 있음<li>But, 가중치를 설정하는 작업은 여전히 사람이 해야 함<li>So, 매개변수의 적절한 값을 데이터로부터 자동으로 학습할 수 있도록 하는 것이 <strong>신경망</strong>의 특징</ul><h4 id="311-신경망의-예"><span class="mr-2">3.1.1 신경망의 예</span><a href="#311-신경망의-예" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 300 300'%3E%3C/svg%3E" data-src="https://sean-parkk.github.io/assets/images/DLscratch/3/Untitled.png" width="300" height="300" data-proofer-ignore></p><p><br /></p><ul><li>신경망은 <strong>입력층 (0층), 은닉층 (1층), 출력층 (2층)</strong>으로 구성됨<li>여기서 은닉층의 뉴런은 (입력층과 출력층과 달리) 사람 눈에 보이지 않음</ul><h4 id="312-퍼셉트론-복습"><span class="mr-2">3.1.2 퍼셉트론 복습</span><a href="#312-퍼셉트론-복습" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><div class="table-wrapper"><table><thead><tr><th style="text-align: center">일반적인 퍼셉트론<th style="text-align: center">편향을 명시한 퍼셉트론<tbody><tr><td style="text-align: center"><img data-src="https://sean-parkk.github.io/assets/images/DLscratch/3/Untitled%201.png" alt="" data-proofer-ignore><td style="text-align: center"><img data-src="https://sean-parkk.github.io/assets/images/DLscratch/3/Untitled%202.png" alt="" data-proofer-ignore></table></div><p><br /></p>\[y = \left\{ \begin{array}\\ 0 &amp; (b + w_1x_1 + w_2x_2 &lt;= 0) \\ 1 &amp; (b + w_1x_1 + w_2x_2 &gt; 0) \\ \end{array} \right.\]<p><br /></p><ul><li>$b$는 <strong>편향</strong>을 뜻하며, 뉴런이 얼마나 쉽게 활성화 되는지를 제어<li>$w_1, w_2$는 각 신호의 <strong>가중치</strong>를 뜻하며, 각 신호의 영향력을 제어<li>&lt;편향을 명시한 퍼셉트론&gt; 그림에서는 $x_1, x_2, 1$에 각 신호의 가중치를 곱한 후, 다음 뉴런에 전달<li>다음 뉴런에서는 이 신호들의 값을 더해서 활성화 될지 여부를 결정 <br /><li>이때, 조건 분기의 동작 (0 이상이면 1 출력, 그렇지 않으면 0 출력)을 다음과 같이 $h(x)$로 정의<li>입력 신호의 총합이 $h(x)$ 함수를 거쳐서 변환되어, 그 값이 y의 출력됨</ul><p><br /></p>\[y = h(b + w_1x_1 + w_2x_2)\] \[h(x) = \left\{ \begin{array}\\ 0 &amp; (x &lt;= 0) \\ 1 &amp; (x &gt; 0) \\ \end{array} \right.\]<h4 id="313-활성화-함수의-등장"><span class="mr-2">3.1.3 활성화 함수의 등장</span><a href="#313-활성화-함수의-등장" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>위의 $h(x)$ 함수처럼 입력 신호의 총합을 출력 신호로 변환하는 함수를 <strong>활성화 (Activation) 함수</strong> 라고 정의<li>위에서 정의한 식을 조금 풀어서 적으면 다음과 같이 표현 가능<li>이 식에서 $a$는 가중치가 달린 입력 신호와 편향의 총합을 계산 한 값<li>즉, 가중치 신호를 조합한 결과가 a라는 노드가 되고, $h(x)$를 통과하여 y라는 노드로 변환</ul><p><br /></p>\[a = b + w_1x_1 + w_2x_2\] \[y = h(a)\]<p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 300 300'%3E%3C/svg%3E" data-src="https://velog.velcdn.com/post-images%2Fdscwinterstudy%2Fd1593000-38e9-11ea-b942-cb9b82d31200%2F%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98%EC%9D%98-%EC%B2%98%EB%A6%AC-%EA%B3%BC%EC%A0%95.PNG" width="300" height="300" data-proofer-ignore></p><h3 id="32-활성화-함수"><span class="mr-2">3.2 활성화 함수</span><a href="#32-활성화-함수" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>위에서 이야기 했던 $h(x)$ 함수는 임계값을 경계로 출력이 바뀌는데, 이를 <strong>계단 (Step) 함수</strong>라고 정의<li>따라서 퍼셉트론에서는 활성화 함수로 계단 함수를 이용<li>물론 신경망에서는 계단 함수 외에 다른 함수를 사용하고 있음</ul><h4 id="321-시그모이드-sigmoid-함수"><span class="mr-2">3.2.1 시그모이드 (Sigmoid) 함수</span><a href="#321-시그모이드-sigmoid-함수" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><br /></p>\[h(x) = \frac{1}{1 + exp(-x)} = \frac{1}{1 + e^{-x}}\]<p><br /></p><ul><li>신경망에서는 활성화 함수로 시그모이드 함수를 이용하여 신호를 변환하고, 변환된 신호를 다음 뉴런에 전달<li>퍼셉트론과 신경망의 주된 차이는 활성화 함수라고 할 수 있음</ul><h4 id="322-계단-함수-구현하기"><span class="mr-2">3.2.2 계단 함수 구현하기</span><a href="#322-계단-함수-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>계단 함수는 입력이 0을 넘으면 1을 출력하고, 그 외에는 0을 출력하는 함수</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">step_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">array_step_func</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">arr</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">int</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">step_func</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>    <span class="c1"># 1
</span><span class="nf">print</span><span class="p">(</span><span class="nf">step_func</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>   <span class="c1"># 0
</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">array_step_func</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])))</span>   <span class="c1"># [1 1]
</span><span class="nf">print</span><span class="p">(</span><span class="nf">array_step_func</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])))</span>  <span class="c1"># [1 0]
</span></pre></table></code></div></div><h4 id="323-계단-함수의-그래프"><span class="mr-2">3.2.3 계단 함수의 그래프</span><a href="#323-계단-함수의-그래프" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>아래 그림에서 볼 수 있듯, 계단 함수는 0을 경계로 출력이 0에서 1로 또는 1에서 0으로 바뀜</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">array_step_func</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="s">"Step Function graph"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><p align="left"> <img data-src="../../assets/img/post_img/221006_1.png" data-proofer-ignore></p><h4 id="324-시그모이드-함수-구현하기"><span class="mr-2">3.2.4 시그모이드 함수 구현하기</span><a href="#324-시그모이드-함수-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># array([0.26894142, 0.73105858, 0.88079708])
</span></pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="c1"># 브로드캐스트 적용
</span><span class="nf">print</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">t</span><span class="p">)</span> <span class="c1"># [2 3 4]
</span><span class="nf">print</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">t</span><span class="p">)</span> <span class="c1"># [1.  0.5  0.33333333]
</span></pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="s">"Sigmoid Function graph"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><p align="left"> <img data-src="../../assets/img/post_img/221006_2.png" data-proofer-ignore></p><h4 id="325-시그모이드-함수와-계단-함수-비교"><span class="mr-2">3.2.5 시그모이드 함수와 계단 함수 비교</span><a href="#325-시그모이드-함수와-계단-함수-비교" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ol><li>[차이점] <strong>매끄러움</strong><ul><li>이 매끄러움이 신경망 학습에서 매우 중요한 역할을 하게 될 것<li>시그모이드 함수는 부드러운 곡선이며, 입력에 따라서 출력이 연속적으로 변화<li>한편, 계단 함수는 0을 경계로 출력이 갑자기 바뀜</ul><li>[차이점] <strong>출력값의 범위</strong>가 다름<ul><li>계단 함수는 0과 1 중 하나의 값만 출력<li>한편, 시그모이드 함수는 실수도 출력 가능<li>즉, 퍼셉트론에서는 뉴런 사이에 0이나 1만 흘렀지만, 신경망에서는 연속적인 실수가 흐름</ul><li>[공통점] 큰 관점에서 보면 <strong>같은 모양</strong>을 보임<ul><li>입력이 작을 때는 0에 가깝고, 입력이 클 때는 1에 가까워짐<li>즉, 두 함수 모두 입력이 중요하면 큰 값을 출력하고, 입력이 중요하지 않으면 작은 값을 출력<li>또한 입력이 아무리 작거나, 커도 출력은 0과 1 사이의 값을 가짐</ul><li>[공통점] <strong>비선형 함수</strong><ul><li>시그모이드 함수는 곡선, 계단 함수는 구부러진 직선 형태의 비선형 함수 꼴을 보임</ul></ol><h4 id="326-비선형-함수"><span class="mr-2">3.2.6 비선형 함수</span><a href="#326-비선형-함수" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>$f(x) = ax + b$처럼 직선 형태를 띄는 것을 <strong>선형 함수</strong>라고 정의<li>But, 위에서 봤던 시그모이드 함수나 계단 함수처럼 직선 1개로 그릴 수 없는 함수를 <strong>비선형 함수</strong>라고 정의<li>신경망의 활성화 함수를 선형 함수로 하는 경우에, 깊은 층이 의미가 없어지므로 비선형 함수를 사용해야 함<ul><li>은닉층이 없는 네트워크</ul></ul><h4 id="327-relu-rectified-linear-unit-함수"><span class="mr-2">3.2.7 ReLU (Rectified Linear Unit) 함수</span><a href="#327-relu-rectified-linear-unit-함수" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>ReLU 함수는 입력이 0을 넘으면 그 입력을 그대로 출력하고, 0 이하면 0을 출력하는 함수<li>이번 장에서는 시그모이드 함수를 사용하지만, 후반부에서는 ReLU 함수를 활성화 함수로 사용</ul><p><br /></p>\[h(x) = \left\{ \begin{array}\\ x &amp; (x &gt; 0) \\ 0 &amp; (x &lt;= 0) \\ \end{array} \right.\]<p><br /></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">ReLU</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="c1"># 두 입력 중 더 큰 값을 선택해서 반환
</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="s">"ReLU Function graph"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><p align="left"> <img data-src="../../assets/img/post_img/221006_3.png" data-proofer-ignore></p><h3 id="33-다차원-배열의-계산"><span class="mr-2">3.3 다차원 배열의 계산</span><a href="#33-다차원-배열의-계산" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="331-다차원-배열"><span class="mr-2">3.3.1 다차원 배열</span><a href="#331-다차원-배열" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>다차원 배열도 기본은 <strong>숫자의 집합</strong><li>숫자가 한 줄로, 직사각형으로, N차원으로 나열된 것 등을 모두 <strong>다차원 배열</strong>이라고 정의<li>2차원 배열은 <strong>행렬 (Matrix)</strong>이라고 부르고, 가로 방향을 행, 세로 방향을 열이라고 정의</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">ndim</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># 1 (4,)
</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">ndim</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="n">B</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># 2 (3, 2)
</span></pre></table></code></div></div><h4 id="332-행렬의-곱"><span class="mr-2">3.3.2 행렬의 곱</span><a href="#332-행렬의-곱" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://s1.md5.ltd/image/076c83bc7deb215d880f4d90dad15b13.png" width="400" height="400" data-proofer-ignore></p><p><br /></p><ul><li>행렬의 곱은 numpy에서 <strong>np.dot()</strong> 함수를 통해서 확인 가능<li>주의해야 할 것은 np.dot(A, B)와 np.dot(B, A)는 달라질 수도 있음<li>행렬의 곱을 수행하기 위해서는 <strong>행렬 A의 열 수와 행렬 B의 행 수가 같아야 함</strong></ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>

<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">))</span>  <span class="c1"># [[19 22] [43 50]] 
</span><span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">A</span><span class="p">))</span>  <span class="c1"># [[23 34] [31 46]]
</span></pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">B</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (3, 2) (2,) 
</span><span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">))</span>      <span class="c1"># [23 53 83]
</span></pre></table></code></div></div><h4 id="333-신경망에서-행렬의-곱"><span class="mr-2">3.3.3 신경망에서 행렬의 곱</span><a href="#333-신경망에서-행렬의-곱" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://mblogthumb-phinf.pstatic.net/MjAxODA5MjdfNjMg/MDAxNTM4MDE0NDkwMjAw.mMfOmVBBpA8Xvb1mlM8XWFlezAzFdF4B8HV0vkp_S24g.YbV20K7bYmvoIP8H_8X1blDyWeOlfGUxTF0dnE9ISyMg.PNG.cheeryun/fig_3-14.png?type=w800" width="400" height="400" data-proofer-ignore></p><p><br /></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>

<span class="nf">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">W</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (2,) (2, 3) 
</span><span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>      <span class="c1"># [ 5 11 17]
</span></pre></table></code></div></div><h3 id="34-3층-신경망-구현하기"><span class="mr-2">3.4 3층 신경망 구현하기</span><a href="#34-3층-신경망-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://mblogthumb-phinf.pstatic.net/MjAxODA2MTBfMjQ3/MDAxNTI4NjEzNzA1OTEx.8LP6DXgs8QCQTeni1VRi9BueT5Uv_DHKpRYBPqi2tC4g.TQmRFx4Qp_1j5kqfyxxLFB1zBo7yIeMTskaQjwX73Pkg.PNG.ssdyka/fig_3-15.png?type=w2" width="400" height="400" data-proofer-ignore></p><p><br /></p><ul><li>입력층 (0층)은 2개, 첫 번째 은닉층 (1층)은 3개, 두 번째 은닉층 (2층)은 2개, 출력층 (3층)은 2개의 뉴런</ul><h4 id="341-표기법-설명"><span class="mr-2">3.4.1 표기법 설명</span><a href="#341-표기법-설명" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://mblogthumb-phinf.pstatic.net/MjAxODA2MTBfNzIg/MDAxNTI4NjEzNzA2MzM0.j9QOoSA1XXHdyvrUWy0ZP_f_nWneMFSd1xIFpSRDxHsg.XXxHvb4p00Wu9Kzn_n-nB_lKfE2iRFVax14IwQhUejcg.PNG.ssdyka/fig_3-16.png?type=w2" width="400" height="400" data-proofer-ignore></p><p><br /></p><h4 id="342-각-층의-신호-전달-구현하기"><span class="mr-2">3.4.2 각 층의 신호 전달 구현하기</span><a href="#342-각-층의-신호-전달-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://mblogthumb-phinf.pstatic.net/MjAxODA2MTBfMjEx/MDAxNTI4NjEzNzA2NzUw.4uqh_gqJn64Ensn63s0fY1jpbspD5oilVYSu-ejMgs8g.Di4xipmNSMo-duyfkJNJAzfkqqS72dWbGSGxzhqcHjQg.PNG.ssdyka/fig_3-17.png?type=w2" width="400" height="400" data-proofer-ignore></p><p><br /></p>\[a_1^{(1)} = w_{11}^{(1)}x_1 + w_{12}^{(1)}x_2 + b_1^{(1)}\] \[A^{(1)} = XW^{(1)} + B^{(1)}\]<p><br /></p><ul><li>위 그림에서는 편향 $b$을 뜻하는 뉴런 1이 추가<li>편향은 오른쪽 아래 인덱스가 하나 밖에 없음 (앞 층의 편향 뉴런이 하나 뿐이기 때문)</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]])</span>
<span class="n">B1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">W1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">B1</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (2,) (2, 3) (3,) 
</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="n">B1</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"A1 = </span><span class="si">{</span><span class="n">A1</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>                <span class="c1"># A1 = [0.3 0.7 1.1]
</span></pre></table></code></div></div><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://mblogthumb-phinf.pstatic.net/MjAxODA2MTBfMTUy/MDAxNTI4NjEzNzA3MTgy.iInlQtedOrR3cr83cHlHh5iBC97Rd3CAn8lsfil2pJwg.VY7Bft0dgHkae7sJ4UrgO9CchUygWMF7DhqdSlMvzm0g.PNG.ssdyka/fig_3-18.png?type=w2" width="400" height="400" data-proofer-ignore></p><p><br /></p><ul><li>은닉층에서 가중치 합을 a로 표기하고, 활성화 함수 $h()$로 변환된 신호를 $z$로 표기<li>여기서 활성화 함수는 시그모이드 함수를 활용</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">Z1</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">A1</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"A1 = </span><span class="si">{</span><span class="n">A1</span><span class="si">}</span><span class="s">"</span><span class="p">)</span> <span class="c1"># A1 = [0.3 0.7 1.1]
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Z1 = </span><span class="si">{</span><span class="n">Z1</span><span class="si">}</span><span class="s">"</span><span class="p">)</span> <span class="c1"># Z1 = [0.57444252 0.66818777 0.75026011]
</span></pre></table></code></div></div><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://mblogthumb-phinf.pstatic.net/MjAxODA2MTBfMjg4/MDAxNTI4NjEzNzA3NTY4.cwhPzaPClfzWeATMD4HaoIlB8fISmeCpZ0F0dOMNYgwg.VCGI5jJ2ZPizDF-7smAQrHaU4-lt5D7edc3wvJXctBUg.PNG.ssdyka/fig_3-19.png?type=w2" width="400" height="400" data-proofer-ignore></p><p><br /></p><ul><li>이번에는 1층의 출력값이었던 Z1이 입력이 된다는 점 빼고는 모두 동일</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]])</span>
<span class="n">B2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="n">Z1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">W2</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">B2</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (3,) (3, 2) (2,) 
</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">B2</span>
<span class="n">Z2</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">A2</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"A2 = </span><span class="si">{</span><span class="n">A2</span><span class="si">}</span><span class="s">"</span><span class="p">)</span> <span class="c1"># A2 = [0.51615984 1.21402696]
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Z2 = </span><span class="si">{</span><span class="n">Z2</span><span class="si">}</span><span class="s">"</span><span class="p">)</span> <span class="c1"># Z2 = [0.62624937 0.7710107 ]
</span></pre></table></code></div></div><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://mblogthumb-phinf.pstatic.net/MjAxODA2MTBfMTgg/MDAxNTI4NjEzNzA3ODk1.OB5KMOlT1nVHC2soDuhlijxo7UTW6zxjoZ3MH1IiIVwg.r8GLKspRWCKdsp3xfel5Y34yJuK5K6AdmOQcBzX_iKgg.PNG.ssdyka/fig_3-20.png?type=w2" width="400" height="400" data-proofer-ignore></p><p><br /></p><ul><li>출력층의 활성화 함수는 입력을 그대로 출력해주는 항등 함수로 정의<li>출력층의 활성화 함수를 $\sigma()$로 표시하여 은닉층의 활성화 함수인 $h()$와 다름을 명시</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">identity_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="n">W3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span>
<span class="n">B3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="n">Z2</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">W3</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">B3</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (2,) (2, 2) (2,) 
</span>
<span class="n">A3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">Z2</span><span class="p">,</span> <span class="n">W3</span><span class="p">)</span> <span class="o">+</span> <span class="n">B3</span>
<span class="n">Y</span> <span class="o">=</span> <span class="nf">identity_func</span><span class="p">(</span><span class="n">A3</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"A3 = </span><span class="si">{</span><span class="n">A3</span><span class="si">}</span><span class="s">"</span><span class="p">)</span> <span class="c1"># A3 = [0.31682708 0.69627909]
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Y = </span><span class="si">{</span><span class="n">Y</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>   <span class="c1"># Y = [0.31682708 0.69627909]
</span></pre></table></code></div></div><h4 id="343-구현-정리"><span class="mr-2">3.4.3 구현 정리</span><a href="#343-구현-정리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>신경망 구현 관례에 따라 가중치만 W1 같이 대문자로 표현, 그 외 편향과 중간 결과는 소문자로 표현</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre><td class="rouge-code"><pre><span class="c1"># 가중치와 편향을 초기화하고, dic에 할당
</span><span class="k">def</span> <span class="nf">init_network</span><span class="p">():</span>
    <span class="n">network</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">network</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]])</span>
    <span class="n">network</span><span class="p">[</span><span class="s">'b1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>    
    <span class="n">network</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]])</span>
    <span class="n">network</span><span class="p">[</span><span class="s">'b2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>    
    <span class="n">network</span><span class="p">[</span><span class="s">'W3'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span>
    <span class="n">network</span><span class="p">[</span><span class="s">'b3'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>    
    
    <span class="k">return</span> <span class="n">network</span>

<span class="c1"># 입력 신호를 출력으로 변환하는 처리 과정 구현
# 신호가 순방향 (입력 -&gt; 출력)으로 전달되므로 forward (순전파)로 정의
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">W1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">W3</span> <span class="o">=</span> <span class="n">network</span><span class="p">[</span><span class="s">'W1'</span><span class="p">],</span> <span class="n">network</span><span class="p">[</span><span class="s">'W2'</span><span class="p">],</span> <span class="n">network</span><span class="p">[</span><span class="s">'W3'</span><span class="p">]</span>
    <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">network</span><span class="p">[</span><span class="s">'b1'</span><span class="p">],</span> <span class="n">network</span><span class="p">[</span><span class="s">'b2'</span><span class="p">],</span> <span class="n">network</span><span class="p">[</span><span class="s">'b3'</span><span class="p">]</span>
    
    <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
    <span class="n">z1</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span>
    
    <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
    <span class="n">z2</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
    
    <span class="n">a3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">W3</span><span class="p">)</span> <span class="o">+</span> <span class="n">b3</span>
    <span class="n">y</span> <span class="o">=</span> <span class="nf">identity_func</span><span class="p">(</span><span class="n">a3</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">y</span>

<span class="n">network</span> <span class="o">=</span> <span class="nf">init_network</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">forward</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># [0.31682708 0.69627909]
</span></pre></table></code></div></div><h3 id="35-출력층-설계하기"><span class="mr-2">3.5 출력층 설계하기</span><a href="#35-출력층-설계하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>신경망은 분류와 회귀 모두 이용 가능<ul><li>분류: 데이터가 어느 class에 속하는지를 찾는 유형<li>회귀: 데이터에서 연속적인 수치를 예측하는 유형</ul><li>일반적으로 회귀에는 항등 함수, 분류에는 시그모이드 및 소프트맥스 함수를 활성화 함수로 사용</ul><h4 id="351-항등-함수와-소프트맥스-함수-구현하기"><span class="mr-2">3.5.1 항등 함수와 소프트맥스 함수 구현하기</span><a href="#351-항등-함수와-소프트맥스-함수-구현하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li><strong>항등 (identity) 함수</strong>는 입력을 그대로 출력하므로, 출력층에서 이를 사용하면 입력 신호가 그대로 출력<li>분류에서 사용하는 <strong>소프트맥스 (softmax) 함수</strong><ul><li>n은 출력층의 뉴런 수<li>$y_k$는 그 중 $k$번째 출력을 뜻함</ul><li>소프트맥스 함수의 출력은 모든 입력 신호로부터 화살표를 받고 있음<li>그 이유는 출력층의 각 뉴런이 모든 입력 신호에서 영향을 받았기 때문</ul><p><br /></p>\[y_k = \frac{exp(a_k)}{\sum_{i=1}^{n} exp(a_i)}\]<p><br /></p><div class="table-wrapper"><table><thead><tr><th style="text-align: center">항등 함수<th style="text-align: center">소프트맥스 함수<tbody><tr><td style="text-align: center"><img data-src="https://sean-parkk.github.io/assets/images/DLscratch/3/Untitled%208.png" alt="" data-proofer-ignore><td style="text-align: center"><img data-src="https://sean-parkk.github.io/assets/images/DLscratch/3/Untitled%209.png" alt="" data-proofer-ignore></table></div><p><br /></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">2.9</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">])</span>
<span class="n">exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="n">sum_exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">exp_a</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">exp_a</span> <span class="o">/</span> <span class="n">sum_exp_a</span>

<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># [0.01821127 0.24519181 0.73659691]
</span></pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">sum_exp_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">exp_a</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">exp_a</span> <span class="o">/</span> <span class="n">sum_exp_a</span>
</pre></table></code></div></div><h4 id="352-소프트맥스-함수-구현-시-주의점"><span class="mr-2">3.5.2 소프트맥스 함수 구현 시 주의점</span><a href="#352-소프트맥스-함수-구현-시-주의점" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>위 <code class="language-plaintext highlighter-rouge">softmax</code> 함수는 컴퓨터로 계산할 때, <strong>오버플로</strong>라는 결함이 존재<li>지수 함수를 사용할 때, 너무 큰 값을 쉽게 내뱉는다는 한계<li>따라서 소프트맥스 함수를 개선</ul><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://velog.velcdn.com/images%2Fu_jinju%2Fpost%2Fcf944335-0e81-4e9d-9335-a7e0541d2ffc%2Fimage.png" width="400" height="400" data-proofer-ignore></p><p><br /></p><ol><li>C라는 임의의 정수를 분자와 분모 양쪽에 곱하기<li>C를 지수 함수 exp() 안으로 옮겨 logC로 만들기<li>logC를 C’이라는 새로운 기호로 바꾸기</ol><ul><li>이를 통해 알 수 있는 것<ul><li>소프트맥스의 지수 함수를 계산할 때, 어떤 정수를 더하거나 빼도 결과는 바뀌지 않음<li>C’에 어떤 값을 대입해도 상관 없지만, 오버플로를 막을 목적으로는 입력 신호 중 최댓값을 이용</ul></ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1010</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">990</span><span class="p">])</span>
<span class="c1"># 소프트맥스 함수의 계산
</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>    <span class="c1">#  array([nan, nan, nan])
</span></pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="c1"># nan만 나왔던 위 결과와 달리 정상 값이 나옴
</span><span class="nf">print</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span> <span class="c1"># [  0 -10 -20]
</span>
<span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">c</span><span class="p">))</span>
<span class="c1"># array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])
</span></pre></table></code></div></div><h4 id="353-소프트맥스-함수의-특징"><span class="mr-2">3.5.3 소프트맥스 함수의 특징</span><a href="#353-소프트맥스-함수의-특징" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>소프트맥스 함수의 출력은 0에서 1 사이의 실수<li>소프트맥스 함수 출력의 총합은 1<li>이러한 성질들을 통해 함수의 출력 값을 <strong>확률</strong>로 해석 가능<li>소프트맥스 함수를 적용해도 각 원소의 대소 관계는 변하지 않음<li>신경망을 이용한 분류에서는 가장 큰 출력을 내는 뉴런에 해당하는 클래스로만 인식<li>기계학습 문제 풀이는 <strong>학습과 추론</strong>의 단계로 이뤄짐<ul><li>학습 (Train): 데이터를 통해서 모델이 학습하는 단계<li>추론 (Inference): 학습한 모델로 미지의 데이터에 대해 추론 (분류)을 수행</ul></ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">2.9</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="c1"># y[0], y[1], y[2]의 확률값
</span><span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>       <span class="c1"># [0.01821127 0.24519181 0.73659691] 
</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>      <span class="c1"># 1.0
</span></pre></table></code></div></div><h4 id="354-출력층의-뉴런-수-정하기"><span class="mr-2">3.5.4 출력층의 뉴런 수 정하기</span><a href="#354-출력층의-뉴런-수-정하기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>출력층의 뉴런 수는 풀려는 문제에 맞게 적절히 정해야 함<li><strong>분류</strong>에서는 분류하고 싶은 클래스 수로 설정하는 것이 일반적<ul><li>0부터 9 중 하나로 분류하는 문제에서의 출력층 뉴런은 10개로 설정</ul></ul><h3 id="36-손글씨-숫자-mnist-인식"><span class="mr-2">3.6 손글씨 숫자 (MNIST) 인식</span><a href="#36-손글씨-숫자-mnist-인식" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h4 id="361-mnist-데이터셋"><span class="mr-2">3.6.1 MNIST 데이터셋</span><a href="#361-mnist-데이터셋" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>MNIST라는 데이터셋은 손글씨 숫자 이미지 집합<ul><li>0부터 9까지의 숫자 이미지로 구성<li>훈련 이미지는 60,000장, 시험 이미지는 10,000장<li>MNIST 이미지 데이터는 28 * 28 크기의 회색조 이미지 (1채널)<li>각 픽셀은 0에서 255까지의 값을 취함<li>각 이미지에는 그 이미지가 실제 의미하는 숫자가 레이블로 붙어 있음</ul></ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">sys</span><span class="p">,</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">pickle</span>
<span class="n">github_url</span> <span class="o">=</span> <span class="s">'/Users/paul/Desktop/github/deep-learning-from-scratch-master/'</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">github_url</span><span class="p">)</span>
<span class="kn">from</span> <span class="n">dataset.mnist</span> <span class="kn">import</span> <span class="n">load_mnist</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> \
    <span class="nf">load_mnist</span><span class="p">(</span><span class="n">flatten</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (60000, 784)
</span><span class="nf">print</span><span class="p">(</span><span class="n">t_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (60000,)
</span><span class="nf">print</span><span class="p">(</span><span class="n">x_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># (10000, 784)
</span><span class="nf">print</span><span class="p">(</span><span class="n">t_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># (10000,)
</span></pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="k">def</span> <span class="nf">img_show</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">pil_img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">fromarray</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">uint8</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
    <span class="n">pil_img</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
    
<span class="n">img</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">t_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>               <span class="c1"># 5
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>           <span class="c1"># (784,)
</span><span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>  <span class="c1"># 형상을 원래 이미지의 크기로 변형
</span><span class="nf">print</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>           <span class="c1"># (28, 28)
</span>
<span class="nf">img_show</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</pre></table></code></div></div><h4 id="362-신경망의-추론-처리"><span class="mr-2">3.6.2 신경망의 추론 처리</span><a href="#362-신경망의-추론-처리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>MNIST 데이터셋은 입력층 뉴런을 784개, 출력층 뉴런을 10개로 구성<ul><li>입력층 뉴런이 784개인 이유는 이미지 크기가 28 * 28 = 784<li>출력층 뉴런이 10개인 이유는 0부터 9까지 숫자를 구분하기 때문</ul><li>은닉층은 총 두 개로, 첫 번째 은닉층에는 50개의 뉴런, 두 번째 은닉층에는 100개의 뉴런 배치 (임의로 설정)<li>입력 이미지 데이터에 대한 전처리 작업으로 정규화를 수행<ul><li>정규화 (Normalization): 데이터를 특정 범위로 변환하는 처리<li>전처리 (Pre-processing): 신경망의 입력 데이터에 특정 변환을 가하는 것<li>백색화 (Whitening): 전체 데이터를 균일하게 분포시키는 것</ul></ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">get_data</span><span class="p">():</span>
    <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)</span> <span class="o">=</span> \
        <span class="nf">load_mnist</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">one_hot_label</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span>

<span class="k">def</span> <span class="nf">init_network</span><span class="p">():</span>
    <span class="c1"># 가중치와 편향 매개변수가 dictionary 변수로 저장되어 있는 pickle 파일
</span>    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">github_url</span> <span class="o">+</span> <span class="s">"ch03/sample_weight.pkl"</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">network</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">network</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">W1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">W3</span> <span class="o">=</span> <span class="n">network</span><span class="p">[</span><span class="s">'W1'</span><span class="p">],</span> <span class="n">network</span><span class="p">[</span><span class="s">'W2'</span><span class="p">],</span> <span class="n">network</span><span class="p">[</span><span class="s">'W3'</span><span class="p">]</span>
    <span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">network</span><span class="p">[</span><span class="s">'b1'</span><span class="p">],</span> <span class="n">network</span><span class="p">[</span><span class="s">'b2'</span><span class="p">],</span> <span class="n">network</span><span class="p">[</span><span class="s">'b3'</span><span class="p">]</span>

    <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
    <span class="n">z1</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
    <span class="n">z2</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">W3</span><span class="p">)</span> <span class="o">+</span> <span class="n">b3</span>
    <span class="n">y</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">a3</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">y</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="nf">get_data</span><span class="p">()</span>
<span class="n">network</span> <span class="o">=</span> <span class="nf">init_network</span><span class="p">()</span> 
<span class="nf">print</span><span class="p">(</span><span class="n">network</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span> <span class="c1"># dict_keys(['b2', 'W1', 'b1', 'W2', 'W3', 'b3'])
</span>
<span class="n">accuracy_cnt</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># 확률이 가장 높은 원소의 인덱스 (clas)
</span>    <span class="k">if</span> <span class="n">p</span> <span class="o">==</span> <span class="n">t</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
        <span class="n">accuracy_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># 가장 마지막 데이터의 예측 확률값과 class
</span><span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="c1"># [4.2882856e-04 2.0043008e-06 2.5405665e-03 2.0168895e-06 5.5917690e-04
#  3.1262048e-04 9.9614757e-01 4.3499364e-07 6.3756829e-06 3.7751408e-07] 6 
</span><span class="nf">print</span><span class="p">(</span><span class="s">"Accuracy:"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">accuracy_cnt</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="c1"># Accuracy:0.9352
</span></pre></table></code></div></div><h4 id="363-배치-처리"><span class="mr-2">3.6.3 배치 처리</span><a href="#363-배치-처리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><ul><li>아래의 결과에서 확인할 수 있듯, 다차원 배열의 대응하는 차원의 원소 수가 일치<li>가장 마지막 최종 결과는 원소가 10개인 1차원 배열 y가 출력</ul><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://sean-parkk.github.io/assets/images/DLscratch/3/Untitled%2010.png" width="400" height="400" data-proofer-ignore></p><p><br /></p><ul><li>이미지 100장을 묶어서 나온 결과를 보면 다음과 같음<li>하나로 묶은 입력 데이터를 <strong>배치 (batch)</strong>라고 정의</ul><p><br /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 400'%3E%3C/svg%3E" data-src="https://sean-parkk.github.io/assets/images/DLscratch/3/Untitled%2011.png" width="400" height="400" data-proofer-ignore></p><p><br /></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="c1">### 개별로 predict 한 결과가 아닌, 배치 단위로 predict하여 결과 확인
</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="nf">get_data</span><span class="p">()</span>
<span class="n">network</span> <span class="o">=</span> <span class="nf">init_network</span><span class="p">()</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># 배치 크기
</span><span class="n">accuracy_cnt</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="c1"># x[0:100], x[100:200], ...과 같은 형태
</span>    <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
    <span class="n">y_batch</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">x_batch</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">accuracy_cnt</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">p</span> <span class="o">==</span> <span class="n">t</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">])</span>

<span class="c1"># 가장 마지막 데이터의 예측 확률값과 class의 shape
</span><span class="nf">print</span><span class="p">(</span><span class="n">y_batch</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (100, 10) (100,)
</span><span class="nf">print</span><span class="p">(</span><span class="s">"Accuracy:"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">accuracy_cnt</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span> <span class="c1"># Accuracy:0.9352
</span></pre></table></code></div></div><h3 id="37-정리"><span class="mr-2">3.7 정리</span><a href="#37-정리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>신경망에서는 활성화 함수로 시그모이드, ReLU 함수 같은 비선형 함수를 활용<li>numpy의 다차원 배열을 잘 사용하면, 신경망을 효율적으로 구현할 수 있음<li>출력층의 활성화 함수로 회귀에서는 항등 함수, 분류에서는 소프트맥스 함수를 사용<li>분류에서는 출력층의 뉴런 수를 분류하려는 클래스 수와 같게 설정<li>입력 데이터를 묶은 것을 배치라고 하고, 추론 처리를 이 배치 단위로 진행하면 결과를 빨리 얻을 수 있음</ul><h3 id="추가-학습---tensorflow를-활용한-mnist-실습"><span class="mr-2">추가 학습 - tensorflow를 활용한 MNIST 실습</span><a href="#추가-학습---tensorflow를-활용한-mnist-실습" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c1"># 1. 데이터 불러오기
</span><span class="n">mnist</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">mnist</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="nf">load_data</span><span class="p">()</span>

<span class="c1"># 2. 간단한 데이터 전처리
</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="c1"># 3. 모델 구성
</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">softmax</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># 4. 모델 컴파일
</span><span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="c1"># 5. 모델 훈련
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># 6 훈련 과정 시각화
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="s">'Model accuracy &amp; loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="s">'Epoch'</span><span class="p">)</span> <span class="p">;</span> <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="s">'Value'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="s">'Accuracy'</span><span class="p">,</span> <span class="s">'Loss'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># 7. 정확도 평가
</span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="s">'테스트 정확도:'</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre>Epoch 1/10
1875/1875 [==========================] - 4s 2ms/step - loss: 0.2236 - accuracy: 0.9347
Epoch 2/10
1875/1875 [==========================] - 3s 2ms/step - loss: 0.0909 - accuracy: 0.9724
Epoch 3/10
1875/1875 [==========================] - 3s 2ms/step - loss: 0.0602 - accuracy: 0.9815
Epoch 4/10
1875/1875 [==========================] - 3s 2ms/step - loss: 0.0435 - accuracy: 0.9867
Epoch 5/10
1875/1875 [==========================] - 3s 2ms/step - loss: 0.0316 - accuracy: 0.9900
Epoch 6/10
1875/1875 [==========================] - 3s 2ms/step - loss: 0.0241 - accuracy: 0.9922
Epoch 7/10
1875/1875 [==========================] - 3s 2ms/step - loss: 0.0195 - accuracy: 0.9936
Epoch 8/10
1875/1875 [==========================] - 3s 2ms/step - loss: 0.0151 - accuracy: 0.9952
Epoch 9/10
1875/1875 [==========================] - 3s 2ms/step - loss: 0.0131 - accuracy: 0.9956
Epoch 10/10
1875/1875 [==========================] - 3s 2ms/step - loss: 0.0112 - accuracy: 0.9964
</pre></table></code></div></div><p align="left"> <img data-src="../../assets/img/post_img/221006_4.png" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>313/313 [==========================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9795
테스트 정확도: 0.9794999957084656
</pre></table></code></div></div><p><br /> <br /></p><blockquote><p>출처: 밑바닥부터 시작하는 딥러닝1 책 리뷰 -&gt; <a href="https://github.com/Paul-scpark/Deep-learning-from-scratch/blob/main/%EB%B0%91%EC%8B%9C%EB%94%A51-3%EA%B0%95-%EC%8B%A0%EA%B2%BD%EB%A7%9D.ipynb">강의 내용 정리 깃허브 링크</a></p></blockquote></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/review-it-book/'>Review - IT Book</a>, <a href='/categories/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D1/'>밑바닥부터 시작하는 딥러닝1</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/ai/" class="post-tag no-text-decoration" >AI</a> <a href="/tags/%EB%B0%91%EC%8B%9C%EB%94%A51/" class="post-tag no-text-decoration" >밑시딥1</a> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >Deep learning</a> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >Machine learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=%EB%B0%91%EC%8B%9C%EB%94%A51+3%EA%B0%95.+%EC%8B%A0%EA%B2%BD%EB%A7%9D+-+Paul%27s+Insights&url=https%3A%2F%2Fpaul-scpark.github.io%2Fposts%2F%25EB%25B0%2591%25EC%258B%259C%25EB%2594%25A51-3%25EA%25B0%2595-%25EC%258B%25A0%25EA%25B2%25BD%25EB%25A7%259D%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=%EB%B0%91%EC%8B%9C%EB%94%A51+3%EA%B0%95.+%EC%8B%A0%EA%B2%BD%EB%A7%9D+-+Paul%27s+Insights&u=https%3A%2F%2Fpaul-scpark.github.io%2Fposts%2F%25EB%25B0%2591%25EC%258B%259C%25EB%2594%25A51-3%25EA%25B0%2595-%25EC%258B%25A0%25EA%25B2%25BD%25EB%25A7%259D%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fpaul-scpark.github.io%2Fposts%2F%25EB%25B0%2591%25EC%258B%259C%25EB%2594%25A51-3%25EA%25B0%2595-%25EC%258B%25A0%25EA%25B2%25BD%25EB%25A7%259D%2F&text=%EB%B0%91%EC%8B%9C%EB%94%A51+3%EA%B0%95.+%EC%8B%A0%EA%B2%BD%EB%A7%9D+-+Paul%27s+Insights" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div><script src="https://utteranc.es/client.js" repo="Paul-scpark/Paul-scpark.github.io" issue-term="pathname" theme="github-dark" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-%ED%9B%84%EA%B8%B0/">프로그래머스 인공지능 데브코스 4기 수료 후기</a><li><a href="/posts/Coursera-Data-Engineering-1%EC%A3%BC%EC%B0%A8/">ETL & Data Pipelines with Shell, Airflow and Kafka 1주차</a><li><a href="/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-1%EC%A3%BC%EC%B0%A8/">프로그래머스 인공지능 데브코스 1주차 정리 및 후기</a><li><a href="/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-2%EC%A3%BC%EC%B0%A8/">프로그래머스 인공지능 데브코스 2주차 정리 및 후기</a><li><a href="/posts/Coursera-Data-Engineering-2%EC%A3%BC%EC%B0%A8/">ETL & Data Pipelines with Shell, Airflow and Kafka 2주차</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/deep-learning/">Deep learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/k-digital-training/">K-digital training</a> <a class="post-tag" href="/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4/">인공지능 데브코스</a> <a class="post-tag" href="/tags/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4/">프로그래머스</a> <a class="post-tag" href="/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%9D%BC%EB%B2%A8%EB%A7%81/">데이터 라벨링</a> <a class="post-tag" href="/tags/airflow/">Airflow</a> <a class="post-tag" href="/tags/data-engineering/">Data Engineering</a> <a class="post-tag" href="/tags/elt/">ELT</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-1%EA%B0%95-%ED%97%AC%EB%A1%9C-%ED%8C%8C%EC%9D%B4%EC%8D%AC/"><div class="card-body"> <em class="small" data-ts="1664600400" data-df="ll" > Oct 1, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑시딥1 1강. 헬로 파이썬</h3><div class="text-muted small"><p> 간단한 책 소개 이 책은 신경망과 딥러닝의 기본을 직접 만들면서 그 개념을 소개하고 있습니다. 일반적으로 잘 알려진 딥러닝 프레임워크인 TensorFlow나 PyTorch가 잘 되어 있긴 하지만, 밑바닥부터 딥러닝의 모델을 직접 만들어보는 것은 매우 중요하다고 생각합니다. 그런 부분에 대한 니즈가 항상...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-2%EA%B0%95-%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0/"><div class="card-body"> <em class="small" data-ts="1664931600" data-df="ll" > Oct 5, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑시딥1 2강. 퍼셉트론</h3><div class="text-muted small"><p> 이번 글에서는 본격적으로 밑바닥부터 시작하는 딥러닝1 책에 대한 리뷰를 시작합니다. 딥러닝의 가장 기초 개념이라고 할 수 있는 퍼셉트론이 무엇인지에 대해 학습합니다. 또한 AND, NAND, OR 게이트 등을 통해서 퍼셉트론의 구조와 동작 원리도 함께 배울 수 있습니다. Chapter Title ...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-4%EA%B0%95-%EC%8B%A0%EA%B2%BD%EB%A7%9D%ED%95%99%EC%8A%B5/"><div class="card-body"> <em class="small" data-ts="1665752400" data-df="ll" > Oct 14, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>밑시딥1 4강. 신경망 학습</h3><div class="text-muted small"><p> 이번 글에서는 밑바닥부터 시작하는 딥러닝1 책의 4강에 대한 리뷰를 시작합니다. 딥러닝의 퍼셉트론과 신경망에 대해 학습한 후, 이번에는 어떻게 학습이 진행되는지 학습합니다. 손실 함수를 통해 파라미터가 갱신되는 과정을 확인해보며, 그것을 가능케 하는 경사 하강법을 배웁니다. Chapter Title ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%EB%B0%91%EC%8B%9C%EB%94%A51-2%EA%B0%95-%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0/" class="btn btn-outline-primary" prompt="Older"><p>밑시딥1 2강. 퍼셉트론</p></a> <a href="/posts/SQL-%EC%BD%94%EB%94%A9%EC%9D%98-%EA%B8%B0%EC%88%A0-1%EA%B0%95/" class="btn btn-outline-primary" prompt="Newer"><p>SQL 코딩의 기술 1강. 데이터 모델 설계</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/Paul-scpark">Seongchan Park</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/deep-learning/">Deep learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/k-digital-training/">K-digital training</a> <a class="post-tag" href="/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4/">인공지능 데브코스</a> <a class="post-tag" href="/tags/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4/">프로그래머스</a> <a class="post-tag" href="/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%9D%BC%EB%B2%A8%EB%A7%81/">데이터 라벨링</a> <a class="post-tag" href="/tags/airflow/">Airflow</a> <a class="post-tag" href="/tags/data-engineering/">Data Engineering</a> <a class="post-tag" href="/tags/elt/">ELT</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { function updateMermaid(event) { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { const mode = event.data.message; if (typeof mermaid === "undefined") { return; } let expectedTheme = (mode === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } let initTheme = "default"; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); window.addEventListener("message", updateMermaid); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/ko.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
