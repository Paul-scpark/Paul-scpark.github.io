<!DOCTYPE html><html lang="ko" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="LG Aimers 2기 Explainable AI (서울대학교 문태섭 교수님)" /><meta property="og:locale" content="ko" /><meta name="description" content="LG Aimers AI 전문가 과정 강의 기록" /><meta property="og:description" content="LG Aimers AI 전문가 과정 강의 기록" /><link rel="canonical" href="https://paul-scpark.github.io/posts/LG-Aimers-%EC%84%A4%EB%AA%85%EA%B0%80%EB%8A%A5%ED%95%9C-AI/" /><meta property="og:url" content="https://paul-scpark.github.io/posts/LG-Aimers-%EC%84%A4%EB%AA%85%EA%B0%80%EB%8A%A5%ED%95%9C-AI/" /><meta property="og:site_name" content="Paul’s Insights" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-01-19T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="LG Aimers 2기 Explainable AI (서울대학교 문태섭 교수님)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-01-25T18:04:26+09:00","datePublished":"2023-01-19T00:00:00+09:00","description":"LG Aimers AI 전문가 과정 강의 기록","headline":"LG Aimers 2기 Explainable AI (서울대학교 문태섭 교수님)","mainEntityOfPage":{"@type":"WebPage","@id":"https://paul-scpark.github.io/posts/LG-Aimers-%EC%84%A4%EB%AA%85%EA%B0%80%EB%8A%A5%ED%95%9C-AI/"},"url":"https://paul-scpark.github.io/posts/LG-Aimers-%EC%84%A4%EB%AA%85%EA%B0%80%EB%8A%A5%ED%95%9C-AI/"}</script><title>LG Aimers 2기 Explainable AI (서울대학교 문태섭 교수님) | Paul's Insights</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Paul's Insights"><meta name="application-name" content="Paul's Insights"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/main_image.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Paul's Insights</a></div><div class="site-subtitle font-italic">Space to learn, to record experiences.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/Paul-scpark" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://www.linkedin.com/in/%EC%84%B1%EC%B0%AC-%EB%B0%95-35a84b219/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['solver.paul','google.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>LG Aimers 2기 Explainable AI (서울대학교 문태섭 교수님)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>LG Aimers 2기 Explainable AI (서울대학교 문태섭 교수님)</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1674054000" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jan 19, 2023 </em> </span> <span> Updated <em class="" data-ts="1674637466" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jan 25, 2023 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/Paul-scpark">Seongchan Park</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2930 words"> <em>16 min</em> read</span></div></div></div><div class="post-content"><p>이번 글에서는 LG Aimers의 AI 전문가 과정에서 설명가능한 AI에 대하여 학습합니다. 머신러닝은 크고 복잡한 데이터를 이해하고, 이들 간의 관계성을 살펴보는 기술이지만 본질적으로 해석 가능성을 제한하는 블랙박스인 경우가 많습니다. 현실에서 이것을 사용할 때는 그에 따른 해석이 요구되는데, 따라서 그 한계를 보완하기 위해 Explainable AI 즉, 설명가능한 AI 기술에 대해 학습하여 머신러닝 모델과 그 의미에 대하여 학습할 것입니다.</p><hr /><h2 id="1-explainable-ai-1"><span class="mr-2">1. Explainable AI 1</span><a href="#1-explainable-ai-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li>최근 딥러닝은 그 성능이 매우 빠르게 발전하고 있음<li>하지만 대용량 학습 데이터로부터 학습하는 모델 구조는 점점 더 복잡해지고, 이해하기 어려워진다는 한계점이 있음<li>즉, 입력을 주게 되면, 그에 따른 결과가 나오는 하나의 블랙박스 형태의 결과가 보여진다는 것<ul><li>이러한 예측 결과가 사람에게 직접 영향을 미치게 되는 경우에는 이 한계점은 매우 심각하게 될 것<li>자율주행, 의학적 진단, 대출 승인 등을 비롯한 AI 편향성 문제</ul><li>Reliability &amp; Robustness (Pascal VOC 2007 Classification)<ul><li>말 이미지가 주어졌을 때, 말의 어느 부분을 보고 해당 사진이 말이라는 것을 알게 됐는지 특정 부분을 하이라이트<li>XAI 기법은 이미지에서 말에 해당하는 부분이 아닌, 아랫쪽에 주로 하이라이트가 되어 있었음<li>데이터를 확인해보니, 말 사진에는 텍스트 워터마크가 있었고, 이것으로 말이라고 예측하고 있었다는 것<li>이처럼 XAI 기법을 통해서 모델이나 데이터셋의 오류를 색출하고, 편향성을 확인 할 수 있을 것</ul><li>결국, 왜 알고리즘이 그런 예측 결과를 냈는지 설명하여 신뢰 여부를 결정할 수 있어야 함<li>XAI에서 설명가능하다는 것은 모델을 사용할 때, 그 동작을 이해하고 신뢰할 수 있게 해주는 기계학습 기술으로 정의</ul><h3 id="xai의-대비되는-종류"><span class="mr-2">XAI의 대비되는 종류</span><a href="#xai의-대비되는-종류" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>Local vs Global<ul><li>Local: Describes an individual prediction (개별적인 예측 결과를 설명)<li>Global: Describes entire model behavior (전반적인 행동을 설명)</ul><li>White-box vs Black-box<ul><li>White-box: Explainer can access the inside of model (모델 내부 구조를 알고 설명)<li>Black-box: Explainer can access only the output (모델 구조를 모르고, 출력만으로 설명)</ul><li>Intrinsic vs Post-hoc<ul><li>Intrinsic: Restricts the model complexity before training<li>Post-hoc: Applies after the ML model is trained</ul><li>Model-specific vs Model-agnostic<ul><li>Model-specific: Some methods restricted to specific model classes<li>Model-agnostic: Some methods can be used for any model</ul></ul><p>-&gt; Linear model, Simple Decision Tree: Global, White-box, Intrinsic, Model-specific <br /> -&gt; Grad-CAM: Local, White-box, Post-hoc, Model-agnostic</p><h3 id="simple-gradient-method"><span class="mr-2">Simple Gradient method</span><a href="#simple-gradient-method" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>Simply use the gradient as the explanation (딥러닝의 Back-propagation)<li>Strength: Easy to compute (via Back-propagation)<li>Weakness: Becomes noisy (due to shattering gradient problem)<ul><li>즉, 똑같은 예측 결과를 갖는 조금씩 변하는 이미지들에 대해 각 이미지에 대한 설명이 많이 다를 수도 있음</ul></ul><h3 id="smoothgrad"><span class="mr-2">SmoothGrad</span><a href="#smoothgrad" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>Simple method to address the noisy gradients<li>이미지가 주어졌을 때, 작은 노이즈인 엡실론을 섞어준 뒤, 노이즈가 섞인 입력 이미지에 Gradient를 구하는 과정을 여러 번 수행하여 그 Gradient의 평균으로 설명하는 것 (대략 50번 정도)<li>Strength: Clearer interpretation via simple averaging, Applicable to most sensitive maps<li>Weakness: Computationally expensive</ul><h2 id="2-explainable-ai-2"><span class="mr-2">2. Explainable AI 2</span><a href="#2-explainable-ai-2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="class-activaiton-map-cam"><span class="mr-2">Class Activaiton Map (CAM)</span><a href="#class-activaiton-map-cam" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>어떤 이미지가 CNN 모델의 입력으로 주어졌을 때, 이미지에 해당하는 Activation들이 최종 이미지에 최종 Activation으로 나타나게 됨. 이러한 각 Activation map은 Global Average Pooling 별로 학습된 w_1부터 w_n을 활용하여 Activation map을 결합하게 됨. 최종 결합된 이미지는 하이라이트 되어 표현됨<li>어떤 Activation map에 Activation이 크게 된다는 것은 그 Map이 주어진 입력과 관련이 많다는 뜻이고, 그것을 결합하는 w가 크다는 것도 최종 분류에 큰 영향을 주는 Activation이라는 것<li>CAM은 Object detection 이나, Semantic segmentation 등 더 복잡한 응용 분야에도 적용 가능<li>Strength: It clearly shows what objects the model is looking at<li>Weakness<ul><li>Model-specific: It can be applied only to models with limited architecture<li>It can only be obtained at the last convolutional layer and this makes the interpretation resolution coarse (마지막 Convolutional layer의 Activation에서 얻을 수 있으므로 해상도가 좋지 않음)</ul></ul><h3 id="grad-cam"><span class="mr-2">Grad-CAM</span><a href="#grad-cam" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>CAM 방식을 보완한 방식으로, Global Average Pooling layer가 없는 모델도 적용할 수 있음<li>특정 모델 구조를 가지고 학습된 w를 사용하는 것이 아닌, Activation map의 Gradient를 구한 다음에 그것의 Global Average Pooling 값으로 w를 적용한다는 것<li>Strength: Model-agnostic 하여 It can be applied to various output models<li>Weakness: Average gradient sometimes is not accurate</ul><h3 id="perturbation-based"><span class="mr-2">Perturbation-based</span><a href="#perturbation-based" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>입력 데이터를 조금씩 바꾸면서 그에 대한 출력을 보고, 그 변화에 기반하여 설명하는 접근법<li>Local Interpretable Model-agnostic Explanations (LIME)<ul><li>어떤 분류기가 딥러닝 모델처럼 복잡한 비선형적 특징을 가지더라도, 주어진 데이터 포인트들에 대해서는 아주 Local 하게는 다 선형적인 모델로 근사화가 가능하다는 관찰에서 출발<li>그래서 주어진 데이터를 조금씩 교란해 가면서, 교란된 입력 데이터를 모델에 여러 번 통과시켜 나오는 출력을 보고, 나오는 입출력 Pair들을 간단한 선형 모델로 근사하여 설명을 얻어내는 방식<li>Strength: Black-box interpretation (딥러닝 모델 뿐 아니라, 입력과 출력을 얻을 수 있다면 모두 적용 가능)<li>Weakness: Computationally expensive, Hard to apply to certain kind of models, When the underlying model is still locally non-linear</ul><li>Randomized Input Sampling for Explanation (RISE)<ul><li>LIME 방식과 비슷하게, 여러 번 입력을 Perturb 해서 설명을 구하는 방식<li>랜덤한 Mask를 만들어서 그 Mask를 씌운 입력이 모델을 통과 했을 때, 해당 클래스에 대한 예측 확률이 얼마나 떨어지는 확인하여 설명력을 예측하게 됨. 즉, 여러 개의 랜덤 마스킹이 되어 있는 입력에 대해 출력 스코어를 구하고, 그 확률을 통해 이 마스크들을 가중치를 두어 평균을 냈을 때 나오는 것이 설명 Map<li>Strength: Much clear saliency-map<li>Weakness: High computational complexity, Noisy due to sampling</ul><li>Different approach for XAI<ul><li>Identify most influential training data point for the given prediction<li>Influence function<ul><li>Measure the effect of removing a training sample on the test loss value<li>특정 Training 이미지 없이 모델을 훈련시켰을 때, 해당 모델의 성능이 얼마만큼 변할지 근사화 하는 함수<li>이 함수를 가지고, 각 Training 이미지마다 영향력을 계산하고, 그 값이 가장 큰 이미지를 설명으로 제공</ul></ul></ul><h2 id="3-explainable-ai-3"><span class="mr-2">3. Explainable AI 3</span><a href="#3-explainable-ai-3" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="xai-방법을-비교-평가하는-방법"><span class="mr-2">XAI 방법을 비교 평가하는 방법</span><a href="#xai-방법을-비교-평가하는-방법" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>사람들이 직접 XAI 방법들이 만들어낸 설명을 보고 비교 및 평가하는 것<ul><li>AMT (Amazon Mechanical Turk) Test<li>Guided Backprop, Guided Grad-CAM 등 확인 가능<li>Weakness: Obtaining human assessment is very expensive</ul><li>Human annotation을 활용하는 것<ul><li>Some metrics employ human annotations (localization and semantic segmentation) as a ground truth, and compare them with interpretation<li>Pointing game: Bounding box를 활용하여 평가하는 방법<li>Weakly supervised semantic segmentation: 어떤 이미지에 대해 Label만 주어졌을 때, 그것을 활용하여 픽셀 별로 객체의 Label을 예측하는 방법 (Weakly supervised인 이유는, 픽셀 별로 정답 Label이 없기 떄문)<li>IoU (Intersection over Union): 정답 Map과 이렇게 만들어낸 Segmentation map이 얼마나 겹치는지 평가<li>Weakness: Hard to make the human annotations, Such localization and segmentation labels are not a ground truth of interpretation</ul><li>Pixel Perturbation 즉, 픽셀을 교란하여 모델의 출력값의 변화를 테스트<ul><li>성이 있는지 분류하는 모델이 있을 때, 성 부분을 가려서 모델을 통과시키면 그 값이 크게 떨어질 것임. 만약 성이 아닌 다른 부분을 가리게 된다면, 분류 스코어 값은 크게 변동이 없을 것임<li>AOPC (Area Over the MoRF Perturbation Curve): 주어진 이미지에 대해 각 XAI 기법이 설명을 제공하면, 그 설명의 중요도 순서대로 각 픽셀을 정렬할 수 있고, 그 순서대로 픽셀을 교란했을 때, 원래 예측한 분류 스코어 값이 얼마나 빨리 바뀌는지를 측정하는 것<li>Insertion: 중요한 순서대로, 백지 상태의 이미지에서 중요한 픽셀의 순서대로 하나씩 추가해가면서 분류기의 출력 스코어가 어떻게 변화하는지 확인하는 것. 따라서 이 값이 클수록 좋은 결과<li>Deletion: AOPC 방법과 같이 XAI 기법이 제공한 중요도 순서대로 픽셀을 하나씩 지워가며, 분류 확률 값이 떨어지는 확인하는 것으로, AOPC와는 반대로 커브의 아래 쪽의 면적을 구함. 따라서 이 값이 낮을수록 좋은 결과<li>Weakness: 데이터를 지우거나, 추가하는 과정이 머신러닝의 주요한 가정에 위반하는 경우가 있음. 즉, 어떤 픽셀을 지우고, 모델의 입력으로 넣었을 때, 해당 이미지는 모델을 학습시킨 Training 이미지들의 분포와 다르기 때문에 정확하지 않다는 것</ul><li>ROAR (RemOve And Retrain)<ul><li>XAI 기법이 발견한 중요한 픽셀을 지우고 나서, 지운 데이터를 통해 모델을 재학습하고, 정확도가 얼마나 떨어지는지 평가하는 방법 (재학습한 후에 나오는 모델의 성능이 떨어지는 경우에는 좋은 설명 방법이라는 것)<li>앞선 방법들에 비해 조금 더 객관적이고, 정확한 평가를 할 수 있지만, 계산 복잡도가 크다는 단점이 있음</ul></ul><h3 id="xai-방법의-신뢰성에-관한-연구"><span class="mr-2">XAI 방법의 신뢰성에 관한 연구</span><a href="#xai-방법의-신뢰성에-관한-연구" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>Sanity Checks<ul><li>Model Randomization<ul><li>Model Randomization Test<li>분류 모델에 위쪽 Layer부터 모델의 계수들을 순차적으로 Randomized 한 후에 얻어지는 설명들을 구함<li>계속 Randomized 되었으므로, 시간이 지날수록 성능이 떨어지지 않은 모델들은 학습이 잘못됨을 추론</ul><li>Adversarial Attack<ul><li>어떤 입력 이미지에 대한 픽셀을 아주 약간 바꿨을 떄, 분류기의 예측 결과를 완전히 다르게 만든다는 것<li>많은 설명 방법들이 Gradient와 연관되는 값을 사용하는데, Decision boundary가 불연속적으로 나오게 된다면, Gradient의 방향이 급격하게 변할 수 있기 때문에 조금만 입력이 바뀌어도 Gradient가 아주 많이 바뀔 수가 있다는 것<li>이에 조금 더 강건하게 반응하기 위해 ReLU 대신, Softplus를 사용하라</ul><li>Adversarial Model Manipulation<ul><li>모델이 편향되었다는 것을 알았을 때, 해당 모델을 다시 고쳐서 재학습 시키는 것이 아니라, 모델 계수를 조금씩 조작하여 모델의 정확도는 차이가 없지만 XAI의 결과가 공정한 것처럼 보일 수도 있다는 것</ul></ul></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/education/'>Education</a>, <a href='/categories/lg-aimers-2%EA%B8%B0/'>LG Aimers 2기</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/ai/" class="post-tag no-text-decoration" >AI</a> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >Deep learning</a> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >Machine learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=LG+Aimers+2%EA%B8%B0+Explainable+AI+%28%EC%84%9C%EC%9A%B8%EB%8C%80%ED%95%99%EA%B5%90+%EB%AC%B8%ED%83%9C%EC%84%AD+%EA%B5%90%EC%88%98%EB%8B%98%29+-+Paul%27s+Insights&url=https%3A%2F%2Fpaul-scpark.github.io%2Fposts%2FLG-Aimers-%25EC%2584%25A4%25EB%25AA%2585%25EA%25B0%2580%25EB%258A%25A5%25ED%2595%259C-AI%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=LG+Aimers+2%EA%B8%B0+Explainable+AI+%28%EC%84%9C%EC%9A%B8%EB%8C%80%ED%95%99%EA%B5%90+%EB%AC%B8%ED%83%9C%EC%84%AD+%EA%B5%90%EC%88%98%EB%8B%98%29+-+Paul%27s+Insights&u=https%3A%2F%2Fpaul-scpark.github.io%2Fposts%2FLG-Aimers-%25EC%2584%25A4%25EB%25AA%2585%25EA%25B0%2580%25EB%258A%25A5%25ED%2595%259C-AI%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fpaul-scpark.github.io%2Fposts%2FLG-Aimers-%25EC%2584%25A4%25EB%25AA%2585%25EA%25B0%2580%25EB%258A%25A5%25ED%2595%259C-AI%2F&text=LG+Aimers+2%EA%B8%B0+Explainable+AI+%28%EC%84%9C%EC%9A%B8%EB%8C%80%ED%95%99%EA%B5%90+%EB%AC%B8%ED%83%9C%EC%84%AD+%EA%B5%90%EC%88%98%EB%8B%98%29+-+Paul%27s+Insights" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div><script src="https://utteranc.es/client.js" repo="Paul-scpark/Paul-scpark.github.io" issue-term="pathname" theme="github-dark" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-%ED%9B%84%EA%B8%B0/">프로그래머스 인공지능 데브코스 4기 수료 후기</a><li><a href="/posts/Coursera-Data-Engineering-1%EC%A3%BC%EC%B0%A8/">ETL & Data Pipelines with Shell, Airflow and Kafka 1주차</a><li><a href="/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-1%EC%A3%BC%EC%B0%A8/">프로그래머스 인공지능 데브코스 1주차 정리 및 후기</a><li><a href="/posts/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4-2%EC%A3%BC%EC%B0%A8/">프로그래머스 인공지능 데브코스 2주차 정리 및 후기</a><li><a href="/posts/Coursera-Data-Engineering-2%EC%A3%BC%EC%B0%A8/">ETL & Data Pipelines with Shell, Airflow and Kafka 2주차</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/deep-learning/">Deep learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/k-digital-training/">K-digital training</a> <a class="post-tag" href="/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4/">인공지능 데브코스</a> <a class="post-tag" href="/tags/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4/">프로그래머스</a> <a class="post-tag" href="/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%9D%BC%EB%B2%A8%EB%A7%81/">데이터 라벨링</a> <a class="post-tag" href="/tags/airflow/">Airflow</a> <a class="post-tag" href="/tags/data-engineering/">Data Engineering</a> <a class="post-tag" href="/tags/elt/">ELT</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/LG-Aimers-%EB%94%A5%EB%9F%AC%EB%8B%9D/"><div class="card-body"> <em class="small" data-ts="1673967600" data-df="ll" > Jan 18, 2023 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>LG Aimers 2기 지도학습 - 딥러닝 (KAIST 주재걸 교수님)</h3><div class="text-muted small"><p> 이번 글에서는 LG Aimers의 AI 전문가 과정에서 딥러닝에 대한 기본 개념과 대표적인 모형의 학습 원리를 학습합니다. 특히, 이미지와 언어 모델 학습을 위한 딥러닝 모델과 학습 원리를 배우게 될 것입니다. 1. Introduction to DNN Artificial Intelligence &amp;gt; Machine Learning &amp;gt...</p></div></div></a></div><div class="card"> <a href="/posts/LG-Aimers-%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/"><div class="card-body"> <em class="small" data-ts="1674486000" data-df="ll" > Jan 24, 2023 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>LG Aimers 2기 인과추론 (서울대학교 이상학 교수님)</h3><div class="text-muted small"><p> 이번 글에서는 LG Aimers의 AI 전문가 과정에서 인과성에 대해 추론하고, 경험적 데이터를 사용해 인과 관계를 결정하는 방법을 익히게 됩니다. 이를 통해 데이터를 생성한 프로세스에 대해 만들어야 하는 필수 가정과 이러한 가정이 합리적인지 평가하는 방법, 마지막으로 추정되는 양을 해석하는 방법을 학습합니다. 1. Causality 인과성...</p></div></div></a></div><div class="card"> <a href="/posts/LG-Aimers-%EC%8B%9C%EA%B3%84%EC%97%B4-%EB%B6%84%EC%84%9D/"><div class="card-body"> <em class="small" data-ts="1674572400" data-df="ll" > Jan 25, 2023 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>LG Aimers 2기 시계열 분석 (고려대학교 강필성 교수님)</h3><div class="text-muted small"><p> 이번 글에서는 LG Aimers의 AI 전문가 과정에서 시계열 데이터의 순차적 특성을 고려한 모형과 그 학습 원리를 배웁니다. 모형의 어떠한 특성이 시계열 데이터의 특성을 학습에 반영하게 되는지 그리고 어떻게 모델의 성능을 향상시킬 수 있는지를 배울 수 있습니다. 1. 순환신경망 기반의 시계열 데이터 회귀 Non-Sequential vs Seq...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/LG-Aimers-%EB%94%A5%EB%9F%AC%EB%8B%9D/" class="btn btn-outline-primary" prompt="Older"><p>LG Aimers 2기 지도학습 - 딥러닝 (KAIST 주재걸 교수님)</p></a> <a href="/posts/LG-Aimers-%EC%9D%B8%EA%B3%BC%EC%B6%94%EB%A1%A0/" class="btn btn-outline-primary" prompt="Newer"><p>LG Aimers 2기 인과추론 (서울대학교 이상학 교수님)</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/Paul-scpark">Seongchan Park</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/deep-learning/">Deep learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/k-digital-training/">K-digital training</a> <a class="post-tag" href="/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EB%8D%B0%EB%B8%8C%EC%BD%94%EC%8A%A4/">인공지능 데브코스</a> <a class="post-tag" href="/tags/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4/">프로그래머스</a> <a class="post-tag" href="/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%9D%BC%EB%B2%A8%EB%A7%81/">데이터 라벨링</a> <a class="post-tag" href="/tags/airflow/">Airflow</a> <a class="post-tag" href="/tags/data-engineering/">Data Engineering</a> <a class="post-tag" href="/tags/elt/">ELT</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { function updateMermaid(event) { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { const mode = event.data.message; if (typeof mermaid === "undefined") { return; } let expectedTheme = (mode === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } let initTheme = "default"; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); window.addEventListener("message", updateMermaid); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/ko.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
